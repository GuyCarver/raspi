{
	"auto_complete":
	{
		"selected_items":
		[
			[
				"_tim",
				"_ontime"
			],
			[
				"_d",
				"_dirtydisplay"
			],
			[
				"display",
				"displayduration"
			],
			[
				"defa",
				"defaultdisplaydur"
			],
			[
				"CheckF",
				"CheckFaceCamera"
			],
			[
				"temp",
				"tempdisplay"
			],
			[
				"loca",
				"location"
			],
			[
				"tempdis",
				"tempdisplayinterval"
			],
			[
				"tempdisplay",
				"tempdisplaytime"
			],
			[
				"_l",
				"_ldthread"
			],
			[
				"update",
				"UpdateWeather"
			],
			[
				"_in",
				"_invertcolor"
			],
			[
				"sc",
				"screen_height"
			],
			[
				"def",
				"define\t#define"
			],
			[
				"wr",
				"wiringPi"
			],
			[
				"sub",
				"sublime_plugin"
			],
			[
				"cl",
				"cln"
			],
			[
				"b",
				"bool"
			],
			[
				"i",
				"i"
			],
			[
				"tabs",
				"tab_size"
			],
			[
				"B",
				"BSInt32"
			],
			[
				"subl",
				"sublime_plugin"
			],
			[
				"focus",
				"focus_view"
			],
			[
				"in",
				"inc\t#include \"â€¦\""
			],
			[
				"column",
				"columnSelect"
			],
			[
				"sublime",
				"sublime_plugin"
			]
		]
	},
	"buffers":
	[
		{
			"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/projects/oled/clock.py",
			"settings":
			{
				"buffer_size": 10325,
				"encoding": "UTF-8",
				"line_ending": "Unix"
			}
		},
		{
			"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/projects/oled/oled.py",
			"settings":
			{
				"buffer_size": 8631,
				"encoding": "UTF-8",
				"line_ending": "Windows"
			}
		},
		{
			"contents": "Searching 3118 files for \"CV_8UC1\" (regex)\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\3rdparty\\carotene\\hal\\tegra_hal.hpp:\n 1075  {\n 1076      if(!context || !kernel_data || allowSubmatrix || allowInplace ||\n 1077:        src_type != CV_8UC1 || dst_type != CV_8UC1 ||\n 1078         delta != 0 || anchor_x != kernel_width / 2 || anchor_y != kernel_height / 2 )\n 1079          return CV_HAL_ERROR_NOT_IMPLEMENTED;\n ....\n 1117      switch(kernel_type)\n 1118      {\n 1119:     case CV_8UC1:\n 1120          convert(ctx->ksize, (CAROTENE_NS::u8*)kernel_data, kernel_step, ctx->kernel_data, kernel_width);\n 1121          break;\n ....\n 1183                                 int anchor_x, int anchor_y, double delta, int borderType)\n 1184  {\n 1185:     if(!context || !kernelx_data || !kernely_data || src_type != CV_8UC1 || dst_type != CV_16SC1 ||\n 1186         kernelx_length != 3 || kernely_length != 3 ||\n 1187         delta != 0 || anchor_x != 1 || anchor_y != 1)\n ....\n 1221      switch(kernel_type)\n 1222      {\n 1223:     case CV_8UC1:\n 1224          ctx->kernelx_data[0]=kernelx_data[0];\n 1225          ctx->kernelx_data[1]=kernelx_data[1];\n ....\n 1451      /*nearest neighbour interpolation disabled due to rounding accuracy issues*/ \\\n 1452      /*interpolation == CV_HAL_INTER_NEAREST ? \\\n 1453:         (src_type == CV_8UC1 || src_type == CV_8SC1) && CAROTENE_NS::isResizeNearestNeighborSupported(CAROTENE_NS::Size2D(src_width, src_height), 1) ? \\\n 1454              CAROTENE_NS::resizeNearestNeighbor(CAROTENE_NS::Size2D(src_width, src_height), CAROTENE_NS::Size2D(dst_width, dst_height), \\\n 1455                                                 src_data, src_step, dst_data, dst_step, 1.0/inv_scale_x, 1.0/inv_scale_y, 1), \\\n ....\n 1470  ( \\\n 1471      interpolation == CV_HAL_INTER_NEAREST ? \\\n 1472:         (src_type == CV_8UC1 || src_type == CV_8SC1) && (borderType == CV_HAL_BORDER_REPLICATE || borderType == CV_HAL_BORDER_CONSTANT) && \\\n 1473          CAROTENE_NS::isWarpAffineNearestNeighborSupported(CAROTENE_NS::Size2D(src_width, src_height)) ? \\\n 1474              CAROTENE_NS::warpAffineNearestNeighbor(CAROTENE_NS::Size2D(src_width, src_height), CAROTENE_NS::Size2D(dst_width, dst_height), \\\n ....\n 1480          CV_HAL_ERROR_OK : CV_HAL_ERROR_NOT_IMPLEMENTED : \\\n 1481      interpolation == CV_HAL_INTER_LINEAR ? \\\n 1482:         (src_type == CV_8UC1 || src_type == CV_8SC1) && (borderType == CV_HAL_BORDER_REPLICATE || borderType == CV_HAL_BORDER_CONSTANT) && \\\n 1483          CAROTENE_NS::isWarpAffineLinearSupported(CAROTENE_NS::Size2D(src_width, src_height)) ? \\\n 1484              CAROTENE_NS::warpAffineLinear(CAROTENE_NS::Size2D(src_width, src_height), CAROTENE_NS::Size2D(dst_width, dst_height), \\\n ....\n 1495  ( \\\n 1496      interpolation == CV_HAL_INTER_NEAREST ? \\\n 1497:         (src_type == CV_8UC1 || src_type == CV_8SC1) && (borderType == CV_HAL_BORDER_REPLICATE || borderType == CV_HAL_BORDER_CONSTANT) && \\\n 1498          CAROTENE_NS::isWarpPerspectiveNearestNeighborSupported(CAROTENE_NS::Size2D(src_width, src_height)) ? \\\n 1499              CAROTENE_NS::warpPerspectiveNearestNeighbor(CAROTENE_NS::Size2D(src_width, src_height), CAROTENE_NS::Size2D(dst_width, dst_height), \\\n ....\n 1505          CV_HAL_ERROR_OK : CV_HAL_ERROR_NOT_IMPLEMENTED : \\\n 1506      interpolation == CV_HAL_INTER_LINEAR ? \\\n 1507:         (src_type == CV_8UC1 || src_type == CV_8SC1) && (borderType == CV_HAL_BORDER_REPLICATE || borderType == CV_HAL_BORDER_CONSTANT) && \\\n 1508          CAROTENE_NS::isWarpPerspectiveLinearSupported(CAROTENE_NS::Size2D(src_width, src_height)) ? \\\n 1509              CAROTENE_NS::warpPerspectiveLinear(CAROTENE_NS::Size2D(src_width, src_height), CAROTENE_NS::Size2D(dst_width, dst_height), \\\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\3rdparty\\openvx\\hal\\openvx_hal.cpp:\n  334                  ivx::Image::createAddressing(bw, bh, 1, (vx_int32)(bstep)), (void*)b);\n  335  \n  336:         if (!((atype == CV_8UC1 || atype == CV_8SC1) &&\n  337              inv_scale_x > 0 && inv_scale_y > 0 &&\n  338              (bw - 0.5) / inv_scale_x - 0.5 < aw && (bh - 0.5) / inv_scale_y - 0.5 < ah &&\n  ...\n  387                  ivx::Image::createAddressing(bw, bh, 1, (vx_int32)(bstep)), (void*)b);\n  388  \n  389:         if (!(atype == CV_8UC1 || atype == CV_8SC1))\n  390              return CV_HAL_ERROR_NOT_IMPLEMENTED;\n  391  \n  ...\n  449                  ivx::Image::createAddressing(bw, bh, 1, (vx_int32)(bstep)), (void*)b);\n  450  \n  451:         if (!(atype == CV_8UC1 || atype == CV_8SC1))\n  452              return CV_HAL_ERROR_NOT_IMPLEMENTED;\n  453  \n  ...\n  511  {\n  512      if (!filter_context || !kernel_data || allowSubmatrix || allowInplace || delta != 0 ||\n  513:         src_type != CV_8UC1 || (dst_type != CV_8UC1 && dst_type != CV_16SC1) ||\n  514          kernel_width % 2 == 0 || kernel_height % 2 == 0 || anchor_x != kernel_width / 2 || anchor_y != kernel_height / 2)\n  515          return CV_HAL_ERROR_NOT_IMPLEMENTED;\n  ...\n  534      switch (kernel_type)\n  535      {\n  536:     case CV_8UC1:\n  537          for (int j = 0; j < kernel_height; ++j)\n  538          {\n  ...\n  629  {\n  630      if (!filter_context || !kernelx_data || !kernely_data || delta != 0 ||\n  631:         src_type != CV_8UC1 || (dst_type != CV_8UC1 && dst_type != CV_16SC1) ||\n  632          kernelx_length != 3 || kernely_length != 3 || anchor_x != 1 || anchor_y != 1)\n  633          return CV_HAL_ERROR_NOT_IMPLEMENTED;\n  ...\n  653      switch (kernel_type)\n  654      {\n  655:     case CV_8UC1:\n  656          for (int j = 0; j < kernely_length; ++j)\n  657              for (int i = 0; i < kernelx_length; ++i)\n  ...\n  693  {\n  694      if (!filter_context || !kernel_data || allowSubmatrix || allowInplace || iterations != 1 ||\n  695:         src_type != CV_8UC1 || dst_type != CV_8UC1 ||\n  696          kernel_width % 2 == 0 || kernel_height % 2 == 0 || anchor_x != kernel_width / 2 || anchor_y != kernel_height / 2)\n  697          return CV_HAL_ERROR_NOT_IMPLEMENTED;\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\3rdparty\\openvx\\include\\ivx.hpp:\n  236      switch (type)\n  237      {\n  238:     case VX_TYPE_CHAR: return CV_8UC1;//While OpenCV support 8S as well, 8U is supported wider\n  239      case VX_TYPE_INT8: return CV_8SC1;\n  240:     case VX_TYPE_UINT8: return CV_8UC1;\n  241      case VX_TYPE_INT16: return CV_16SC1;\n  242      case VX_TYPE_UINT16: return CV_16UC1;\n  ...\n 1727          case VX_DF_IMAGE_RGB:  return CV_8UC3;\n 1728          case VX_DF_IMAGE_RGBX: return CV_8UC4;\n 1729:         case VX_DF_IMAGE_U8:   return CV_8UC1;\n 1730          case VX_DF_IMAGE_U16:  return CV_16UC1;\n 1731          case VX_DF_IMAGE_S16:  return CV_16SC1;\n ....\n 1735                                 return CV_32FC1;\n 1736          case VX_DF_IMAGE_YUV4:\n 1737:         case VX_DF_IMAGE_IYUV: return CV_8UC1;\n 1738          case VX_DF_IMAGE_UYVY:\n 1739          case VX_DF_IMAGE_YUYV: return CV_8UC2;\n 1740          case VX_DF_IMAGE_NV12:\n 1741:         case VX_DF_IMAGE_NV21: return planeIdx == 0 ? CV_8UC1 : CV_8UC2;\n 1742          default: return CV_USRTYPE1;\n 1743          }\n ....\n 1751          case CV_8UC4:  return VX_DF_IMAGE_RGBX;\n 1752          case CV_8UC3:  return VX_DF_IMAGE_RGB;\n 1753:         case CV_8UC1:  return VX_DF_IMAGE_U8;\n 1754          case CV_16UC1: return VX_DF_IMAGE_U16;\n 1755          case CV_16SC1: return VX_DF_IMAGE_S16;\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\apps\\createsamples\\utility.cpp:\n  265  \n  266      if( !src || (!CV_IS_IMAGE( src ) && !CV_IS_MAT( src )) ||\n  267:         cvGetElemType( src ) != CV_8UC1 ||\n  268          cvGetDims( src ) != 2 )\n  269      {\n  270          CV_ERROR( CV_StsBadArg,\n  271:             \"Source must be two-dimensional array of CV_8UC1 type.\" );\n  272      }\n  273      if( !dst || (!CV_IS_IMAGE( dst ) && !CV_IS_MAT( dst )) ||\n  274:         cvGetElemType( dst ) != CV_8UC1 ||\n  275          cvGetDims( dst ) != 2 )\n  276      {\n  277          CV_ERROR( CV_StsBadArg,\n  278:             \"Destination must be two-dimensional array of CV_8UC1 type.\" );\n  279      }\n  280  \n  ...\n  937      reader = (CvBackgroundReader*) cvAlloc( sizeof( *reader ) );\n  938      memset( (void*) reader, 0, sizeof( *reader ) );\n  939:     reader->src = cvMat( 0, 0, CV_8UC1, NULL );\n  940:     reader->img = cvMat( 0, 0, CV_8UC1, NULL );\n  941      reader->offset = cvPoint( 0, 0 );\n  942      reader->scale       = 1.0F;\n  ...\n 1036      }\n 1037      datasize = sizeof( uchar ) * img->width * img->height;\n 1038:     reader->src = cvMat( img->height, img->width, CV_8UC1, (void*) cvAlloc( datasize ) );\n 1039      cvCopy( img, &reader->src, NULL );\n 1040      cvReleaseImage( &img );\n ....\n 1051      reader->img = cvMat( (int) (reader->scale * reader->src.rows + 0.5F),\n 1052                           (int) (reader->scale * reader->src.cols + 0.5F),\n 1053:                           CV_8UC1, (void*) cvAlloc( datasize ) );\n 1054      cvResize( &(reader->src), &(reader->img) );\n 1055  }\n ....\n 1081  \n 1082      assert( data != NULL && reader != NULL && img != NULL );\n 1083:     assert( CV_MAT_TYPE( img->type ) == CV_8UC1 );\n 1084      assert( img->cols == data->winsize.width );\n 1085      assert( img->rows == data->winsize.height );\n ....\n 1090      }\n 1091  \n 1092:     mat = cvMat( data->winsize.height, data->winsize.width, CV_8UC1 );\n 1093      cvSetData( &mat, (void*) (reader->img.data.ptr + reader->point.y * reader->img.step\n 1094                                + reader->point.x * sizeof( uchar )), reader->img.step );\n ....\n 1116                  reader->img = cvMat( (int) (reader->scale * reader->src.rows),\n 1117                                       (int) (reader->scale * reader->src.cols),\n 1118:                                       CV_8UC1, (void*) (reader->img.data.ptr) );\n 1119                  cvResize( &(reader->src), &(reader->img) );\n 1120              }\n ....\n 1235                       cvSize( winwidth,winheight ) ) );\n 1236  \n 1237:             sample = cvMat( winheight, winwidth, CV_8UC1, cvAlloc( sizeof( uchar ) *\n 1238                              winheight * winwidth ) );\n 1239  \n ....\n 1660              file.last = 0;\n 1661              file.vector = (short*) cvAlloc( sizeof( *file.vector ) * file.vecsize );\n 1662:             sample = scaled_sample = cvCreateMat( winheight, winwidth, CV_8UC1 );\n 1663              if( scale != 1.0 )\n 1664              {\n 1665                  scaled_sample = cvCreateMat( MAX( 1, cvCeil( scale * winheight ) ),\n 1666                                               MAX( 1, cvCeil( scale * winwidth ) ),\n 1667:                                              CV_8UC1 );\n 1668              }\n 1669              cvNamedWindow( \"Sample\", CV_WINDOW_AUTOSIZE );\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\apps\\traincascade\\boost.cpp:\n  138      switch( type )\n  139      {\n  140:     case CV_8UC1:\n  141      case CV_8SC1:\n  142          // idx_arr is array of 1's and 0's -\n  ...\n  700      priors_mult = cvCloneMat( priors );\n  701      counts = cvCreateMat( 1, get_num_classes(), CV_32SC1 );\n  702:     direction = cvCreateMat( 1, sample_count, CV_8UC1 );\n  703      split_buf = cvCreateMat( 1, sample_count, CV_32SC1 );//TODO: make a pointer\n  704  }\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\apps\\traincascade\\cascadeclassifier.cpp:\n  323  {\n  324      int getcount = 0;\n  325:     Mat img(cascadeParams.winSize, CV_8UC1);\n  326      for( int i = first; i < first + count; i++ )\n  327      {\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\apps\\traincascade\\imagestorage.cpp:\n   19  CvCascadeImageReader::NegReader::NegReader()\n   20  {\n   21:     src.create( 0, 0 , CV_8UC1 );\n   22:     img.create( 0, 0, CV_8UC1 );\n   23      point = offset = Point( 0, 0 );\n   24      scale       = 1.0F;\n   ..\n   66          _offset.x = std::min( (int)round % winSize.width, src.cols - winSize.width );\n   67          _offset.y = std::min( (int)round / winSize.width, src.rows - winSize.height );\n   68:         if( !src.empty() && src.type() == CV_8UC1\n   69                  && _offset.x >= 0 && _offset.y >= 0 )\n   70              break;\n   ..\n   85  {\n   86      CV_Assert( !_img.empty() );\n   87:     CV_Assert( _img.type() == CV_8UC1 );\n   88      CV_Assert( _img.cols == winSize.width );\n   89      CV_Assert( _img.rows == winSize.height );\n   ..\n   93              return false;\n   94  \n   95:     Mat mat( winSize.height, winSize.width, CV_8UC1,\n   96          (void*)(img.ptr(point.y) + point.x * img.elemSize()), img.step );\n   97      mat.copyTo(_img);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\apps\\traincascade\\old_ml_boost.cpp:\n 1674  \n 1675          sample = cv::Mat(1, var_count, CV_32FC1);\n 1676:         missing = cv::Mat(1, var_count, CV_8UC1);\n 1677  \n 1678          dst_sample = sample.ptr<float>();\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\apps\\traincascade\\old_ml_data.cpp:\n  247      values = cvCreateMat( seq->total, cols_count, CV_32FC1 );\n  248      missing = cvCreateMat( seq->total, cols_count, CV_8U );\n  249:     var_idx_mask = cvCreateMat( 1, values->cols, CV_8UC1 );\n  250      cvSet( var_idx_mask, cvRealScalar(1) );\n  251      train_sample_count = seq->total;\n  ...\n  567      {\n  568          cvReleaseMat( &var_types_out );\n  569:         var_types_out = cvCreateMat( 1, vt_size, CV_8UC1 );\n  570      }\n  571  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\apps\\traincascade\\old_ml_inner_functions.cpp:\n  418      switch( type )\n  419      {\n  420:     case CV_8UC1:\n  421      case CV_8SC1:\n  422          // idx_arr is array of 1's and 0's -\n  ...\n  540      }\n  541  \n  542:     CV_CALL( out_var_type = cvCreateMat( 1, var_count, CV_8UC1 ));\n  543      src = var_type->data.ptr;\n  544      dst = out_var_type->data.ptr;\n  ...\n 1556          if( sample_idx && CV_MAT_TYPE(sample_idx->type) == CV_32SC1 )\n 1557          {\n 1558:             CV_CALL( sample_idx_buffer = cvCreateMat( 1, samples_all, CV_8UC1 ));\n 1559              cvZero( sample_idx_buffer );\n 1560              for( i = 0; i < samples_selected; i++ )\n ....\n 1612                      CV_ERROR( CV_StsOutOfRange, \"Some of sample_idx elements are out of range\" );\n 1613              }\n 1614:             else if( CV_MAT_TYPE(sample_idx->type) == CV_8UC1 &&\n 1615                       sample_idx->data.ptr[i*sample_idx_step] == 0 )\n 1616                  continue;\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\apps\\traincascade\\old_ml_precomp.hpp:\n  175      if( param )                                                                     \\\n  176      {                                                                               \\\n  177:         if( !ICV_IS_MAT_OF_TYPE( param, CV_8UC1 ) )                                 \\\n  178          {                                                                           \\\n  179              CV_ERROR( CV_StsBadArg, \"Invalid \" #param \" parameter\" );               \\\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\apps\\traincascade\\old_ml_tree.cpp:\n  667  \n  668  \n  669:     CV_CALL( direction = cvCreateMat( 1, sample_count, CV_8UC1 ));\n  670      CV_CALL( split_buf = cvCreateMat( 1, sample_count, CV_32SC1 ));\n  671  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\apps\\visualisation\\opencv_visualisation.cpp:\n  200          // If visualisations should be stored then do the in between calculations\n  201          Mat image_plane;\n  202:         Mat metadata = Mat::zeros(150, 1000, CV_8UC1);\n  203          vector< rect_data > current_rects;\n  204          for(int sid = 0; sid < (int)stage_features.size(); sid ++){\n  ...\n  210                      rows++;\n  211                  }\n  212:                 image_plane = Mat::zeros(reference_image.rows * resize_storage_factor * rows, reference_image.cols * resize_storage_factor * cols, CV_8UC1);\n  213              }\n  214              for(int fid = 0; fid < (int)stage_features[sid].size(); fid++){\n  ...\n  274          // then continue to the next feature.\n  275          Mat image_plane;\n  276:         Mat metadata = Mat::zeros(150, 1000, CV_8UC1);\n  277          for(int sid = 0; sid < (int)stage_features.size(); sid ++){\n  278              if(draw_planes){\n  ...\n  283                      rows++;\n  284                  }\n  285:                 image_plane = Mat::zeros(reference_image.rows * resize_storage_factor * rows, reference_image.cols * resize_storage_factor * cols, CV_8UC1);\n  286              }\n  287              for(int fid = 0; fid < (int)stage_features[sid].size(); fid++){\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\build\\carotene\\tegra_hal.hpp:\n 1075  {\n 1076      if(!context || !kernel_data || allowSubmatrix || allowInplace ||\n 1077:        src_type != CV_8UC1 || dst_type != CV_8UC1 ||\n 1078         delta != 0 || anchor_x != kernel_width / 2 || anchor_y != kernel_height / 2 )\n 1079          return CV_HAL_ERROR_NOT_IMPLEMENTED;\n ....\n 1117      switch(kernel_type)\n 1118      {\n 1119:     case CV_8UC1:\n 1120          convert(ctx->ksize, (CAROTENE_NS::u8*)kernel_data, kernel_step, ctx->kernel_data, kernel_width);\n 1121          break;\n ....\n 1183                                 int anchor_x, int anchor_y, double delta, int borderType)\n 1184  {\n 1185:     if(!context || !kernelx_data || !kernely_data || src_type != CV_8UC1 || dst_type != CV_16SC1 ||\n 1186         kernelx_length != 3 || kernely_length != 3 ||\n 1187         delta != 0 || anchor_x != 1 || anchor_y != 1)\n ....\n 1221      switch(kernel_type)\n 1222      {\n 1223:     case CV_8UC1:\n 1224          ctx->kernelx_data[0]=kernelx_data[0];\n 1225          ctx->kernelx_data[1]=kernelx_data[1];\n ....\n 1451      /*nearest neighbour interpolation disabled due to rounding accuracy issues*/ \\\n 1452      /*interpolation == CV_HAL_INTER_NEAREST ? \\\n 1453:         (src_type == CV_8UC1 || src_type == CV_8SC1) && CAROTENE_NS::isResizeNearestNeighborSupported(CAROTENE_NS::Size2D(src_width, src_height), 1) ? \\\n 1454              CAROTENE_NS::resizeNearestNeighbor(CAROTENE_NS::Size2D(src_width, src_height), CAROTENE_NS::Size2D(dst_width, dst_height), \\\n 1455                                                 src_data, src_step, dst_data, dst_step, 1.0/inv_scale_x, 1.0/inv_scale_y, 1), \\\n ....\n 1470  ( \\\n 1471      interpolation == CV_HAL_INTER_NEAREST ? \\\n 1472:         (src_type == CV_8UC1 || src_type == CV_8SC1) && (borderType == CV_HAL_BORDER_REPLICATE || borderType == CV_HAL_BORDER_CONSTANT) && \\\n 1473          CAROTENE_NS::isWarpAffineNearestNeighborSupported(CAROTENE_NS::Size2D(src_width, src_height)) ? \\\n 1474              CAROTENE_NS::warpAffineNearestNeighbor(CAROTENE_NS::Size2D(src_width, src_height), CAROTENE_NS::Size2D(dst_width, dst_height), \\\n ....\n 1480          CV_HAL_ERROR_OK : CV_HAL_ERROR_NOT_IMPLEMENTED : \\\n 1481      interpolation == CV_HAL_INTER_LINEAR ? \\\n 1482:         (src_type == CV_8UC1 || src_type == CV_8SC1) && (borderType == CV_HAL_BORDER_REPLICATE || borderType == CV_HAL_BORDER_CONSTANT) && \\\n 1483          CAROTENE_NS::isWarpAffineLinearSupported(CAROTENE_NS::Size2D(src_width, src_height)) ? \\\n 1484              CAROTENE_NS::warpAffineLinear(CAROTENE_NS::Size2D(src_width, src_height), CAROTENE_NS::Size2D(dst_width, dst_height), \\\n ....\n 1495  ( \\\n 1496      interpolation == CV_HAL_INTER_NEAREST ? \\\n 1497:         (src_type == CV_8UC1 || src_type == CV_8SC1) && (borderType == CV_HAL_BORDER_REPLICATE || borderType == CV_HAL_BORDER_CONSTANT) && \\\n 1498          CAROTENE_NS::isWarpPerspectiveNearestNeighborSupported(CAROTENE_NS::Size2D(src_width, src_height)) ? \\\n 1499              CAROTENE_NS::warpPerspectiveNearestNeighbor(CAROTENE_NS::Size2D(src_width, src_height), CAROTENE_NS::Size2D(dst_width, dst_height), \\\n ....\n 1505          CV_HAL_ERROR_OK : CV_HAL_ERROR_NOT_IMPLEMENTED : \\\n 1506      interpolation == CV_HAL_INTER_LINEAR ? \\\n 1507:         (src_type == CV_8UC1 || src_type == CV_8SC1) && (borderType == CV_HAL_BORDER_REPLICATE || borderType == CV_HAL_BORDER_CONSTANT) && \\\n 1508          CAROTENE_NS::isWarpPerspectiveLinearSupported(CAROTENE_NS::Size2D(src_width, src_height)) ? \\\n 1509              CAROTENE_NS::warpPerspectiveLinear(CAROTENE_NS::Size2D(src_width, src_height), CAROTENE_NS::Size2D(dst_width, dst_height), \\\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\build\\modules\\python2\\pyopencv_generated_funcs.h:\n 25014      int dy=1;\n 25015      int ksize=3;\n 25016:     int out_dtype=CV_8UC1;\n 25017      double scale=1;\n 25018      double delta=0;\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\build\\modules\\python2\\pyopencv_generated_ns_reg.h:\n   61      {\"addText\", (PyCFunction)pyopencv_cv_addText, METH_VARARGS | METH_KEYWORDS, \"addText(img, text, org, nameFont[, pointSize[, color[, weight[, style[, spacing]]]]]) -> None\\n.   @brief Draws a text on the image.\\n.   \\n.   @param img 8-bit 3-channel image where the text should be drawn.\\n.   @param text Text to write on an image.\\n.   @param org Point(x,y) where the text should start on an image.\\n.   @param nameFont Name of the font. The name should match the name of a system font (such as\\n.   *Times*). If the font is not found, a default one is used.\\n.   @param pointSize Size of the font. If not specified, equal zero or negative, the point size of the\\n.   font is set to a system-dependent default value. Generally, this is 12 points.\\n.   @param color Color of the font in BGRA where A = 255 is fully transparent.\\n.   @param weight Font weight. Available operation flags are : cv::QtFontWeights You can also specify a positive integer for better control.\\n.   @param style Font style. Available operation flags are : cv::QtFontStyles\\n.   @param spacing Spacing between characters. It can be negative or positive.\"},\n   62      {\"addWeighted\", (PyCFunction)pyopencv_cv_addWeighted, METH_VARARGS | METH_KEYWORDS, \"addWeighted(src1, alpha, src2, beta, gamma[, dst[, dtype]]) -> dst\\n.   @brief Calculates the weighted sum of two arrays.\\n.   \\n.   The function addWeighted calculates the weighted sum of two arrays as follows:\\n.   \\\\f[\\\\texttt{dst} (I)= \\\\texttt{saturate} ( \\\\texttt{src1} (I)* \\\\texttt{alpha} +  \\\\texttt{src2} (I)* \\\\texttt{beta} +  \\\\texttt{gamma} )\\\\f]\\n.   where I is a multi-dimensional index of array elements. In case of multi-channel arrays, each\\n.   channel is processed independently.\\n.   The function can be replaced with a matrix expression:\\n.   @code{.cpp}\\n.   dst = src1*alpha + src2*beta + gamma;\\n.   @endcode\\n.   @note Saturation is not applied when the output array has the depth CV_32S. You may even get\\n.   result of an incorrect sign in the case of overflow.\\n.   @param src1 first input array.\\n.   @param alpha weight of the first array elements.\\n.   @param src2 second input array of the same size and channel number as src1.\\n.   @param beta weight of the second array elements.\\n.   @param gamma scalar added to each sum.\\n.   @param dst output array that has the same size and number of channels as the input arrays.\\n.   @param dtype optional depth of the output array; when both input arrays have the same depth, dtype\\n.   can be set to -1, which will be equivalent to src1.depth().\\n.   @sa  add, subtract, scaleAdd, Mat::convertTo\"},\n   63:     {\"applyColorMap\", (PyCFunction)pyopencv_cv_applyColorMap, METH_VARARGS | METH_KEYWORDS, \"applyColorMap(src, colormap[, dst]) -> dst\\n.   @brief Applies a GNU Octave/MATLAB equivalent colormap on a given image.\\n.   \\n.   @param src The source image, grayscale or colored of type CV_8UC1 or CV_8UC3.\\n.   @param dst The result is the colormapped source image. Note: Mat::create is called on dst.\\n.   @param colormap The colormap to apply, see cv::ColormapTypes\\n\\n\\n\\napplyColorMap(src, userColor[, dst]) -> dst\\n.   @brief Applies a user colormap on a given image.\\n.   \\n.   @param src The source image, grayscale or colored of type CV_8UC1 or CV_8UC3.\\n.   @param dst The result is the colormapped source image. Note: Mat::create is called on dst.\\n.   @param userColor The colormap to apply of type CV_8UC1 or CV_8UC3 and size 256\"},\n   64      {\"approxPolyDP\", (PyCFunction)pyopencv_cv_approxPolyDP, METH_VARARGS | METH_KEYWORDS, \"approxPolyDP(curve, epsilon, closed[, approxCurve]) -> approxCurve\\n.   @brief Approximates a polygonal curve(s) with the specified precision.\\n.   \\n.   The function cv::approxPolyDP approximates a curve or a polygon with another curve/polygon with less\\n.   vertices so that the distance between them is less or equal to the specified precision. It uses the\\n.   Douglas-Peucker algorithm <http://en.wikipedia.org/wiki/Ramer-Douglas-Peucker_algorithm>\\n.   \\n.   @param curve Input vector of a 2D point stored in std::vector or Mat\\n.   @param approxCurve Result of the approximation. The type should match the type of the input curve.\\n.   @param epsilon Parameter specifying the approximation accuracy. This is the maximum distance\\n.   between the original curve and its approximation.\\n.   @param closed If true, the approximated curve is closed (its first and last vertices are\\n.   connected). Otherwise, it is not closed.\"},\n   65      {\"arcLength\", (PyCFunction)pyopencv_cv_arcLength, METH_VARARGS | METH_KEYWORDS, \"arcLength(curve, closed) -> retval\\n.   @brief Calculates a contour perimeter or a curve length.\\n.   \\n.   The function computes a curve length or a closed contour perimeter.\\n.   \\n.   @param curve Input vector of 2D points, stored in std::vector or Mat.\\n.   @param closed Flag indicating whether the curve is closed or not.\"},\n   ..\n  196      {\"findFundamentalMat\", (PyCFunction)pyopencv_cv_findFundamentalMat, METH_VARARGS | METH_KEYWORDS, \"findFundamentalMat(points1, points2[, method[, param1[, param2[, mask]]]]) -> retval, mask\\n.   @brief Calculates a fundamental matrix from the corresponding points in two images.\\n.   \\n.   @param points1 Array of N points from the first image. The point coordinates should be\\n.   floating-point (single or double precision).\\n.   @param points2 Array of the second image points of the same size and format as points1 .\\n.   @param method Method for computing a fundamental matrix.\\n.   -   **CV_FM_7POINT** for a 7-point algorithm. \\\\f$N = 7\\\\f$\\n.   -   **CV_FM_8POINT** for an 8-point algorithm. \\\\f$N \\\\ge 8\\\\f$\\n.   -   **CV_FM_RANSAC** for the RANSAC algorithm. \\\\f$N \\\\ge 8\\\\f$\\n.   -   **CV_FM_LMEDS** for the LMedS algorithm. \\\\f$N \\\\ge 8\\\\f$\\n.   @param param1 Parameter used for RANSAC. It is the maximum distance from a point to an epipolar\\n.   line in pixels, beyond which the point is considered an outlier and is not used for computing the\\n.   final fundamental matrix. It can be set to something like 1-3, depending on the accuracy of the\\n.   point localization, image resolution, and the image noise.\\n.   @param param2 Parameter used for the RANSAC or LMedS methods only. It specifies a desirable level\\n.   of confidence (probability) that the estimated matrix is correct.\\n.   @param mask\\n.   \\n.   The epipolar geometry is described by the following equation:\\n.   \\n.   \\\\f[[p_2; 1]^T F [p_1; 1] = 0\\\\f]\\n.   \\n.   where \\\\f$F\\\\f$ is a fundamental matrix, \\\\f$p_1\\\\f$ and \\\\f$p_2\\\\f$ are corresponding points in the first and the\\n.   second images, respectively.\\n.   \\n.   The function calculates the fundamental matrix using one of four methods listed above and returns\\n.   the found fundamental matrix. Normally just one matrix is found. But in case of the 7-point\\n.   algorithm, the function may return up to 3 solutions ( \\\\f$9 \\\\times 3\\\\f$ matrix that stores all 3\\n.   matrices sequentially).\\n.   \\n.   The calculated fundamental matrix may be passed further to computeCorrespondEpilines that finds the\\n.   epipolar lines corresponding to the specified points. It can also be passed to\\n.   stereoRectifyUncalibrated to compute the rectification transformation. :\\n.   @code\\n.   // Example. Estimation of fundamental matrix using the RANSAC algorithm\\n.   int point_count = 100;\\n.   vector<Point2f> points1(point_count);\\n.   vector<Point2f> points2(point_count);\\n.   \\n.   // initialize the points here ...\\n.   for( int i = 0; i < point_count; i++ )\\n.   {\\n.   points1[i] = ...;\\n.   points2[i] = ...;\\n.   }\\n.   \\n.   Mat fundamental_matrix =\\n.   findFundamentalMat(points1, points2, FM_RANSAC, 3, 0.99);\\n.   @endcode\"},\n  197      {\"findHomography\", (PyCFunction)pyopencv_cv_findHomography, METH_VARARGS | METH_KEYWORDS, \"findHomography(srcPoints, dstPoints[, method[, ransacReprojThreshold[, mask[, maxIters[, confidence]]]]]) -> retval, mask\\n.   @brief Finds a perspective transformation between two planes.\\n.   \\n.   @param srcPoints Coordinates of the points in the original plane, a matrix of the type CV_32FC2\\n.   or vector\\\\<Point2f\\\\> .\\n.   @param dstPoints Coordinates of the points in the target plane, a matrix of the type CV_32FC2 or\\n.   a vector\\\\<Point2f\\\\> .\\n.   @param method Method used to computed a homography matrix. The following methods are possible:\\n.   -   **0** - a regular method using all the points\\n.   -   **RANSAC** - RANSAC-based robust method\\n.   -   **LMEDS** - Least-Median robust method\\n.   -   **RHO**    - PROSAC-based robust method\\n.   @param ransacReprojThreshold Maximum allowed reprojection error to treat a point pair as an inlier\\n.   (used in the RANSAC and RHO methods only). That is, if\\n.   \\\\f[\\\\| \\\\texttt{dstPoints} _i -  \\\\texttt{convertPointsHomogeneous} ( \\\\texttt{H} * \\\\texttt{srcPoints} _i) \\\\|  >  \\\\texttt{ransacReprojThreshold}\\\\f]\\n.   then the point \\\\f$i\\\\f$ is considered an outlier. If srcPoints and dstPoints are measured in pixels,\\n.   it usually makes sense to set this parameter somewhere in the range of 1 to 10.\\n.   @param mask Optional output mask set by a robust method ( RANSAC or LMEDS ). Note that the input\\n.   mask values are ignored.\\n.   @param maxIters The maximum number of RANSAC iterations, 2000 is the maximum it can be.\\n.   @param confidence Confidence level, between 0 and 1.\\n.   \\n.   The function finds and returns the perspective transformation \\\\f$H\\\\f$ between the source and the\\n.   destination planes:\\n.   \\n.   \\\\f[s_i  \\\\vecthree{x'_i}{y'_i}{1} \\\\sim H  \\\\vecthree{x_i}{y_i}{1}\\\\f]\\n.   \\n.   so that the back-projection error\\n.   \\n.   \\\\f[\\\\sum _i \\\\left ( x'_i- \\\\frac{h_{11} x_i + h_{12} y_i + h_{13}}{h_{31} x_i + h_{32} y_i + h_{33}} \\\\right )^2+ \\\\left ( y'_i- \\\\frac{h_{21} x_i + h_{22} y_i + h_{23}}{h_{31} x_i + h_{32} y_i + h_{33}} \\\\right )^2\\\\f]\\n.   \\n.   is minimized. If the parameter method is set to the default value 0, the function uses all the point\\n.   pairs to compute an initial homography estimate with a simple least-squares scheme.\\n.   \\n.   However, if not all of the point pairs ( \\\\f$srcPoints_i\\\\f$, \\\\f$dstPoints_i\\\\f$ ) fit the rigid perspective\\n.   transformation (that is, there are some outliers), this initial estimate will be poor. In this case,\\n.   you can use one of the three robust methods. The methods RANSAC, LMeDS and RHO try many different\\n.   random subsets of the corresponding point pairs (of four pairs each), estimate the homography matrix\\n.   using this subset and a simple least-square algorithm, and then compute the quality/goodness of the\\n.   computed homography (which is the number of inliers for RANSAC or the median re-projection error for\\n.   LMeDs). The best subset is then used to produce the initial estimate of the homography matrix and\\n.   the mask of inliers/outliers.\\n.   \\n.   Regardless of the method, robust or not, the computed homography matrix is refined further (using\\n.   inliers only in case of a robust method) with the Levenberg-Marquardt method to reduce the\\n.   re-projection error even more.\\n.   \\n.   The methods RANSAC and RHO can handle practically any ratio of outliers but need a threshold to\\n.   distinguish inliers from outliers. The method LMeDS does not need any threshold but it works\\n.   correctly only when there are more than 50% of inliers. Finally, if there are no outliers and the\\n.   noise is rather small, use the default method (method=0).\\n.   \\n.   The function is used to find initial intrinsic and extrinsic matrices. Homography matrix is\\n.   determined up to a scale. Thus, it is normalized so that \\\\f$h_{33}=1\\\\f$. Note that whenever an H matrix\\n.   cannot be estimated, an empty one will be returned.\\n.   \\n.   @sa\\n.   getAffineTransform, estimateAffine2D, estimateAffinePartial2D, getPerspectiveTransform, warpPerspective,\\n.   perspectiveTransform\\n.   \\n.   \\n.   @note\\n.   -   A example on calculating a homography for image matching can be found at\\n.   opencv_source_code/samples/cpp/video_homography.cpp\"},\n  198:     {\"findNonZero\", (PyCFunction)pyopencv_cv_findNonZero, METH_VARARGS | METH_KEYWORDS, \"findNonZero(src[, idx]) -> idx\\n.   @brief Returns the list of locations of non-zero pixels\\n.   \\n.   Given a binary matrix (likely returned from an operation such\\n.   as threshold(), compare(), >, ==, etc, return all of\\n.   the non-zero indices as a cv::Mat or std::vector<cv::Point> (x,y)\\n.   For example:\\n.   @code{.cpp}\\n.   cv::Mat binaryImage; // input, binary image\\n.   cv::Mat locations;   // output, locations of non-zero pixels\\n.   cv::findNonZero(binaryImage, locations);\\n.   \\n.   // access pixel coordinates\\n.   Point pnt = locations.at<Point>(i);\\n.   @endcode\\n.   or\\n.   @code{.cpp}\\n.   cv::Mat binaryImage; // input, binary image\\n.   vector<Point> locations;   // output, locations of non-zero pixels\\n.   cv::findNonZero(binaryImage, locations);\\n.   \\n.   // access pixel coordinates\\n.   Point pnt = locations[i];\\n.   @endcode\\n.   @param src single-channel array (type CV_8UC1)\\n.   @param idx the output array, type of cv::Mat or std::vector<Point>, corresponding to non-zero indices in the input\"},\n  199      {\"findTransformECC\", (PyCFunction)pyopencv_cv_findTransformECC, METH_VARARGS | METH_KEYWORDS, \"findTransformECC(templateImage, inputImage, warpMatrix[, motionType[, criteria[, inputMask]]]) -> retval, warpMatrix\\n.   @brief Finds the geometric transform (warp) between two images in terms of the ECC criterion @cite EP08 .\\n.   \\n.   @param templateImage single-channel template image; CV_8U or CV_32F array.\\n.   @param inputImage single-channel input image which should be warped with the final warpMatrix in\\n.   order to provide an image similar to templateImage, same type as temlateImage.\\n.   @param warpMatrix floating-point \\\\f$2\\\\times 3\\\\f$ or \\\\f$3\\\\times 3\\\\f$ mapping matrix (warp).\\n.   @param motionType parameter, specifying the type of motion:\\n.   -   **MOTION_TRANSLATION** sets a translational motion model; warpMatrix is \\\\f$2\\\\times 3\\\\f$ with\\n.   the first \\\\f$2\\\\times 2\\\\f$ part being the unity matrix and the rest two parameters being\\n.   estimated.\\n.   -   **MOTION_EUCLIDEAN** sets a Euclidean (rigid) transformation as motion model; three\\n.   parameters are estimated; warpMatrix is \\\\f$2\\\\times 3\\\\f$.\\n.   -   **MOTION_AFFINE** sets an affine motion model (DEFAULT); six parameters are estimated;\\n.   warpMatrix is \\\\f$2\\\\times 3\\\\f$.\\n.   -   **MOTION_HOMOGRAPHY** sets a homography as a motion model; eight parameters are\\n.   estimated;\\\\`warpMatrix\\\\` is \\\\f$3\\\\times 3\\\\f$.\\n.   @param criteria parameter, specifying the termination criteria of the ECC algorithm;\\n.   criteria.epsilon defines the threshold of the increment in the correlation coefficient between two\\n.   iterations (a negative criteria.epsilon makes criteria.maxcount the only termination criterion).\\n.   Default values are shown in the declaration above.\\n.   @param inputMask An optional mask to indicate valid values of inputImage.\\n.   \\n.   The function estimates the optimum transformation (warpMatrix) with respect to ECC criterion\\n.   (@cite EP08), that is\\n.   \\n.   \\\\f[\\\\texttt{warpMatrix} = \\\\texttt{warpMatrix} = \\\\arg\\\\max_{W} \\\\texttt{ECC}(\\\\texttt{templateImage}(x,y),\\\\texttt{inputImage}(x',y'))\\\\f]\\n.   \\n.   where\\n.   \\n.   \\\\f[\\\\begin{bmatrix} x' \\\\\\\\ y' \\\\end{bmatrix} = W \\\\cdot \\\\begin{bmatrix} x \\\\\\\\ y \\\\\\\\ 1 \\\\end{bmatrix}\\\\f]\\n.   \\n.   (the equation holds with homogeneous coordinates for homography). It returns the final enhanced\\n.   correlation coefficient, that is the correlation coefficient between the template image and the\\n.   final warped input image. When a \\\\f$3\\\\times 3\\\\f$ matrix is given with motionType =0, 1 or 2, the third\\n.   row is ignored.\\n.   \\n.   Unlike findHomography and estimateRigidTransform, the function findTransformECC implements an\\n.   area-based alignment that builds on intensity similarities. In essence, the function updates the\\n.   initial transformation that roughly aligns the images. If this information is missing, the identity\\n.   warp (unity matrix) is used as an initialization. Note that if images undergo strong\\n.   displacements/rotations, an initial transformation that roughly aligns the images is necessary\\n.   (e.g., a simple euclidean/similarity transform that allows for the images showing the same image\\n.   content approximately). Use inverse warping in the second image to take an image close to the first\\n.   one, i.e. use the flag WARP_INVERSE_MAP with warpAffine or warpPerspective. See also the OpenCV\\n.   sample image_alignment.cpp that demonstrates the use of the function. Note that the function throws\\n.   an exception if algorithm does not converges.\\n.   \\n.   @sa\\n.   estimateAffine2D, estimateAffinePartial2D, findHomography\"},\n  200      {\"fitEllipse\", (PyCFunction)pyopencv_cv_fitEllipse, METH_VARARGS | METH_KEYWORDS, \"fitEllipse(points) -> retval\\n.   @brief Fits an ellipse around a set of 2D points.\\n.   \\n.   The function calculates the ellipse that fits (in a least-squares sense) a set of 2D points best of\\n.   all. It returns the rotated rectangle in which the ellipse is inscribed. The first algorithm described by @cite Fitzgibbon95\\n.   is used. Developer should keep in mind that it is possible that the returned\\n.   ellipse/rotatedRect data contains negative indices, due to the data points being close to the\\n.   border of the containing Mat element.\\n.   \\n.   @param points Input 2D point set, stored in std::vector\\\\<\\\\> or Mat\"},\n  ...\n  227      {\"getValidDisparityROI\", (PyCFunction)pyopencv_cv_getValidDisparityROI, METH_VARARGS | METH_KEYWORDS, \"getValidDisparityROI(roi1, roi2, minDisparity, numberOfDisparities, SADWindowSize) -> retval\\n.\"},\n  228      {\"getWindowProperty\", (PyCFunction)pyopencv_cv_getWindowProperty, METH_VARARGS | METH_KEYWORDS, \"getWindowProperty(winname, prop_id) -> retval\\n.   @brief Provides parameters of a window.\\n.   \\n.   The function getWindowProperty returns properties of a window.\\n.   \\n.   @param winname Name of the window.\\n.   @param prop_id Window property to retrieve. The following operation flags are available: (cv::WindowPropertyFlags)\\n.   \\n.   @sa setWindowProperty\"},\n  229:     {\"goodFeaturesToTrack\", (PyCFunction)pyopencv_cv_goodFeaturesToTrack, METH_VARARGS | METH_KEYWORDS, \"goodFeaturesToTrack(image, maxCorners, qualityLevel, minDistance[, corners[, mask[, blockSize[, useHarrisDetector[, k]]]]]) -> corners\\n.   @brief Determines strong corners on an image.\\n.   \\n.   The function finds the most prominent corners in the image or in the specified image region, as\\n.   described in @cite Shi94\\n.   \\n.   -   Function calculates the corner quality measure at every source image pixel using the\\n.   cornerMinEigenVal or cornerHarris .\\n.   -   Function performs a non-maximum suppression (the local maximums in *3 x 3* neighborhood are\\n.   retained).\\n.   -   The corners with the minimal eigenvalue less than\\n.   \\\\f$\\\\texttt{qualityLevel} \\\\cdot \\\\max_{x,y} qualityMeasureMap(x,y)\\\\f$ are rejected.\\n.   -   The remaining corners are sorted by the quality measure in the descending order.\\n.   -   Function throws away each corner for which there is a stronger corner at a distance less than\\n.   maxDistance.\\n.   \\n.   The function can be used to initialize a point-based tracker of an object.\\n.   \\n.   @note If the function is called with different values A and B of the parameter qualityLevel , and\\n.   A \\\\> B, the vector of returned corners with qualityLevel=A will be the prefix of the output vector\\n.   with qualityLevel=B .\\n.   \\n.   @param image Input 8-bit or floating-point 32-bit, single-channel image.\\n.   @param corners Output vector of detected corners.\\n.   @param maxCorners Maximum number of corners to return. If there are more corners than are found,\\n.   the strongest of them is returned. `maxCorners <= 0` implies that no limit on the maximum is set\\n.   and all detected corners are returned.\\n.   @param qualityLevel Parameter characterizing the minimal accepted quality of image corners. The\\n.   parameter value is multiplied by the best corner quality measure, which is the minimal eigenvalue\\n.   (see cornerMinEigenVal ) or the Harris function response (see cornerHarris ). The corners with the\\n.   quality measure less than the product are rejected. For example, if the best corner has the\\n.   quality measure = 1500, and the qualityLevel=0.01 , then all the corners with the quality measure\\n.   less than 15 are rejected.\\n.   @param minDistance Minimum possible Euclidean distance between the returned corners.\\n.   @param mask Optional region of interest. If the image is not empty (it needs to have the type\\n.   CV_8UC1 and the same size as image ), it specifies the region in which the corners are detected.\\n.   @param blockSize Size of an average block for computing a derivative covariation matrix over each\\n.   pixel neighborhood. See cornerEigenValsAndVecs .\\n.   @param useHarrisDetector Parameter indicating whether to use a Harris detector (see cornerHarris)\\n.   or cornerMinEigenVal.\\n.   @param k Free parameter of the Harris detector.\\n.   \\n.   @sa  cornerMinEigenVal, cornerHarris, calcOpticalFlowPyrLK, estimateRigidTransform,\\n\\n\\n\\ngoodFeaturesToTrack(image, maxCorners, qualityLevel, minDistance, mask, blockSize, gradientSize[, corners[, useHarrisDetector[, k]]]) -> corners\\n.\"},\n  230      {\"grabCut\", (PyCFunction)pyopencv_cv_grabCut, METH_VARARGS | METH_KEYWORDS, \"grabCut(img, mask, rect, bgdModel, fgdModel, iterCount[, mode]) -> mask, bgdModel, fgdModel\\n.   @brief Runs the GrabCut algorithm.\\n.   \\n.   The function implements the [GrabCut image segmentation algorithm](http://en.wikipedia.org/wiki/GrabCut).\\n.   \\n.   @param img Input 8-bit 3-channel image.\\n.   @param mask Input/output 8-bit single-channel mask. The mask is initialized by the function when\\n.   mode is set to GC_INIT_WITH_RECT. Its elements may have one of the cv::GrabCutClasses.\\n.   @param rect ROI containing a segmented object. The pixels outside of the ROI are marked as\\n.   \\\"obvious background\\\". The parameter is only used when mode==GC_INIT_WITH_RECT .\\n.   @param bgdModel Temporary array for the background model. Do not modify it while you are\\n.   processing the same image.\\n.   @param fgdModel Temporary arrays for the foreground model. Do not modify it while you are\\n.   processing the same image.\\n.   @param iterCount Number of iterations the algorithm should make before returning the result. Note\\n.   that the result can be refined with further calls with mode==GC_INIT_WITH_MASK or\\n.   mode==GC_EVAL .\\n.   @param mode Operation mode that could be one of the cv::GrabCutModes\"},\n  231      {\"groupRectangles\", (PyCFunction)pyopencv_cv_groupRectangles, METH_VARARGS | METH_KEYWORDS, \"groupRectangles(rectList, groupThreshold[, eps]) -> rectList, weights\\n.   @overload\"},\n  232      {\"haveOpenVX\", (PyCFunction)pyopencv_cv_haveOpenVX, METH_VARARGS | METH_KEYWORDS, \"haveOpenVX() -> retval\\n.\"},\n  233:     {\"hconcat\", (PyCFunction)pyopencv_cv_hconcat, METH_VARARGS | METH_KEYWORDS, \"hconcat(src[, dst]) -> dst\\n.   @overload\\n.   @code{.cpp}\\n.   std::vector<cv::Mat> matrices = { cv::Mat(4, 1, CV_8UC1, cv::Scalar(1)),\\n.   cv::Mat(4, 1, CV_8UC1, cv::Scalar(2)),\\n.   cv::Mat(4, 1, CV_8UC1, cv::Scalar(3)),};\\n.   \\n.   cv::Mat out;\\n.   cv::hconcat( matrices, out );\\n.   //out:\\n.   //[1, 2, 3;\\n.   // 1, 2, 3;\\n.   // 1, 2, 3;\\n.   // 1, 2, 3]\\n.   @endcode\\n.   @param src input array or vector of matrices. all of the matrices must have the same number of rows and the same depth.\\n.   @param dst output array. It has the same number of rows and depth as the src, and the sum of cols of the src.\\n.   same depth.\"},\n  234      {\"idct\", (PyCFunction)pyopencv_cv_idct, METH_VARARGS | METH_KEYWORDS, \"idct(src[, dst[, flags]]) -> dst\\n.   @brief Calculates the inverse Discrete Cosine Transform of a 1D or 2D array.\\n.   \\n.   idct(src, dst, flags) is equivalent to dct(src, dst, flags | DCT_INVERSE).\\n.   @param src input floating-point single-channel array.\\n.   @param dst output array of the same size and type as src.\\n.   @param flags operation flags.\\n.   @sa  dct, dft, idft, getOptimalDFTSize\"},\n  235      {\"idft\", (PyCFunction)pyopencv_cv_idft, METH_VARARGS | METH_KEYWORDS, \"idft(src[, dst[, flags[, nonzeroRows]]]) -> dst\\n.   @brief Calculates the inverse Discrete Fourier Transform of a 1D or 2D array.\\n.   \\n.   idft(src, dst, flags) is equivalent to dft(src, dst, flags | DFT_INVERSE) .\\n.   @note None of dft and idft scales the result by default. So, you should pass DFT_SCALE to one of\\n.   dft or idft explicitly to make these transforms mutually inverse.\\n.   @sa dft, dct, idct, mulSpectrums, getOptimalDFTSize\\n.   @param src input floating-point real or complex array.\\n.   @param dst output array whose size and type depend on the flags.\\n.   @param flags operation flags (see dft and cv::DftFlags).\\n.   @param nonzeroRows number of dst rows to process; the rest of the rows have undefined content (see\\n.   the convolution sample in dft description.\"},\n  ...\n  282      {\"multiply\", (PyCFunction)pyopencv_cv_multiply, METH_VARARGS | METH_KEYWORDS, \"multiply(src1, src2[, dst[, scale[, dtype]]]) -> dst\\n.   @brief Calculates the per-element scaled product of two arrays.\\n.   \\n.   The function multiply calculates the per-element product of two arrays:\\n.   \\n.   \\\\f[\\\\texttt{dst} (I)= \\\\texttt{saturate} ( \\\\texttt{scale} \\\\cdot \\\\texttt{src1} (I)  \\\\cdot \\\\texttt{src2} (I))\\\\f]\\n.   \\n.   There is also a @ref MatrixExpressions -friendly variant of the first function. See Mat::mul .\\n.   \\n.   For a not-per-element matrix product, see gemm .\\n.   \\n.   @note Saturation is not applied when the output array has the depth\\n.   CV_32S. You may even get result of an incorrect sign in the case of\\n.   overflow.\\n.   @param src1 first input array.\\n.   @param src2 second input array of the same size and the same type as src1.\\n.   @param dst output array of the same size and type as src1.\\n.   @param scale optional scale factor.\\n.   @param dtype optional depth of the output array\\n.   @sa add, subtract, divide, scaleAdd, addWeighted, accumulate, accumulateProduct, accumulateSquare,\\n.   Mat::convertTo\"},\n  283      {\"namedWindow\", (PyCFunction)pyopencv_cv_namedWindow, METH_VARARGS | METH_KEYWORDS, \"namedWindow(winname[, flags]) -> None\\n.   @brief Creates a window.\\n.   \\n.   The function namedWindow creates a window that can be used as a placeholder for images and\\n.   trackbars. Created windows are referred to by their names.\\n.   \\n.   If a window with the same name already exists, the function does nothing.\\n.   \\n.   You can call cv::destroyWindow or cv::destroyAllWindows to close the window and de-allocate any associated\\n.   memory usage. For a simple program, you do not really have to call these functions because all the\\n.   resources and windows of the application are closed automatically by the operating system upon exit.\\n.   \\n.   @note\\n.   \\n.   Qt backend supports additional flags:\\n.   -   **WINDOW_NORMAL or WINDOW_AUTOSIZE:** WINDOW_NORMAL enables you to resize the\\n.   window, whereas WINDOW_AUTOSIZE adjusts automatically the window size to fit the\\n.   displayed image (see imshow ), and you cannot change the window size manually.\\n.   -   **WINDOW_FREERATIO or WINDOW_KEEPRATIO:** WINDOW_FREERATIO adjusts the image\\n.   with no respect to its ratio, whereas WINDOW_KEEPRATIO keeps the image ratio.\\n.   -   **WINDOW_GUI_NORMAL or WINDOW_GUI_EXPANDED:** WINDOW_GUI_NORMAL is the old way to draw the window\\n.   without statusbar and toolbar, whereas WINDOW_GUI_EXPANDED is a new enhanced GUI.\\n.   By default, flags == WINDOW_AUTOSIZE | WINDOW_KEEPRATIO | WINDOW_GUI_EXPANDED\\n.   \\n.   @param winname Name of the window in the window caption that may be used as a window identifier.\\n.   @param flags Flags of the window. The supported flags are: (cv::WindowFlags)\"},\n  284:     {\"norm\", (PyCFunction)pyopencv_cv_norm, METH_VARARGS | METH_KEYWORDS, \"norm(src1[, normType[, mask]]) -> retval\\n.   @brief Calculates the  absolute norm of an array.\\n.   \\n.   This version of cv::norm calculates the absolute norm of src1. The type of norm to calculate is specified using cv::NormTypes.\\n.   \\n.   As example for one array consider the function \\\\f$r(x)= \\\\begin{pmatrix} x \\\\\\\\ 1-x \\\\end{pmatrix}, x \\\\in [-1;1]\\\\f$.\\n.   The \\\\f$ L_{1}, L_{2} \\\\f$ and \\\\f$ L_{\\\\infty} \\\\f$ norm for the sample value \\\\f$r(-1) = \\\\begin{pmatrix} -1 \\\\\\\\ 2 \\\\end{pmatrix}\\\\f$\\n.   is calculated as follows\\n.   \\\\f{align*}\\n.   \\\\| r(-1) \\\\|_{L_1} &= |-1| + |2| = 3 \\\\\\\\\\n.   \\\\| r(-1) \\\\|_{L_2} &= \\\\sqrt{(-1)^{2} + (2)^{2}} = \\\\sqrt{5} \\\\\\\\\\n.   \\\\| r(-1) \\\\|_{L_\\\\infty} &= \\\\max(|-1|,|2|) = 2\\n.   \\\\f}\\n.   and for \\\\f$r(0.5) = \\\\begin{pmatrix} 0.5 \\\\\\\\ 0.5 \\\\end{pmatrix}\\\\f$ the calculation is\\n.   \\\\f{align*}\\n.   \\\\| r(0.5) \\\\|_{L_1} &= |0.5| + |0.5| = 1 \\\\\\\\\\n.   \\\\| r(0.5) \\\\|_{L_2} &= \\\\sqrt{(0.5)^{2} + (0.5)^{2}} = \\\\sqrt{0.5} \\\\\\\\\\n.   \\\\| r(0.5) \\\\|_{L_\\\\infty} &= \\\\max(|0.5|,|0.5|) = 0.5.\\n.   \\\\f}\\n.   The following graphic shows all values for the three norm functions \\\\f$\\\\| r(x) \\\\|_{L_1}, \\\\| r(x) \\\\|_{L_2}\\\\f$ and \\\\f$\\\\| r(x) \\\\|_{L_\\\\infty}\\\\f$.\\n.   It is notable that the \\\\f$ L_{1} \\\\f$ norm forms the upper and the \\\\f$ L_{\\\\infty} \\\\f$ norm forms the lower border for the example function \\\\f$ r(x) \\\\f$.\\n.   ![Graphs for the different norm functions from the above example](pics/NormTypes_OneArray_1-2-INF.png)\\n.   \\n.   When the mask parameter is specified and it is not empty, the norm is\\n.   \\n.   If normType is not specified, NORM_L2 is used.\\n.   calculated only over the region specified by the mask.\\n.   \\n.   Multi-channel input arrays are treated as single-channel arrays, that is,\\n.   the results for all channels are combined.\\n.   \\n.   Hamming norms can only be calculated with CV_8U depth arrays.\\n.   \\n.   @param src1 first input array.\\n.   @param normType type of the norm (see cv::NormTypes).\\n.   @param mask optional operation mask; it must have the same size as src1 and CV_8UC1 type.\\n\\n\\n\\nnorm(src1, src2[, normType[, mask]]) -> retval\\n.   @brief Calculates an absolute difference norm or a relative difference norm.\\n.   \\n.   This version of cv::norm calculates the absolute difference norm\\n.   or the relative difference norm of arrays src1 and src2.\\n.   The type of norm to calculate is specified using cv::NormTypes.\\n.   \\n.   @param src1 first input array.\\n.   @param src2 second input array of the same size and the same type as src1.\\n.   @param normType type of the norm (cv::NormTypes).\\n.   @param mask optional operation mask; it must have the same size as src1 and CV_8UC1 type.\"},\n  285      {\"normalize\", (PyCFunction)pyopencv_cv_normalize, METH_VARARGS | METH_KEYWORDS, \"normalize(src, dst[, alpha[, beta[, norm_type[, dtype[, mask]]]]]) -> dst\\n.   @brief Normalizes the norm or value range of an array.\\n.   \\n.   The function cv::normalize normalizes scale and shift the input array elements so that\\n.   \\\\f[\\\\| \\\\texttt{dst} \\\\| _{L_p}= \\\\texttt{alpha}\\\\f]\\n.   (where p=Inf, 1 or 2) when normType=NORM_INF, NORM_L1, or NORM_L2, respectively; or so that\\n.   \\\\f[\\\\min _I  \\\\texttt{dst} (I)= \\\\texttt{alpha} , \\\\, \\\\, \\\\max _I  \\\\texttt{dst} (I)= \\\\texttt{beta}\\\\f]\\n.   \\n.   when normType=NORM_MINMAX (for dense arrays only). The optional mask specifies a sub-array to be\\n.   normalized. This means that the norm or min-n-max are calculated over the sub-array, and then this\\n.   sub-array is modified to be normalized. If you want to only use the mask to calculate the norm or\\n.   min-max but modify the whole array, you can use norm and Mat::convertTo.\\n.   \\n.   In case of sparse matrices, only the non-zero values are analyzed and transformed. Because of this,\\n.   the range transformation for sparse matrices is not allowed since it can shift the zero level.\\n.   \\n.   Possible usage with some positive example data:\\n.   @code{.cpp}\\n.   vector<double> positiveData = { 2.0, 8.0, 10.0 };\\n.   vector<double> normalizedData_l1, normalizedData_l2, normalizedData_inf, normalizedData_minmax;\\n.   \\n.   // Norm to probability (total count)\\n.   // sum(numbers) = 20.0\\n.   // 2.0      0.1     (2.0/20.0)\\n.   // 8.0      0.4     (8.0/20.0)\\n.   // 10.0     0.5     (10.0/20.0)\\n.   normalize(positiveData, normalizedData_l1, 1.0, 0.0, NORM_L1);\\n.   \\n.   // Norm to unit vector: ||positiveData|| = 1.0\\n.   // 2.0      0.15\\n.   // 8.0      0.62\\n.   // 10.0     0.77\\n.   normalize(positiveData, normalizedData_l2, 1.0, 0.0, NORM_L2);\\n.   \\n.   // Norm to max element\\n.   // 2.0      0.2     (2.0/10.0)\\n.   // 8.0      0.8     (8.0/10.0)\\n.   // 10.0     1.0     (10.0/10.0)\\n.   normalize(positiveData, normalizedData_inf, 1.0, 0.0, NORM_INF);\\n.   \\n.   // Norm to range [0.0;1.0]\\n.   // 2.0      0.0     (shift to left border)\\n.   // 8.0      0.75    (6.0/8.0)\\n.   // 10.0     1.0     (shift to right border)\\n.   normalize(positiveData, normalizedData_minmax, 1.0, 0.0, NORM_MINMAX);\\n.   @endcode\\n.   \\n.   @param src input array.\\n.   @param dst output array of the same size as src .\\n.   @param alpha norm value to normalize to or the lower range boundary in case of the range\\n.   normalization.\\n.   @param beta upper range boundary in case of the range normalization; it is not used for the norm\\n.   normalization.\\n.   @param norm_type normalization type (see cv::NormTypes).\\n.   @param dtype when negative, the output array has the same type as src; otherwise, it has the same\\n.   number of channels as src and the depth =CV_MAT_DEPTH(dtype).\\n.   @param mask optional operation mask.\\n.   @sa norm, Mat::convertTo, SparseMat::convertTo\"},\n  286      {\"patchNaNs\", (PyCFunction)pyopencv_cv_patchNaNs, METH_VARARGS | METH_KEYWORDS, \"patchNaNs(a[, val]) -> a\\n.   @brief converts NaN's to the given number\"},\n  ...\n  361      {\"useOptimized\", (PyCFunction)pyopencv_cv_useOptimized, METH_VARARGS | METH_KEYWORDS, \"useOptimized() -> retval\\n.   @brief Returns the status of optimized code usage.\\n.   \\n.   The function returns true if the optimized code is enabled. Otherwise, it returns false.\"},\n  362      {\"validateDisparity\", (PyCFunction)pyopencv_cv_validateDisparity, METH_VARARGS | METH_KEYWORDS, \"validateDisparity(disparity, cost, minDisparity, numberOfDisparities[, disp12MaxDisp]) -> disparity\\n.\"},\n  363:     {\"vconcat\", (PyCFunction)pyopencv_cv_vconcat, METH_VARARGS | METH_KEYWORDS, \"vconcat(src[, dst]) -> dst\\n.   @overload\\n.   @code{.cpp}\\n.   std::vector<cv::Mat> matrices = { cv::Mat(1, 4, CV_8UC1, cv::Scalar(1)),\\n.   cv::Mat(1, 4, CV_8UC1, cv::Scalar(2)),\\n.   cv::Mat(1, 4, CV_8UC1, cv::Scalar(3)),};\\n.   \\n.   cv::Mat out;\\n.   cv::vconcat( matrices, out );\\n.   //out:\\n.   //[1,   1,   1,   1;\\n.   // 2,   2,   2,   2;\\n.   // 3,   3,   3,   3]\\n.   @endcode\\n.   @param src input array or vector of matrices. all of the matrices must have the same number of cols and the same depth\\n.   @param dst output array. It has the same number of cols and depth as the src, and the sum of rows of the src.\\n.   same depth.\"},\n  364      {\"waitKey\", (PyCFunction)pyopencv_cv_waitKey, METH_VARARGS | METH_KEYWORDS, \"waitKey([, delay]) -> retval\\n.   @brief Waits for a pressed key.\\n.   \\n.   The function waitKey waits for a key event infinitely (when \\\\f$\\\\texttt{delay}\\\\leq 0\\\\f$ ) or for delay\\n.   milliseconds, when it is positive. Since the OS has a minimum time between switching threads, the\\n.   function will not wait exactly delay ms, it will wait at least delay ms, depending on what else is\\n.   running on your computer at that time. It returns the code of the pressed key or -1 if no key was\\n.   pressed before the specified time had elapsed.\\n.   \\n.   @note\\n.   \\n.   This function is the only method in HighGUI that can fetch and handle events, so it needs to be\\n.   called periodically for normal event processing unless HighGUI is used within an environment that\\n.   takes care of event processing.\\n.   \\n.   @note\\n.   \\n.   The function only works if there is at least one HighGUI window created and the window is active.\\n.   If there are several HighGUI windows, any of them can be active.\\n.   \\n.   @param delay Delay in milliseconds. 0 is the special value that means \\\"forever\\\".\"},\n  365      {\"waitKeyEx\", (PyCFunction)pyopencv_cv_waitKeyEx, METH_VARARGS | METH_KEYWORDS, \"waitKeyEx([, delay]) -> retval\\n.   @brief Similar to #waitKey, but returns full key code.\\n.   \\n.   @note\\n.   \\n.   Key code is implementation specific and depends on used backend: QT/GTK/Win32/etc\"},\n  ...\n 2144      {\"PHash_create\", (PyCFunction)pyopencv_cv_img_hash_PHash_create, METH_VARARGS | METH_KEYWORDS, \"PHash_create() -> retval\\n.\"},\n 2145      {\"RadialVarianceHash_create\", (PyCFunction)pyopencv_cv_img_hash_RadialVarianceHash_create, METH_VARARGS | METH_KEYWORDS, \"RadialVarianceHash_create([, sigma[, numOfAngleLine]]) -> retval\\n.\"},\n 2146:     {\"averageHash\", (PyCFunction)pyopencv_cv_img_hash_averageHash, METH_VARARGS | METH_KEYWORDS, \"averageHash(inputArr[, outputArr]) -> outputArr\\n.   @brief Calculates img_hash::AverageHash in one call\\n.   @param inputArr input image want to compute hash value, type should be CV_8UC4, CV_8UC3 or CV_8UC1.\\n.   @param outputArr Hash value of input, it will contain 16 hex decimal number, return type is CV_8U\"},\n 2147:     {\"blockMeanHash\", (PyCFunction)pyopencv_cv_img_hash_blockMeanHash, METH_VARARGS | METH_KEYWORDS, \"blockMeanHash(inputArr[, outputArr[, mode]]) -> outputArr\\n.   @brief Computes block mean hash of the input image\\n.   @param inputArr input image want to compute hash value, type should be CV_8UC4, CV_8UC3 or CV_8UC1.\\n.   @param outputArr Hash value of input, it will contain 16 hex decimal number, return type is CV_8U\\n.   @param mode\"},\n 2148:     {\"colorMomentHash\", (PyCFunction)pyopencv_cv_img_hash_colorMomentHash, METH_VARARGS | METH_KEYWORDS, \"colorMomentHash(inputArr[, outputArr]) -> outputArr\\n.   @brief Computes color moment hash of the input, the algorithm\\n.   is come from the paper \\\"Perceptual  Hashing  for  Color  Images\\n.   Using  Invariant Moments\\\"\\n.   @param inputArr input image want to compute hash value,\\n.   type should be CV_8UC4, CV_8UC3 or CV_8UC1.\\n.   @param outputArr 42 hash values with type CV_64F(double)\"},\n 2149:     {\"marrHildrethHash\", (PyCFunction)pyopencv_cv_img_hash_marrHildrethHash, METH_VARARGS | METH_KEYWORDS, \"marrHildrethHash(inputArr[, outputArr[, alpha[, scale]]]) -> outputArr\\n.   @brief Computes average hash value of the input image\\n.   @param inputArr input image want to compute hash value,\\n.   type should be CV_8UC4, CV_8UC3, CV_8UC1.\\n.   @param outputArr Hash value of input, it will contain 16 hex\\n.   decimal number, return type is CV_8U\\n.   @param alpha int scale factor for marr wavelet (default=2).\\n.   @param scale int level of scale factor (default = 1)\"},\n 2150:     {\"pHash\", (PyCFunction)pyopencv_cv_img_hash_pHash, METH_VARARGS | METH_KEYWORDS, \"pHash(inputArr[, outputArr]) -> outputArr\\n.   @brief Computes pHash value of the input image\\n.   @param inputArr input image want to compute hash value,\\n.   type should be CV_8UC4, CV_8UC3, CV_8UC1.\\n.   @param outputArr Hash value of input, it will contain 8 uchar value\"},\n 2151:     {\"radialVarianceHash\", (PyCFunction)pyopencv_cv_img_hash_radialVarianceHash, METH_VARARGS | METH_KEYWORDS, \"radialVarianceHash(inputArr[, outputArr[, sigma[, numOfAngleLine]]]) -> outputArr\\n.   @brief Computes radial variance hash of the input image\\n.   @param inputArr input image want to compute hash value,\\n.   type should be CV_8UC4, CV_8UC3, CV_8UC1.\\n.   @param outputArr Hash value of input\\n.   @param sigma Gaussian kernel standard deviation\\n.   @param numOfAngleLine The number of angles to consider\"},\n 2152      {NULL, NULL}\n 2153  };\n ....\n 2333  static PyMethodDef methods_motempl[] = {\n 2334      {\"calcGlobalOrientation\", (PyCFunction)pyopencv_cv_motempl_calcGlobalOrientation, METH_VARARGS | METH_KEYWORDS, \"calcGlobalOrientation(orientation, mask, mhi, timestamp, duration) -> retval\\n.   @brief Calculates a global motion orientation in a selected region.\\n.   \\n.   @param orientation Motion gradient orientation image calculated by the function calcMotionGradient\\n.   @param mask Mask image. It may be a conjunction of a valid gradient mask, also calculated by\\n.   calcMotionGradient , and the mask of a region whose direction needs to be calculated.\\n.   @param mhi Motion history image calculated by updateMotionHistory .\\n.   @param timestamp Timestamp passed to updateMotionHistory .\\n.   @param duration Maximum duration of a motion track in milliseconds, passed to updateMotionHistory\\n.   \\n.   The function calculates an average motion direction in the selected region and returns the angle\\n.   between 0 degrees and 360 degrees. The average direction is computed from the weighted orientation\\n.   histogram, where a recent motion has a larger weight and the motion occurred in the past has a\\n.   smaller weight, as recorded in mhi .\"},\n 2335:     {\"calcMotionGradient\", (PyCFunction)pyopencv_cv_motempl_calcMotionGradient, METH_VARARGS | METH_KEYWORDS, \"calcMotionGradient(mhi, delta1, delta2[, mask[, orientation[, apertureSize]]]) -> mask, orientation\\n.   @brief Calculates a gradient orientation of a motion history image.\\n.   \\n.   @param mhi Motion history single-channel floating-point image.\\n.   @param mask Output mask image that has the type CV_8UC1 and the same size as mhi . Its non-zero\\n.   elements mark pixels where the motion gradient data is correct.\\n.   @param orientation Output motion gradient orientation image that has the same type and the same\\n.   size as mhi . Each pixel of the image is a motion orientation, from 0 to 360 degrees.\\n.   @param delta1 Minimal (or maximal) allowed difference between mhi values within a pixel\\n.   neighborhood.\\n.   @param delta2 Maximal (or minimal) allowed difference between mhi values within a pixel\\n.   neighborhood. That is, the function finds the minimum ( \\\\f$m(x,y)\\\\f$ ) and maximum ( \\\\f$M(x,y)\\\\f$ ) mhi\\n.   values over \\\\f$3 \\\\times 3\\\\f$ neighborhood of each pixel and marks the motion orientation at \\\\f$(x, y)\\\\f$\\n.   as valid only if\\n.   \\\\f[\\\\min ( \\\\texttt{delta1}  ,  \\\\texttt{delta2}  )  \\\\le  M(x,y)-m(x,y)  \\\\le   \\\\max ( \\\\texttt{delta1}  , \\\\texttt{delta2} ).\\\\f]\\n.   @param apertureSize Aperture size of the Sobel operator.\\n.   \\n.   The function calculates a gradient orientation at each pixel \\\\f$(x, y)\\\\f$ as:\\n.   \\n.   \\\\f[\\\\texttt{orientation} (x,y)= \\\\arctan{\\\\frac{d\\\\texttt{mhi}/dy}{d\\\\texttt{mhi}/dx}}\\\\f]\\n.   \\n.   In fact, fastAtan2 and phase are used so that the computed angle is measured in degrees and covers\\n.   the full range 0..360. Also, the mask is filled to indicate pixels where the computed angle is\\n.   valid.\\n.   \\n.   @note\\n.   -   (Python) An example on how to perform a motion template technique can be found at\\n.   opencv_source_code/samples/python2/motempl.py\"},\n 2336      {\"segmentMotion\", (PyCFunction)pyopencv_cv_motempl_segmentMotion, METH_VARARGS | METH_KEYWORDS, \"segmentMotion(mhi, timestamp, segThresh[, segmask]) -> segmask, boundingRects\\n.   @brief Splits a motion history image into a few parts corresponding to separate independent motions (for\\n.   example, left hand, right hand).\\n.   \\n.   @param mhi Motion history image.\\n.   @param segmask Image where the found mask should be stored, single-channel, 32-bit floating-point.\\n.   @param boundingRects Vector containing ROIs of motion connected components.\\n.   @param timestamp Current time in milliseconds or other units.\\n.   @param segThresh Segmentation threshold that is recommended to be equal to the interval between\\n.   motion history \\\"steps\\\" or greater.\\n.   \\n.   The function finds all of the motion segments and marks them in segmask with individual values\\n.   (1,2,...). It also computes a vector with ROIs of motion connected components. After that the motion\\n.   direction for every component can be calculated with calcGlobalOrientation using the extracted mask\\n.   of the particular component.\"},\n 2337      {\"updateMotionHistory\", (PyCFunction)pyopencv_cv_motempl_updateMotionHistory, METH_VARARGS | METH_KEYWORDS, \"updateMotionHistory(silhouette, mhi, timestamp, duration) -> mhi\\n.   @brief Updates the motion history image by a moving silhouette.\\n.   \\n.   @param silhouette Silhouette mask that has non-zero pixels where the motion occurs.\\n.   @param mhi Motion history image that is updated by the function (single-channel, 32-bit\\n.   floating-point).\\n.   @param timestamp Current time in milliseconds or other units.\\n.   @param duration Maximal duration of the motion track in the same units as timestamp .\\n.   \\n.   The function updates the motion history image as follows:\\n.   \\n.   \\\\f[\\\\texttt{mhi} (x,y)= \\\\forkthree{\\\\texttt{timestamp}}{if \\\\(\\\\texttt{silhouette}(x,y) \\\\ne 0\\\\)}{0}{if \\\\(\\\\texttt{silhouette}(x,y) = 0\\\\) and \\\\(\\\\texttt{mhi} < (\\\\texttt{timestamp} - \\\\texttt{duration})\\\\)}{\\\\texttt{mhi}(x,y)}{otherwise}\\\\f]\\n.   \\n.   That is, MHI pixels where the motion occurs are set to the current timestamp , while the pixels\\n.   where the motion happened last time a long time ago are cleared.\\n.   \\n.   The function, together with calcMotionGradient and calcGlobalOrientation , implements a motion\\n.   templates technique described in @cite Davis97 and @cite Bradski00 .\"},\n ....\n 2587      {\"registerDepth\", (PyCFunction)pyopencv_cv_rgbd_registerDepth, METH_VARARGS | METH_KEYWORDS, \"registerDepth(unregisteredCameraMatrix, registeredCameraMatrix, registeredDistCoeffs, Rt, unregisteredDepth, outputImagePlaneSize[, registeredDepth[, depthDilation]]) -> registeredDepth\\n.   Registers depth data to an external camera\\n.   * Registration is performed by creating a depth cloud, transforming the cloud by\\n.   * the rigid body transformation between the cameras, and then projecting the\\n.   * transformed points into the RGB camera.\\n.   *\\n.   * uv_rgb = K_rgb * [R | t] * z * inv(K_ir) * uv_ir\\n.   *\\n.   * Currently does not check for negative depth values.\\n.   *\\n.   * @param unregisteredCameraMatrix the camera matrix of the depth camera\\n.   * @param registeredCameraMatrix the camera matrix of the external camera\\n.   * @param registeredDistCoeffs the distortion coefficients of the external camera\\n.   * @param Rt the rigid body transform between the cameras. Transforms points from depth camera frame to external camera frame.\\n.   * @param unregisteredDepth the input depth data\\n.   * @param outputImagePlaneSize the image plane dimensions of the external camera (width, height)\\n.   * @param registeredDepth the result of transforming the depth into the external camera\\n.   * @param depthDilation whether or not the depth is dilated to avoid holes and occlusion errors (optional)\"},\n 2588      {\"rescaleDepth\", (PyCFunction)pyopencv_cv_rgbd_rescaleDepth, METH_VARARGS | METH_KEYWORDS, \"rescaleDepth(in, depth[, out]) -> out\\n.   If the input image is of type CV_16UC1 (like the Kinect one), the image is converted to floats, divided\\n.   * by 1000 to get a depth in meters, and the values 0 are converted to std::numeric_limits<float>::quiet_NaN()\\n.   * Otherwise, the image is simply converted to floats\\n.   * @param in the depth image (if given as short int CV_U, it is assumed to be the depth in millimeters\\n.   *              (as done with the Microsoft Kinect), it is assumed in meters)\\n.   * @param depth the desired output depth (floats or double)\\n.   * @param out The rescaled float depth image\"},\n 2589:     {\"warpFrame\", (PyCFunction)pyopencv_cv_rgbd_warpFrame, METH_VARARGS | METH_KEYWORDS, \"warpFrame(image, depth, mask, Rt, cameraMatrix, distCoeff[, warpedImage[, warpedDepth[, warpedMask]]]) -> warpedImage, warpedDepth, warpedMask\\n.   Warp the image: compute 3d points from the depth, transform them using given transformation,\\n.   * then project color point cloud to an image plane.\\n.   * This function can be used to visualize results of the Odometry algorithm.\\n.   * @param image The image (of CV_8UC1 or CV_8UC3 type)\\n.   * @param depth The depth (of type used in depthTo3d fuction)\\n.   * @param mask The mask of used pixels (of CV_8UC1), it can be empty\\n.   * @param Rt The transformation that will be applied to the 3d points computed from the depth\\n.   * @param cameraMatrix Camera matrix\\n.   * @param distCoeff Distortion coefficients\\n.   * @param warpedImage The warped image.\\n.   * @param warpedDepth The warped depth.\\n.   * @param warpedMask The warped mask.\"},\n 2590      {NULL, NULL}\n 2591  };\n ....\n 2652      {\"createERFilterNM2\", (PyCFunction)pyopencv_cv_text_createERFilterNM2, METH_VARARGS | METH_KEYWORDS, \"createERFilterNM2(cb[, minProbability]) -> retval\\n.   @brief Create an Extremal Region Filter for the 2nd stage classifier of N&M algorithm @cite Neumann12.\\n.   \\n.   @param  cb :   Callback with the classifier. Default classifier can be implicitly load with function\\n.   loadClassifierNM2, e.g. from file in samples/cpp/trained_classifierNM2.xml\\n.   @param  minProbability :   The minimum probability P(er|character) allowed for retreived ER's\\n.   \\n.   In the second stage, the ERs that passed the first stage are classified into character and\\n.   non-character classes using more informative but also more computationally expensive features. The\\n.   classifier uses all the features calculated in the first stage and the following additional\\n.   features: hole area ratio, convex hull ratio, and number of outer inflexion points.\\n\\n\\n\\ncreateERFilterNM2(filename[, minProbability]) -> retval\\n.   @brief Reads an Extremal Region Filter for the 2nd stage classifier of N&M algorithm\\n.   from the provided path e.g. /path/to/cpp/trained_classifierNM2.xml\\n.   \\n.   @overload\"},\n 2653      {\"createOCRHMMTransitionsTable\", (PyCFunction)pyopencv_cv_text_createOCRHMMTransitionsTable, METH_VARARGS | METH_KEYWORDS, \"createOCRHMMTransitionsTable(vocabulary, lexicon) -> retval\\n.   @brief Utility function to create a tailored language model transitions table from a given list of words (lexicon).\\n.   *\\n.   * @param vocabulary The language vocabulary (chars when ASCII English text).\\n.   *\\n.   * @param lexicon The list of words that are expected to be found in a particular image.\\n.   *\\n.   * @param transition_probabilities_table Output table with transition probabilities between character pairs. cols == rows == vocabulary.size().\\n.   *\\n.   * The function calculate frequency statistics of character pairs from the given lexicon and fills the output transition_probabilities_table with them. The transition_probabilities_table can be used as input in the OCRHMMDecoder::create() and OCRBeamSearchDecoder::create() methods.\\n.   * @note\\n.   *    -   (C++) An alternative would be to load the default generic language transition table provided in the text module samples folder (created from ispell 42869 english words list) :\\n.   *            <https://github.com/opencv/opencv_contrib/blob/master/modules/text/samples/OCRHMM_transitions_table.xml>\\n.   *\"},\n 2654:     {\"detectRegions\", (PyCFunction)pyopencv_cv_text_detectRegions, METH_VARARGS | METH_KEYWORDS, \"detectRegions(image, er_filter1, er_filter2) -> regions\\n.   @brief Converts MSER contours (vector\\\\<Point\\\\>) to ERStat regions.\\n.   \\n.   @param image Source image CV_8UC1 from which the MSERs where extracted.\\n.   \\n.   @param contours Input vector with all the contours (vector\\\\<Point\\\\>).\\n.   \\n.   @param regions Output where the ERStat regions are stored.\\n.   \\n.   It takes as input the contours provided by the OpenCV MSER feature detector and returns as output\\n.   two vectors of ERStats. This is because MSER() output contains both MSER+ and MSER- regions in a\\n.   single vector\\\\<Point\\\\>, the function separates them in two different vectors (this is as if the\\n.   ERStats where extracted from two different channels).\\n.   \\n.   An example of MSERsToERStats in use can be found in the text detection webcam_demo:\\n.   <https://github.com/opencv/opencv_contrib/blob/master/modules/text/samples/webcam_demo.cpp>\\n\\n\\n\\ndetectRegions(image, er_filter1, er_filter2[, method[, filename[, minProbability]]]) -> groups_rects\\n.   @brief Extracts text regions from image.\\n.   \\n.   @param image Source image where text blocks needs to be extracted from.  Should be CV_8UC3 (color).\\n.   @param er_filter1 Extremal Region Filter for the 1st stage classifier of N&M algorithm @cite Neumann12\\n.   @param er_filter2 Extremal Region Filter for the 2nd stage classifier of N&M algorithm @cite Neumann12\\n.   @param groups_rects Output list of rectangle blocks with text\\n.   @param method Grouping method (see text::erGrouping_Modes). Can be one of ERGROUPING_ORIENTATION_HORIZ, ERGROUPING_ORIENTATION_ANY.\\n.   @param filename The XML or YAML file with the classifier model (e.g. samples/trained_classifier_erGrouping.xml). Only to use when grouping method is ERGROUPING_ORIENTATION_ANY.\\n.   @param minProbability The minimum probability for accepting a group. Only to use when grouping method is ERGROUPING_ORIENTATION_ANY.\"},\n 2655:     {\"erGrouping\", (PyCFunction)pyopencv_cv_text_erGrouping, METH_VARARGS | METH_KEYWORDS, \"erGrouping(image, channel, regions[, method[, filename[, minProbablity]]]) -> groups_rects\\n.   @brief Find groups of Extremal Regions that are organized as text blocks.\\n.   \\n.   @param img Original RGB or Greyscale image from wich the regions were extracted.\\n.   \\n.   @param channels Vector of single channel images CV_8UC1 from wich the regions were extracted.\\n.   \\n.   @param regions Vector of ER's retrieved from the ERFilter algorithm from each channel.\\n.   \\n.   @param groups The output of the algorithm is stored in this parameter as set of lists of indexes to\\n.   provided regions.\\n.   \\n.   @param groups_rects The output of the algorithm are stored in this parameter as list of rectangles.\\n.   \\n.   @param method Grouping method (see text::erGrouping_Modes). Can be one of ERGROUPING_ORIENTATION_HORIZ,\\n.   ERGROUPING_ORIENTATION_ANY.\\n.   \\n.   @param filename The XML or YAML file with the classifier model (e.g.\\n.   samples/trained_classifier_erGrouping.xml). Only to use when grouping method is\\n.   ERGROUPING_ORIENTATION_ANY.\\n.   \\n.   @param minProbablity The minimum probability for accepting a group. Only to use when grouping\\n.   method is ERGROUPING_ORIENTATION_ANY.\"},\n 2656      {\"loadClassifierNM1\", (PyCFunction)pyopencv_cv_text_loadClassifierNM1, METH_VARARGS | METH_KEYWORDS, \"loadClassifierNM1(filename) -> retval\\n.   @brief Allow to implicitly load the default classifier when creating an ERFilter object.\\n.   \\n.   @param filename The XML or YAML file with the classifier model (e.g. trained_classifierNM1.xml)\\n.   \\n.   returns a pointer to ERFilter::Callback.\"},\n 2657      {\"loadClassifierNM2\", (PyCFunction)pyopencv_cv_text_loadClassifierNM2, METH_VARARGS | METH_KEYWORDS, \"loadClassifierNM2(filename) -> retval\\n.   @brief Allow to implicitly load the default classifier when creating an ERFilter object.\\n.   \\n.   @param filename The XML or YAML file with the classifier model (e.g. trained_classifierNM2.xml)\\n.   \\n.   returns a pointer to ERFilter::Callback.\"},\n ....\n 2768      {\"AdaptiveManifoldFilter_create\", (PyCFunction)pyopencv_cv_ximgproc_AdaptiveManifoldFilter_create, METH_VARARGS | METH_KEYWORDS, \"AdaptiveManifoldFilter_create() -> retval\\n.\"},\n 2769      {\"PeiLinNormalization\", (PyCFunction)pyopencv_cv_ximgproc_PeiLinNormalization, METH_VARARGS | METH_KEYWORDS, \"PeiLinNormalization(I[, T]) -> T\\n.   @overload\"},\n 2770:     {\"RidgeDetectionFilter_create\", (PyCFunction)pyopencv_cv_ximgproc_RidgeDetectionFilter_create, METH_VARARGS | METH_KEYWORDS, \"RidgeDetectionFilter_create([, ddepth[, dx[, dy[, ksize[, out_dtype[, scale[, delta[, borderType]]]]]]]]) -> retval\\n.   @brief Create pointer to the Ridge detection filter.\\n.   @param ddepth  Specifies output image depth. Defualt is CV_32FC1\\n.   @param dx Order of derivative x, default is 1\\n.   @param dy  Order of derivative y, default is 1\\n.   @param ksize Sobel kernel size , default is 3\\n.   @param out_dtype Converted format for output, default is CV_8UC1\\n.   @param scale Optional scale value for derivative values, default is 1\\n.   @param delta  Optional bias added to output, default is 0\\n.   @param borderType Pixel extrapolation method, default is BORDER_DEFAULT\\n.   @see Sobel, threshold, getStructuringElement, morphologyEx.( for additional refinement)\"},\n 2771      {\"amFilter\", (PyCFunction)pyopencv_cv_ximgproc_amFilter, METH_VARARGS | METH_KEYWORDS, \"amFilter(joint, src, sigma_s, sigma_r[, dst[, adjust_outliers]]) -> dst\\n.   @brief Simple one-line Adaptive Manifold Filter call.\\n.   \\n.   @param joint joint (also called as guided) image or array of images with any numbers of channels.\\n.   \\n.   @param src filtering image with any numbers of channels.\\n.   \\n.   @param dst output image.\\n.   \\n.   @param sigma_s spatial standard deviation.\\n.   \\n.   @param sigma_r color space standard deviation, it is similar to the sigma in the color space into\\n.   bilateralFilter.\\n.   \\n.   @param adjust_outliers optional, specify perform outliers adjust operation or not, (Eq. 9) in the\\n.   original paper.\\n.   \\n.   @note Joint images with CV_8U and CV_16U depth converted to images with CV_32F depth and [0; 1]\\n.   color range before processing. Hence color space sigma sigma_r must be in [0; 1] range, unlike same\\n.   sigmas in bilateralFilter and dtFilter functions. @sa bilateralFilter, dtFilter, guidedFilter\"},\n 2772      {\"anisotropicDiffusion\", (PyCFunction)pyopencv_cv_ximgproc_anisotropicDiffusion, METH_VARARGS | METH_KEYWORDS, \"anisotropicDiffusion(src, alpha, K, niters[, dst]) -> dst\\n.   @brief Performs anisotropic diffusian on an image.\\n.   \\n.   The function applies Perona-Malik anisotropic diffusion to an image. This is the solution to the partial differential equation:\\n.   \\n.   \\\\f[{\\\\frac  {\\\\partial I}{\\\\partial t}}={\\\\mathrm  {div}}\\\\left(c(x,y,t)\\\\nabla I\\\\right)=\\\\nabla c\\\\cdot \\\\nabla I+c(x,y,t)\\\\Delta I\\\\f]\\n.   \\n.   Suggested functions for c(x,y,t) are:\\n.   \\n.   \\\\f[c\\\\left(\\\\|\\\\nabla I\\\\|\\\\right)=e^{{-\\\\left(\\\\|\\\\nabla I\\\\|/K\\\\right)^{2}}}\\\\f]\\n.   \\n.   or\\n.   \\n.   \\\\f[ c\\\\left(\\\\|\\\\nabla I\\\\|\\\\right)={\\\\frac {1}{1+\\\\left({\\\\frac  {\\\\|\\\\nabla I\\\\|}{K}}\\\\right)^{2}}} \\\\f]\\n.   \\n.   @param src Grayscale Source image.\\n.   @param dst Destination image of the same size and the same number of channels as src .\\n.   @param alpha The amount of time to step forward by on each iteration (normally, it's between 0 and 1).\\n.   @param K sensitivity to the edges\\n.   @param niters The number of iterations\"},\n ....\n 2865      {\"createSimpleWB\", (PyCFunction)pyopencv_cv_xphoto_createSimpleWB, METH_VARARGS | METH_KEYWORDS, \"createSimpleWB() -> retval\\n.   @brief Creates an instance of SimpleWB\"},\n 2866      {\"dctDenoising\", (PyCFunction)pyopencv_cv_xphoto_dctDenoising, METH_VARARGS | METH_KEYWORDS, \"dctDenoising(src, dst, sigma[, psize]) -> None\\n.   @brief The function implements simple dct-based denoising\\n.   \\n.   <http://www.ipol.im/pub/art/2011/ys-dct/>.\\n.   @param src source image\\n.   @param dst destination image\\n.   @param sigma expected noise standard deviation\\n.   @param psize size of block side where dct is computed\\n.   \\n.   @sa\\n.   fastNlMeansDenoising\"},\n 2867:     {\"inpaint\", (PyCFunction)pyopencv_cv_xphoto_inpaint, METH_VARARGS | METH_KEYWORDS, \"inpaint(src, mask, dst, algorithmType) -> None\\n.   @brief The function implements different single-image inpainting algorithms.\\n.   \\n.   See the original paper @cite He2012 for details.\\n.   \\n.   @param src source image, it could be of any type and any number of channels from 1 to 4. In case of\\n.   3- and 4-channels images the function expect them in CIELab colorspace or similar one, where first\\n.   color component shows intensity, while second and third shows colors. Nonetheless you can try any\\n.   colorspaces.\\n.   @param mask mask (CV_8UC1), where non-zero pixels indicate valid image area, while zero pixels\\n.   indicate area to be inpainted\\n.   @param dst destination image\\n.   @param algorithmType see xphoto::InpaintTypes\"},\n 2868      {NULL, NULL}\n 2869  };\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\build\\modules\\python2\\pyopencv_generated_types.h:\n 12778  {\n 12779      {\"compareSegments\", (PyCFunction)pyopencv_cv_LineSegmentDetector_compareSegments, METH_VARARGS | METH_KEYWORDS, \"compareSegments(size, lines1, lines2[, _image]) -> retval, _image\\n.   @brief Draws two groups of lines in blue and red, counting the non overlapping (mismatching) pixels.\\n.   \\n.   @param size The size of the image, where lines1 and lines2 were found.\\n.   @param lines1 The first group of lines that needs to be drawn. It is visualized in blue color.\\n.   @param lines2 The second group of lines. They visualized in red color.\\n.   @param _image Optional image, where the lines will be drawn. The image should be color(3-channel)\\n.   in order for lines1 and lines2 to be drawn in the above mentioned colors.\"},\n 12780:     {\"detect\", (PyCFunction)pyopencv_cv_LineSegmentDetector_detect, METH_VARARGS | METH_KEYWORDS, \"detect(_image[, _lines[, width[, prec[, nfa]]]]) -> _lines, width, prec, nfa\\n.   @brief Finds lines in the input image.\\n.   \\n.   This is the output of the default parameters of the algorithm on the above shown image.\\n.   \\n.   ![image](pics/building_lsd.png)\\n.   \\n.   @param _image A grayscale (CV_8UC1) input image. If only a roi needs to be selected, use:\\n.   `lsd_ptr-\\\\>detect(image(roi), lines, ...); lines += Scalar(roi.x, roi.y, roi.x, roi.y);`\\n.   @param _lines A vector of Vec4i or Vec4f elements specifying the beginning and ending point of a line. Where\\n.   Vec4i/Vec4f is (x1, y1, x2, y2), point 1 is the start, point 2 - end. Returned lines are strictly\\n.   oriented depending on the gradient.\\n.   @param width Vector of widths of the regions, where the lines are found. E.g. Width of line.\\n.   @param prec Vector of precisions with which the lines are found.\\n.   @param nfa Vector containing number of false alarms in the line region, with precision of 10%. The\\n.   bigger the value, logarithmically better the detection.\\n.   - -1 corresponds to 10 mean false alarms\\n.   - 0 corresponds to 1 mean false alarm\\n.   - 1 corresponds to 0.1 mean false alarms\\n.   This vector will be calculated only when the objects type is LSD_REFINE_ADV.\"},\n 12781      {\"drawSegments\", (PyCFunction)pyopencv_cv_LineSegmentDetector_drawSegments, METH_VARARGS | METH_KEYWORDS, \"drawSegments(_image, lines) -> _image\\n.   @brief Draws the line segments on a given image.\\n.   @param _image The image, where the lines will be drawn. Should be bigger or equal to the image,\\n.   where the lines were found.\\n.   @param lines A vector of the lines that needed to be drawn.\"},\n 12782  \n .....\n 39658  {\n 39659      {\"create\", (PyCFunction)pyopencv_cv_text_text_OCRTesseract_create_cls, METH_VARARGS | METH_KEYWORDS | METH_CLASS, \"create([, datapath[, language[, char_whitelist[, oem[, psmode]]]]]) -> retval\\n.   @brief Creates an instance of the OCRTesseract class. Initializes Tesseract.\\n.   \\n.   @param datapath the name of the parent directory of tessdata ended with \\\"/\\\", or NULL to use the\\n.   system's default directory.\\n.   @param language an ISO 639-3 code or NULL will default to \\\"eng\\\".\\n.   @param char_whitelist specifies the list of characters used for recognition. NULL defaults to\\n.   \\\"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\\\".\\n.   @param oem tesseract-ocr offers different OCR Engine Modes (OEM), by default\\n.   tesseract::OEM_DEFAULT is used. See the tesseract-ocr API documentation for other possible\\n.   values.\\n.   @param psmode tesseract-ocr offers different Page Segmentation Modes (PSM) tesseract::PSM_AUTO\\n.   (fully automatic layout analysis) is used. See the tesseract-ocr API documentation for other\\n.   possible values.\"},\n 39660:     {\"run\", (PyCFunction)pyopencv_cv_text_text_OCRTesseract_run, METH_VARARGS | METH_KEYWORDS, \"run(image, min_confidence[, component_level]) -> retval\\n.   @brief Recognize text using the tesseract-ocr API.\\n.   \\n.   Takes image on input and returns recognized text in the output_text parameter. Optionally\\n.   provides also the Rects for individual text elements found (e.g. words), and the list of those\\n.   text elements with their confidence values.\\n.   \\n.   @param image Input image CV_8UC1 or CV_8UC3\\n.   @param output_text Output text of the tesseract-ocr.\\n.   @param component_rects If provided the method will output a list of Rects for the individual\\n.   text elements found (e.g. words or text lines).\\n.   @param component_texts If provided the method will output a list of text strings for the\\n.   recognition of individual text elements found (e.g. words or text lines).\\n.   @param component_confidences If provided the method will output a list of confidence values\\n.   for the recognition of individual text elements found (e.g. words or text lines).\\n.   @param component_level OCR_LEVEL_WORD (by default), or OCR_LEVEL_TEXTLINE.\\n\\n\\n\\nrun(image, mask, min_confidence[, component_level]) -> retval\\n.\"},\n 39661      {\"setWhiteList\", (PyCFunction)pyopencv_cv_text_text_OCRTesseract_setWhiteList, METH_VARARGS | METH_KEYWORDS, \"setWhiteList(char_whitelist) -> None\\n.\"},\n 39662  \n .....\n 39886  {\n 39887      {\"create\", (PyCFunction)pyopencv_cv_text_text_OCRHMMDecoder_create_cls, METH_VARARGS | METH_KEYWORDS | METH_CLASS, \"create(classifier, vocabulary, transition_probabilities_table, emission_probabilities_table[, mode]) -> retval\\n.   @brief Creates an instance of the OCRHMMDecoder class. Initializes HMMDecoder.\\n.   \\n.   @param classifier The character classifier with built in feature extractor.\\n.   \\n.   @param vocabulary The language vocabulary (chars when ascii english text). vocabulary.size()\\n.   must be equal to the number of classes of the classifier.\\n.   \\n.   @param transition_probabilities_table Table with transition probabilities between character\\n.   pairs. cols == rows == vocabulary.size().\\n.   \\n.   @param emission_probabilities_table Table with observation emission probabilities. cols ==\\n.   rows == vocabulary.size().\\n.   \\n.   @param mode HMM Decoding algorithm. Only OCR_DECODER_VITERBI is available for the moment\\n.   (<http://en.wikipedia.org/wiki/Viterbi_algorithm>).\\n\\n\\n\\ncreate(filename, vocabulary, transition_probabilities_table, emission_probabilities_table[, mode[, classifier]]) -> retval\\n.   @brief Creates an instance of the OCRHMMDecoder class. Loads and initializes HMMDecoder from the specified path\\n.   \\n.   @overload\"},\n 39888:     {\"run\", (PyCFunction)pyopencv_cv_text_text_OCRHMMDecoder_run, METH_VARARGS | METH_KEYWORDS, \"run(image, min_confidence[, component_level]) -> retval\\n.   @brief Recognize text using HMM.\\n.   \\n.   Takes an image and a mask (where each connected component corresponds to a segmented character)\\n.   on input and returns recognized text in the output_text parameter. Optionally\\n.   provides also the Rects for individual text elements found (e.g. words), and the list of those\\n.   text elements with their confidence values.\\n.   \\n.   @param image Input image CV_8UC1 or CV_8UC3 with a single text line (or word).\\n.   @param mask Input binary image CV_8UC1 same size as input image. Each connected component in mask corresponds to a segmented character in the input image.\\n.   \\n.   @param output_text Output text. Most likely character sequence found by the HMM decoder.\\n.   \\n.   @param component_rects If provided the method will output a list of Rects for the individual\\n.   text elements found (e.g. words).\\n.   \\n.   @param component_texts If provided the method will output a list of text strings for the\\n.   recognition of individual text elements found (e.g. words).\\n.   \\n.   @param component_confidences If provided the method will output a list of confidence values\\n.   for the recognition of individual text elements found (e.g. words).\\n.   \\n.   @param component_level Only OCR_LEVEL_WORD is supported.\\n\\n\\n\\nrun(image, mask, min_confidence[, component_level]) -> retval\\n.\"},\n 39889  \n 39890      {NULL,          NULL}\n .....\n 40147  {\n 40148      {\"create\", (PyCFunction)pyopencv_cv_text_text_OCRBeamSearchDecoder_create_cls, METH_VARARGS | METH_KEYWORDS | METH_CLASS, \"create(classifier, vocabulary, transition_probabilities_table, emission_probabilities_table[, mode[, beam_size]]) -> retval\\n.   @brief Creates an instance of the OCRBeamSearchDecoder class. Initializes HMMDecoder.\\n.   \\n.   @param classifier The character classifier with built in feature extractor.\\n.   \\n.   @param vocabulary The language vocabulary (chars when ASCII English text). vocabulary.size()\\n.   must be equal to the number of classes of the classifier.\\n.   \\n.   @param transition_probabilities_table Table with transition probabilities between character\\n.   pairs. cols == rows == vocabulary.size().\\n.   \\n.   @param emission_probabilities_table Table with observation emission probabilities. cols ==\\n.   rows == vocabulary.size().\\n.   \\n.   @param mode HMM Decoding algorithm. Only OCR_DECODER_VITERBI is available for the moment\\n.   (<http://en.wikipedia.org/wiki/Viterbi_algorithm>).\\n.   \\n.   @param beam_size Size of the beam in Beam Search algorithm.\\n\\n\\n\\ncreate(filename, vocabulary, transition_probabilities_table, emission_probabilities_table[, mode[, beam_size]]) -> retval\\n.   @brief Creates an instance of the OCRBeamSearchDecoder class. Initializes HMMDecoder from the specified path.\\n.   \\n.   @overload\"},\n 40149:     {\"run\", (PyCFunction)pyopencv_cv_text_text_OCRBeamSearchDecoder_run, METH_VARARGS | METH_KEYWORDS, \"run(image, min_confidence[, component_level]) -> retval\\n.   @brief Recognize text using Beam Search.\\n.   \\n.   Takes image on input and returns recognized text in the output_text parameter. Optionally\\n.   provides also the Rects for individual text elements found (e.g. words), and the list of those\\n.   text elements with their confidence values.\\n.   \\n.   @param image Input binary image CV_8UC1 with a single text line (or word).\\n.   \\n.   @param output_text Output text. Most likely character sequence found by the HMM decoder.\\n.   \\n.   @param component_rects If provided the method will output a list of Rects for the individual\\n.   text elements found (e.g. words).\\n.   \\n.   @param component_texts If provided the method will output a list of text strings for the\\n.   recognition of individual text elements found (e.g. words).\\n.   \\n.   @param component_confidences If provided the method will output a list of confidence values\\n.   for the recognition of individual text elements found (e.g. words).\\n.   \\n.   @param component_level Only OCR_LEVEL_WORD is supported.\\n\\n\\n\\nrun(image, mask, min_confidence[, component_level]) -> retval\\n.\"},\n 40150  \n 40151      {NULL,          NULL}\n .....\n 43378      {\"DEFAULT_MAX_TRANSLATION\", (PyCFunction)pyopencv_cv_rgbd_rgbd_Odometry_DEFAULT_MAX_TRANSLATION, METH_VARARGS | METH_KEYWORDS, \"DEFAULT_MAX_TRANSLATION() -> retval\\n.\"},\n 43379      {\"DEFAULT_MIN_DEPTH\", (PyCFunction)pyopencv_cv_rgbd_rgbd_Odometry_DEFAULT_MIN_DEPTH, METH_VARARGS | METH_KEYWORDS, \"DEFAULT_MIN_DEPTH() -> retval\\n.\"},\n 43380:     {\"compute\", (PyCFunction)pyopencv_cv_rgbd_rgbd_Odometry_compute, METH_VARARGS | METH_KEYWORDS, \"compute(srcImage, srcDepth, srcMask, dstImage, dstDepth, dstMask[, Rt[, initRt]]) -> retval, Rt\\n.   Method to compute a transformation from the source frame to the destination one.\\n.   * Some odometry algorithms do not used some data of frames (eg. ICP does not use images).\\n.   * In such case corresponding arguments can be set as empty Mat.\\n.   * The method returns true if all internal computions were possible (e.g. there were enough correspondences,\\n.   * system of equations has a solution, etc) and resulting transformation satisfies some test if it's provided\\n.   * by the Odometry inheritor implementation (e.g. thresholds for maximum translation and rotation).\\n.   * @param srcImage Image data of the source frame (CV_8UC1)\\n.   * @param srcDepth Depth data of the source frame (CV_32FC1, in meters)\\n.   * @param srcMask Mask that sets which pixels have to be used from the source frame (CV_8UC1)\\n.   * @param dstImage Image data of the destination frame (CV_8UC1)\\n.   * @param dstDepth Depth data of the destination frame (CV_32FC1, in meters)\\n.   * @param dstMask Mask that sets which pixels have to be used from the destination frame (CV_8UC1)\\n.   * @param Rt Resulting transformation from the source frame to the destination one (rigid body motion):\\n.   dst_p = Rt * src_p, where dst_p is a homogeneous point in the destination frame and src_p is\\n.   homogeneous point in the source frame,\\n.   Rt is 4x4 matrix of CV_64FC1 type.\\n.   * @param initRt Initial transformation from the source frame to the destination one (optional)\"},\n 43381      {\"compute2\", (PyCFunction)pyopencv_cv_rgbd_rgbd_Odometry_compute2, METH_VARARGS | METH_KEYWORDS, \"compute2(srcFrame, dstFrame[, Rt[, initRt]]) -> retval, Rt\\n.   One more method to compute a transformation from the source frame to the destination one.\\n.   * It is designed to save on computing the frame data (image pyramids, normals, etc.).\"},\n 43382      {\"create\", (PyCFunction)pyopencv_cv_rgbd_rgbd_Odometry_create_cls, METH_VARARGS | METH_KEYWORDS | METH_CLASS, \"create(odometryType) -> retval\\n.\"},\n .....\n 46198      {\"getT\", (PyCFunction)pyopencv_cv_linemod_linemod_Detector_getT, METH_VARARGS | METH_KEYWORDS, \"getT(pyramid_level) -> retval\\n.   * \\\\brief Get sampling step T at pyramid_level.\"},\n 46199      {\"getTemplates\", (PyCFunction)pyopencv_cv_linemod_linemod_Detector_getTemplates, METH_VARARGS | METH_KEYWORDS, \"getTemplates(class_id, template_id) -> retval\\n.   * \\\\brief Get the template pyramid identified by template_id.\\n.   *\\n.   * For example, with 2 modalities (Gradient, Normal) and two pyramid levels\\n.   * (L0, L1), the order is (GradientL0, NormalL0, GradientL1, NormalL1).\"},\n 46200:     {\"match\", (PyCFunction)pyopencv_cv_linemod_linemod_Detector_match, METH_VARARGS | METH_KEYWORDS, \"match(sources, threshold[, class_ids[, quantized_images[, masks]]]) -> matches, quantized_images\\n.   * \\\\brief Detect objects by template matching.\\n.   *\\n.   * Matches globally at the lowest pyramid level, then refines locally stepping up the pyramid.\\n.   *\\n.   * \\\\param      sources   Source images, one for each modality.\\n.   * \\\\param      threshold Similarity threshold, a percentage between 0 and 100.\\n.   * \\\\param[out] matches   Template matches, sorted by similarity score.\\n.   * \\\\param      class_ids If non-empty, only search for the desired object classes.\\n.   * \\\\param[out] quantized_images Optionally return vector<Mat> of quantized images.\\n.   * \\\\param      masks     The masks for consideration during matching. The masks should be CV_8UC1\\n.   *                       where 255 represents a valid pixel.  If non-empty, the vector must be\\n.   *                       the same size as sources.  Each element must be\\n.   *                       empty or the same size as its corresponding source.\"},\n 46201      {\"numClasses\", (PyCFunction)pyopencv_cv_linemod_linemod_Detector_numClasses, METH_VARARGS | METH_KEYWORDS, \"numClasses() -> retval\\n.\"},\n 46202      {\"numTemplates\", (PyCFunction)pyopencv_cv_linemod_linemod_Detector_numTemplates, METH_VARARGS | METH_KEYWORDS, \"numTemplates() -> retval\\n.   \\n\\n\\n\\nnumTemplates(class_id) -> retval\\n.\"},\n .....\n 51260  static PyMethodDef pyopencv_ximgproc_FastLineDetector_methods[] =\n 51261  {\n 51262:     {\"detect\", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_FastLineDetector_detect, METH_VARARGS | METH_KEYWORDS, \"detect(_image[, _lines]) -> _lines\\n.   @brief Finds lines in the input image.\\n.   This is the output of the default parameters of the algorithm on the above\\n.   shown image.\\n.   \\n.   ![image](pics/corridor_fld.jpg)\\n.   \\n.   @param _image A grayscale (CV_8UC1) input image. If only a roi needs to be\\n.   selected, use: `fld_ptr-\\\\>detect(image(roi), lines, ...);\\n.   lines += Scalar(roi.x, roi.y, roi.x, roi.y);`\\n.   @param _lines A vector of Vec4f elements specifying the beginning\\n.   and ending point of a line.  Where Vec4f is (x1, y1, x2, y2), point\\n.   1 is the start, point 2 - end. Returned lines are directed so that the\\n.   brighter side is on their left.\"},\n 51263      {\"drawSegments\", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_FastLineDetector_drawSegments, METH_VARARGS | METH_KEYWORDS, \"drawSegments(_image, lines[, draw_arrow]) -> _image\\n.   @brief Draws the line segments on a given image.\\n.   @param _image The image, where the lines will be drawn. Should be bigger\\n.   or equal to the image, where the lines were found.\\n.   @param lines A vector of the lines that needed to be drawn.\\n.   @param draw_arrow If true, arrow heads will be drawn.\"},\n 51264  \n .....\n 51651      int dy=1;\n 51652      int ksize=3;\n 51653:     int out_dtype=CV_8UC1;\n 51654      double scale=1;\n 51655      double delta=0;\n .....\n 51716  static PyMethodDef pyopencv_ximgproc_RidgeDetectionFilter_methods[] =\n 51717  {\n 51718:     {\"create\", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_RidgeDetectionFilter_create_cls, METH_VARARGS | METH_KEYWORDS | METH_CLASS, \"create([, ddepth[, dx[, dy[, ksize[, out_dtype[, scale[, delta[, borderType]]]]]]]]) -> retval\\n.   @brief Create pointer to the Ridge detection filter.\\n.   @param ddepth  Specifies output image depth. Defualt is CV_32FC1\\n.   @param dx Order of derivative x, default is 1\\n.   @param dy  Order of derivative y, default is 1\\n.   @param ksize Sobel kernel size , default is 3\\n.   @param out_dtype Converted format for output, default is CV_8UC1\\n.   @param scale Optional scale value for derivative values, default is 1\\n.   @param delta  Optional bias added to output, default is 0\\n.   @param borderType Pixel extrapolation method, default is BORDER_DEFAULT\\n.   @see Sobel, threshold, getStructuringElement, morphologyEx.( for additional refinement)\"},\n 51719      {\"getRidgeFilteredImage\", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_RidgeDetectionFilter_getRidgeFilteredImage, METH_VARARGS | METH_KEYWORDS, \"getRidgeFilteredImage(_img[, out]) -> out\\n.   @brief Apply Ridge detection filter on input image.\\n.   @param _img InputArray as supported by Sobel. img can be 1-Channel or 3-Channels.\\n.   @param out OutputAray of structure as RidgeDetectionFilter::ddepth. Output image with ridges.\"},\n 51720  \n .....\n 51891  static PyMethodDef pyopencv_ximgproc_SuperpixelSEEDS_methods[] =\n 51892  {\n 51893:     {\"getLabelContourMask\", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_SuperpixelSEEDS_getLabelContourMask, METH_VARARGS | METH_KEYWORDS, \"getLabelContourMask([, image[, thick_line]]) -> image\\n.   @brief Returns the mask of the superpixel segmentation stored in SuperpixelSEEDS object.\\n.   \\n.   @param image Return: CV_8UC1 image mask where -1 indicates that the pixel is a superpixel border,\\n.   and 0 otherwise.\\n.   \\n.   @param thick_line If false, the border is only one pixel wide, otherwise all pixels at the border\\n.   are masked.\\n.   \\n.   The function return the boundaries of the superpixel segmentation.\\n.   \\n.   @note\\n.   -   (Python) A demo on how to generate superpixels in images from the webcam can be found at\\n.   opencv_source_code/samples/python2/seeds.py\\n.   -   (cpp) A demo on how to generate superpixels in images from the webcam can be found at\\n.   opencv_source_code/modules/ximgproc/samples/seeds.cpp. By adding a file image as a command\\n.   line argument, the static image will be used instead of the webcam.\\n.   -   It will show a window with the video from the webcam with the superpixel boundaries marked\\n.   in red (see below). Use Space to switch between different output modes. At the top of the\\n.   window there are 4 sliders, from which the user can change on-the-fly the number of\\n.   superpixels, the number of block levels, the strength of the boundary prior term to modify\\n.   the shape, and the number of iterations at pixel level. This is useful to play with the\\n.   parameters and set them to the user convenience. In the console the frame-rate of the\\n.   algorithm is indicated.\\n.   \\n.   ![image](pics/superpixels_demo.png)\"},\n 51894      {\"getLabels\", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_SuperpixelSEEDS_getLabels, METH_VARARGS | METH_KEYWORDS, \"getLabels([, labels_out]) -> labels_out\\n.   @brief Returns the segmentation labeling of the image.\\n.   \\n.   Each label represents a superpixel, and each pixel is assigned to one superpixel label.\\n.   \\n.   @param labels_out Return: A CV_32UC1 integer array containing the labels of the superpixel\\n.   segmentation. The labels are in the range [0, getNumberOfSuperpixels()].\\n.   \\n.   The function returns an image with ssthe labels of the superpixel segmentation. The labels are in\\n.   the range [0, getNumberOfSuperpixels()].\"},\n 51895      {\"getNumberOfSuperpixels\", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_SuperpixelSEEDS_getNumberOfSuperpixels, METH_VARARGS | METH_KEYWORDS, \"getNumberOfSuperpixels() -> retval\\n.   @brief Calculates the superpixel segmentation on a given image stored in SuperpixelSEEDS object.\\n.   \\n.   The function computes the superpixels segmentation of an image with the parameters initialized\\n.   with the function createSuperpixelSEEDS().\"},\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\build\\modules\\python3\\pyopencv_generated_funcs.h:\n 25014      int dy=1;\n 25015      int ksize=3;\n 25016:     int out_dtype=CV_8UC1;\n 25017      double scale=1;\n 25018      double delta=0;\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\build\\modules\\python3\\pyopencv_generated_ns_reg.h:\n   61      {\"addText\", (PyCFunction)pyopencv_cv_addText, METH_VARARGS | METH_KEYWORDS, \"addText(img, text, org, nameFont[, pointSize[, color[, weight[, style[, spacing]]]]]) -> None\\n.   @brief Draws a text on the image.\\n.   \\n.   @param img 8-bit 3-channel image where the text should be drawn.\\n.   @param text Text to write on an image.\\n.   @param org Point(x,y) where the text should start on an image.\\n.   @param nameFont Name of the font. The name should match the name of a system font (such as\\n.   *Times*). If the font is not found, a default one is used.\\n.   @param pointSize Size of the font. If not specified, equal zero or negative, the point size of the\\n.   font is set to a system-dependent default value. Generally, this is 12 points.\\n.   @param color Color of the font in BGRA where A = 255 is fully transparent.\\n.   @param weight Font weight. Available operation flags are : cv::QtFontWeights You can also specify a positive integer for better control.\\n.   @param style Font style. Available operation flags are : cv::QtFontStyles\\n.   @param spacing Spacing between characters. It can be negative or positive.\"},\n   62      {\"addWeighted\", (PyCFunction)pyopencv_cv_addWeighted, METH_VARARGS | METH_KEYWORDS, \"addWeighted(src1, alpha, src2, beta, gamma[, dst[, dtype]]) -> dst\\n.   @brief Calculates the weighted sum of two arrays.\\n.   \\n.   The function addWeighted calculates the weighted sum of two arrays as follows:\\n.   \\\\f[\\\\texttt{dst} (I)= \\\\texttt{saturate} ( \\\\texttt{src1} (I)* \\\\texttt{alpha} +  \\\\texttt{src2} (I)* \\\\texttt{beta} +  \\\\texttt{gamma} )\\\\f]\\n.   where I is a multi-dimensional index of array elements. In case of multi-channel arrays, each\\n.   channel is processed independently.\\n.   The function can be replaced with a matrix expression:\\n.   @code{.cpp}\\n.   dst = src1*alpha + src2*beta + gamma;\\n.   @endcode\\n.   @note Saturation is not applied when the output array has the depth CV_32S. You may even get\\n.   result of an incorrect sign in the case of overflow.\\n.   @param src1 first input array.\\n.   @param alpha weight of the first array elements.\\n.   @param src2 second input array of the same size and channel number as src1.\\n.   @param beta weight of the second array elements.\\n.   @param gamma scalar added to each sum.\\n.   @param dst output array that has the same size and number of channels as the input arrays.\\n.   @param dtype optional depth of the output array; when both input arrays have the same depth, dtype\\n.   can be set to -1, which will be equivalent to src1.depth().\\n.   @sa  add, subtract, scaleAdd, Mat::convertTo\"},\n   63:     {\"applyColorMap\", (PyCFunction)pyopencv_cv_applyColorMap, METH_VARARGS | METH_KEYWORDS, \"applyColorMap(src, colormap[, dst]) -> dst\\n.   @brief Applies a GNU Octave/MATLAB equivalent colormap on a given image.\\n.   \\n.   @param src The source image, grayscale or colored of type CV_8UC1 or CV_8UC3.\\n.   @param dst The result is the colormapped source image. Note: Mat::create is called on dst.\\n.   @param colormap The colormap to apply, see cv::ColormapTypes\\n\\n\\n\\napplyColorMap(src, userColor[, dst]) -> dst\\n.   @brief Applies a user colormap on a given image.\\n.   \\n.   @param src The source image, grayscale or colored of type CV_8UC1 or CV_8UC3.\\n.   @param dst The result is the colormapped source image. Note: Mat::create is called on dst.\\n.   @param userColor The colormap to apply of type CV_8UC1 or CV_8UC3 and size 256\"},\n   64      {\"approxPolyDP\", (PyCFunction)pyopencv_cv_approxPolyDP, METH_VARARGS | METH_KEYWORDS, \"approxPolyDP(curve, epsilon, closed[, approxCurve]) -> approxCurve\\n.   @brief Approximates a polygonal curve(s) with the specified precision.\\n.   \\n.   The function cv::approxPolyDP approximates a curve or a polygon with another curve/polygon with less\\n.   vertices so that the distance between them is less or equal to the specified precision. It uses the\\n.   Douglas-Peucker algorithm <http://en.wikipedia.org/wiki/Ramer-Douglas-Peucker_algorithm>\\n.   \\n.   @param curve Input vector of a 2D point stored in std::vector or Mat\\n.   @param approxCurve Result of the approximation. The type should match the type of the input curve.\\n.   @param epsilon Parameter specifying the approximation accuracy. This is the maximum distance\\n.   between the original curve and its approximation.\\n.   @param closed If true, the approximated curve is closed (its first and last vertices are\\n.   connected). Otherwise, it is not closed.\"},\n   65      {\"arcLength\", (PyCFunction)pyopencv_cv_arcLength, METH_VARARGS | METH_KEYWORDS, \"arcLength(curve, closed) -> retval\\n.   @brief Calculates a contour perimeter or a curve length.\\n.   \\n.   The function computes a curve length or a closed contour perimeter.\\n.   \\n.   @param curve Input vector of 2D points, stored in std::vector or Mat.\\n.   @param closed Flag indicating whether the curve is closed or not.\"},\n   ..\n  196      {\"findFundamentalMat\", (PyCFunction)pyopencv_cv_findFundamentalMat, METH_VARARGS | METH_KEYWORDS, \"findFundamentalMat(points1, points2[, method[, param1[, param2[, mask]]]]) -> retval, mask\\n.   @brief Calculates a fundamental matrix from the corresponding points in two images.\\n.   \\n.   @param points1 Array of N points from the first image. The point coordinates should be\\n.   floating-point (single or double precision).\\n.   @param points2 Array of the second image points of the same size and format as points1 .\\n.   @param method Method for computing a fundamental matrix.\\n.   -   **CV_FM_7POINT** for a 7-point algorithm. \\\\f$N = 7\\\\f$\\n.   -   **CV_FM_8POINT** for an 8-point algorithm. \\\\f$N \\\\ge 8\\\\f$\\n.   -   **CV_FM_RANSAC** for the RANSAC algorithm. \\\\f$N \\\\ge 8\\\\f$\\n.   -   **CV_FM_LMEDS** for the LMedS algorithm. \\\\f$N \\\\ge 8\\\\f$\\n.   @param param1 Parameter used for RANSAC. It is the maximum distance from a point to an epipolar\\n.   line in pixels, beyond which the point is considered an outlier and is not used for computing the\\n.   final fundamental matrix. It can be set to something like 1-3, depending on the accuracy of the\\n.   point localization, image resolution, and the image noise.\\n.   @param param2 Parameter used for the RANSAC or LMedS methods only. It specifies a desirable level\\n.   of confidence (probability) that the estimated matrix is correct.\\n.   @param mask\\n.   \\n.   The epipolar geometry is described by the following equation:\\n.   \\n.   \\\\f[[p_2; 1]^T F [p_1; 1] = 0\\\\f]\\n.   \\n.   where \\\\f$F\\\\f$ is a fundamental matrix, \\\\f$p_1\\\\f$ and \\\\f$p_2\\\\f$ are corresponding points in the first and the\\n.   second images, respectively.\\n.   \\n.   The function calculates the fundamental matrix using one of four methods listed above and returns\\n.   the found fundamental matrix. Normally just one matrix is found. But in case of the 7-point\\n.   algorithm, the function may return up to 3 solutions ( \\\\f$9 \\\\times 3\\\\f$ matrix that stores all 3\\n.   matrices sequentially).\\n.   \\n.   The calculated fundamental matrix may be passed further to computeCorrespondEpilines that finds the\\n.   epipolar lines corresponding to the specified points. It can also be passed to\\n.   stereoRectifyUncalibrated to compute the rectification transformation. :\\n.   @code\\n.   // Example. Estimation of fundamental matrix using the RANSAC algorithm\\n.   int point_count = 100;\\n.   vector<Point2f> points1(point_count);\\n.   vector<Point2f> points2(point_count);\\n.   \\n.   // initialize the points here ...\\n.   for( int i = 0; i < point_count; i++ )\\n.   {\\n.   points1[i] = ...;\\n.   points2[i] = ...;\\n.   }\\n.   \\n.   Mat fundamental_matrix =\\n.   findFundamentalMat(points1, points2, FM_RANSAC, 3, 0.99);\\n.   @endcode\"},\n  197      {\"findHomography\", (PyCFunction)pyopencv_cv_findHomography, METH_VARARGS | METH_KEYWORDS, \"findHomography(srcPoints, dstPoints[, method[, ransacReprojThreshold[, mask[, maxIters[, confidence]]]]]) -> retval, mask\\n.   @brief Finds a perspective transformation between two planes.\\n.   \\n.   @param srcPoints Coordinates of the points in the original plane, a matrix of the type CV_32FC2\\n.   or vector\\\\<Point2f\\\\> .\\n.   @param dstPoints Coordinates of the points in the target plane, a matrix of the type CV_32FC2 or\\n.   a vector\\\\<Point2f\\\\> .\\n.   @param method Method used to computed a homography matrix. The following methods are possible:\\n.   -   **0** - a regular method using all the points\\n.   -   **RANSAC** - RANSAC-based robust method\\n.   -   **LMEDS** - Least-Median robust method\\n.   -   **RHO**    - PROSAC-based robust method\\n.   @param ransacReprojThreshold Maximum allowed reprojection error to treat a point pair as an inlier\\n.   (used in the RANSAC and RHO methods only). That is, if\\n.   \\\\f[\\\\| \\\\texttt{dstPoints} _i -  \\\\texttt{convertPointsHomogeneous} ( \\\\texttt{H} * \\\\texttt{srcPoints} _i) \\\\|  >  \\\\texttt{ransacReprojThreshold}\\\\f]\\n.   then the point \\\\f$i\\\\f$ is considered an outlier. If srcPoints and dstPoints are measured in pixels,\\n.   it usually makes sense to set this parameter somewhere in the range of 1 to 10.\\n.   @param mask Optional output mask set by a robust method ( RANSAC or LMEDS ). Note that the input\\n.   mask values are ignored.\\n.   @param maxIters The maximum number of RANSAC iterations, 2000 is the maximum it can be.\\n.   @param confidence Confidence level, between 0 and 1.\\n.   \\n.   The function finds and returns the perspective transformation \\\\f$H\\\\f$ between the source and the\\n.   destination planes:\\n.   \\n.   \\\\f[s_i  \\\\vecthree{x'_i}{y'_i}{1} \\\\sim H  \\\\vecthree{x_i}{y_i}{1}\\\\f]\\n.   \\n.   so that the back-projection error\\n.   \\n.   \\\\f[\\\\sum _i \\\\left ( x'_i- \\\\frac{h_{11} x_i + h_{12} y_i + h_{13}}{h_{31} x_i + h_{32} y_i + h_{33}} \\\\right )^2+ \\\\left ( y'_i- \\\\frac{h_{21} x_i + h_{22} y_i + h_{23}}{h_{31} x_i + h_{32} y_i + h_{33}} \\\\right )^2\\\\f]\\n.   \\n.   is minimized. If the parameter method is set to the default value 0, the function uses all the point\\n.   pairs to compute an initial homography estimate with a simple least-squares scheme.\\n.   \\n.   However, if not all of the point pairs ( \\\\f$srcPoints_i\\\\f$, \\\\f$dstPoints_i\\\\f$ ) fit the rigid perspective\\n.   transformation (that is, there are some outliers), this initial estimate will be poor. In this case,\\n.   you can use one of the three robust methods. The methods RANSAC, LMeDS and RHO try many different\\n.   random subsets of the corresponding point pairs (of four pairs each), estimate the homography matrix\\n.   using this subset and a simple least-square algorithm, and then compute the quality/goodness of the\\n.   computed homography (which is the number of inliers for RANSAC or the median re-projection error for\\n.   LMeDs). The best subset is then used to produce the initial estimate of the homography matrix and\\n.   the mask of inliers/outliers.\\n.   \\n.   Regardless of the method, robust or not, the computed homography matrix is refined further (using\\n.   inliers only in case of a robust method) with the Levenberg-Marquardt method to reduce the\\n.   re-projection error even more.\\n.   \\n.   The methods RANSAC and RHO can handle practically any ratio of outliers but need a threshold to\\n.   distinguish inliers from outliers. The method LMeDS does not need any threshold but it works\\n.   correctly only when there are more than 50% of inliers. Finally, if there are no outliers and the\\n.   noise is rather small, use the default method (method=0).\\n.   \\n.   The function is used to find initial intrinsic and extrinsic matrices. Homography matrix is\\n.   determined up to a scale. Thus, it is normalized so that \\\\f$h_{33}=1\\\\f$. Note that whenever an H matrix\\n.   cannot be estimated, an empty one will be returned.\\n.   \\n.   @sa\\n.   getAffineTransform, estimateAffine2D, estimateAffinePartial2D, getPerspectiveTransform, warpPerspective,\\n.   perspectiveTransform\\n.   \\n.   \\n.   @note\\n.   -   A example on calculating a homography for image matching can be found at\\n.   opencv_source_code/samples/cpp/video_homography.cpp\"},\n  198:     {\"findNonZero\", (PyCFunction)pyopencv_cv_findNonZero, METH_VARARGS | METH_KEYWORDS, \"findNonZero(src[, idx]) -> idx\\n.   @brief Returns the list of locations of non-zero pixels\\n.   \\n.   Given a binary matrix (likely returned from an operation such\\n.   as threshold(), compare(), >, ==, etc, return all of\\n.   the non-zero indices as a cv::Mat or std::vector<cv::Point> (x,y)\\n.   For example:\\n.   @code{.cpp}\\n.   cv::Mat binaryImage; // input, binary image\\n.   cv::Mat locations;   // output, locations of non-zero pixels\\n.   cv::findNonZero(binaryImage, locations);\\n.   \\n.   // access pixel coordinates\\n.   Point pnt = locations.at<Point>(i);\\n.   @endcode\\n.   or\\n.   @code{.cpp}\\n.   cv::Mat binaryImage; // input, binary image\\n.   vector<Point> locations;   // output, locations of non-zero pixels\\n.   cv::findNonZero(binaryImage, locations);\\n.   \\n.   // access pixel coordinates\\n.   Point pnt = locations[i];\\n.   @endcode\\n.   @param src single-channel array (type CV_8UC1)\\n.   @param idx the output array, type of cv::Mat or std::vector<Point>, corresponding to non-zero indices in the input\"},\n  199      {\"findTransformECC\", (PyCFunction)pyopencv_cv_findTransformECC, METH_VARARGS | METH_KEYWORDS, \"findTransformECC(templateImage, inputImage, warpMatrix[, motionType[, criteria[, inputMask]]]) -> retval, warpMatrix\\n.   @brief Finds the geometric transform (warp) between two images in terms of the ECC criterion @cite EP08 .\\n.   \\n.   @param templateImage single-channel template image; CV_8U or CV_32F array.\\n.   @param inputImage single-channel input image which should be warped with the final warpMatrix in\\n.   order to provide an image similar to templateImage, same type as temlateImage.\\n.   @param warpMatrix floating-point \\\\f$2\\\\times 3\\\\f$ or \\\\f$3\\\\times 3\\\\f$ mapping matrix (warp).\\n.   @param motionType parameter, specifying the type of motion:\\n.   -   **MOTION_TRANSLATION** sets a translational motion model; warpMatrix is \\\\f$2\\\\times 3\\\\f$ with\\n.   the first \\\\f$2\\\\times 2\\\\f$ part being the unity matrix and the rest two parameters being\\n.   estimated.\\n.   -   **MOTION_EUCLIDEAN** sets a Euclidean (rigid) transformation as motion model; three\\n.   parameters are estimated; warpMatrix is \\\\f$2\\\\times 3\\\\f$.\\n.   -   **MOTION_AFFINE** sets an affine motion model (DEFAULT); six parameters are estimated;\\n.   warpMatrix is \\\\f$2\\\\times 3\\\\f$.\\n.   -   **MOTION_HOMOGRAPHY** sets a homography as a motion model; eight parameters are\\n.   estimated;\\\\`warpMatrix\\\\` is \\\\f$3\\\\times 3\\\\f$.\\n.   @param criteria parameter, specifying the termination criteria of the ECC algorithm;\\n.   criteria.epsilon defines the threshold of the increment in the correlation coefficient between two\\n.   iterations (a negative criteria.epsilon makes criteria.maxcount the only termination criterion).\\n.   Default values are shown in the declaration above.\\n.   @param inputMask An optional mask to indicate valid values of inputImage.\\n.   \\n.   The function estimates the optimum transformation (warpMatrix) with respect to ECC criterion\\n.   (@cite EP08), that is\\n.   \\n.   \\\\f[\\\\texttt{warpMatrix} = \\\\texttt{warpMatrix} = \\\\arg\\\\max_{W} \\\\texttt{ECC}(\\\\texttt{templateImage}(x,y),\\\\texttt{inputImage}(x',y'))\\\\f]\\n.   \\n.   where\\n.   \\n.   \\\\f[\\\\begin{bmatrix} x' \\\\\\\\ y' \\\\end{bmatrix} = W \\\\cdot \\\\begin{bmatrix} x \\\\\\\\ y \\\\\\\\ 1 \\\\end{bmatrix}\\\\f]\\n.   \\n.   (the equation holds with homogeneous coordinates for homography). It returns the final enhanced\\n.   correlation coefficient, that is the correlation coefficient between the template image and the\\n.   final warped input image. When a \\\\f$3\\\\times 3\\\\f$ matrix is given with motionType =0, 1 or 2, the third\\n.   row is ignored.\\n.   \\n.   Unlike findHomography and estimateRigidTransform, the function findTransformECC implements an\\n.   area-based alignment that builds on intensity similarities. In essence, the function updates the\\n.   initial transformation that roughly aligns the images. If this information is missing, the identity\\n.   warp (unity matrix) is used as an initialization. Note that if images undergo strong\\n.   displacements/rotations, an initial transformation that roughly aligns the images is necessary\\n.   (e.g., a simple euclidean/similarity transform that allows for the images showing the same image\\n.   content approximately). Use inverse warping in the second image to take an image close to the first\\n.   one, i.e. use the flag WARP_INVERSE_MAP with warpAffine or warpPerspective. See also the OpenCV\\n.   sample image_alignment.cpp that demonstrates the use of the function. Note that the function throws\\n.   an exception if algorithm does not converges.\\n.   \\n.   @sa\\n.   estimateAffine2D, estimateAffinePartial2D, findHomography\"},\n  200      {\"fitEllipse\", (PyCFunction)pyopencv_cv_fitEllipse, METH_VARARGS | METH_KEYWORDS, \"fitEllipse(points) -> retval\\n.   @brief Fits an ellipse around a set of 2D points.\\n.   \\n.   The function calculates the ellipse that fits (in a least-squares sense) a set of 2D points best of\\n.   all. It returns the rotated rectangle in which the ellipse is inscribed. The first algorithm described by @cite Fitzgibbon95\\n.   is used. Developer should keep in mind that it is possible that the returned\\n.   ellipse/rotatedRect data contains negative indices, due to the data points being close to the\\n.   border of the containing Mat element.\\n.   \\n.   @param points Input 2D point set, stored in std::vector\\\\<\\\\> or Mat\"},\n  ...\n  227      {\"getValidDisparityROI\", (PyCFunction)pyopencv_cv_getValidDisparityROI, METH_VARARGS | METH_KEYWORDS, \"getValidDisparityROI(roi1, roi2, minDisparity, numberOfDisparities, SADWindowSize) -> retval\\n.\"},\n  228      {\"getWindowProperty\", (PyCFunction)pyopencv_cv_getWindowProperty, METH_VARARGS | METH_KEYWORDS, \"getWindowProperty(winname, prop_id) -> retval\\n.   @brief Provides parameters of a window.\\n.   \\n.   The function getWindowProperty returns properties of a window.\\n.   \\n.   @param winname Name of the window.\\n.   @param prop_id Window property to retrieve. The following operation flags are available: (cv::WindowPropertyFlags)\\n.   \\n.   @sa setWindowProperty\"},\n  229:     {\"goodFeaturesToTrack\", (PyCFunction)pyopencv_cv_goodFeaturesToTrack, METH_VARARGS | METH_KEYWORDS, \"goodFeaturesToTrack(image, maxCorners, qualityLevel, minDistance[, corners[, mask[, blockSize[, useHarrisDetector[, k]]]]]) -> corners\\n.   @brief Determines strong corners on an image.\\n.   \\n.   The function finds the most prominent corners in the image or in the specified image region, as\\n.   described in @cite Shi94\\n.   \\n.   -   Function calculates the corner quality measure at every source image pixel using the\\n.   cornerMinEigenVal or cornerHarris .\\n.   -   Function performs a non-maximum suppression (the local maximums in *3 x 3* neighborhood are\\n.   retained).\\n.   -   The corners with the minimal eigenvalue less than\\n.   \\\\f$\\\\texttt{qualityLevel} \\\\cdot \\\\max_{x,y} qualityMeasureMap(x,y)\\\\f$ are rejected.\\n.   -   The remaining corners are sorted by the quality measure in the descending order.\\n.   -   Function throws away each corner for which there is a stronger corner at a distance less than\\n.   maxDistance.\\n.   \\n.   The function can be used to initialize a point-based tracker of an object.\\n.   \\n.   @note If the function is called with different values A and B of the parameter qualityLevel , and\\n.   A \\\\> B, the vector of returned corners with qualityLevel=A will be the prefix of the output vector\\n.   with qualityLevel=B .\\n.   \\n.   @param image Input 8-bit or floating-point 32-bit, single-channel image.\\n.   @param corners Output vector of detected corners.\\n.   @param maxCorners Maximum number of corners to return. If there are more corners than are found,\\n.   the strongest of them is returned. `maxCorners <= 0` implies that no limit on the maximum is set\\n.   and all detected corners are returned.\\n.   @param qualityLevel Parameter characterizing the minimal accepted quality of image corners. The\\n.   parameter value is multiplied by the best corner quality measure, which is the minimal eigenvalue\\n.   (see cornerMinEigenVal ) or the Harris function response (see cornerHarris ). The corners with the\\n.   quality measure less than the product are rejected. For example, if the best corner has the\\n.   quality measure = 1500, and the qualityLevel=0.01 , then all the corners with the quality measure\\n.   less than 15 are rejected.\\n.   @param minDistance Minimum possible Euclidean distance between the returned corners.\\n.   @param mask Optional region of interest. If the image is not empty (it needs to have the type\\n.   CV_8UC1 and the same size as image ), it specifies the region in which the corners are detected.\\n.   @param blockSize Size of an average block for computing a derivative covariation matrix over each\\n.   pixel neighborhood. See cornerEigenValsAndVecs .\\n.   @param useHarrisDetector Parameter indicating whether to use a Harris detector (see cornerHarris)\\n.   or cornerMinEigenVal.\\n.   @param k Free parameter of the Harris detector.\\n.   \\n.   @sa  cornerMinEigenVal, cornerHarris, calcOpticalFlowPyrLK, estimateRigidTransform,\\n\\n\\n\\ngoodFeaturesToTrack(image, maxCorners, qualityLevel, minDistance, mask, blockSize, gradientSize[, corners[, useHarrisDetector[, k]]]) -> corners\\n.\"},\n  230      {\"grabCut\", (PyCFunction)pyopencv_cv_grabCut, METH_VARARGS | METH_KEYWORDS, \"grabCut(img, mask, rect, bgdModel, fgdModel, iterCount[, mode]) -> mask, bgdModel, fgdModel\\n.   @brief Runs the GrabCut algorithm.\\n.   \\n.   The function implements the [GrabCut image segmentation algorithm](http://en.wikipedia.org/wiki/GrabCut).\\n.   \\n.   @param img Input 8-bit 3-channel image.\\n.   @param mask Input/output 8-bit single-channel mask. The mask is initialized by the function when\\n.   mode is set to GC_INIT_WITH_RECT. Its elements may have one of the cv::GrabCutClasses.\\n.   @param rect ROI containing a segmented object. The pixels outside of the ROI are marked as\\n.   \\\"obvious background\\\". The parameter is only used when mode==GC_INIT_WITH_RECT .\\n.   @param bgdModel Temporary array for the background model. Do not modify it while you are\\n.   processing the same image.\\n.   @param fgdModel Temporary arrays for the foreground model. Do not modify it while you are\\n.   processing the same image.\\n.   @param iterCount Number of iterations the algorithm should make before returning the result. Note\\n.   that the result can be refined with further calls with mode==GC_INIT_WITH_MASK or\\n.   mode==GC_EVAL .\\n.   @param mode Operation mode that could be one of the cv::GrabCutModes\"},\n  231      {\"groupRectangles\", (PyCFunction)pyopencv_cv_groupRectangles, METH_VARARGS | METH_KEYWORDS, \"groupRectangles(rectList, groupThreshold[, eps]) -> rectList, weights\\n.   @overload\"},\n  232      {\"haveOpenVX\", (PyCFunction)pyopencv_cv_haveOpenVX, METH_VARARGS | METH_KEYWORDS, \"haveOpenVX() -> retval\\n.\"},\n  233:     {\"hconcat\", (PyCFunction)pyopencv_cv_hconcat, METH_VARARGS | METH_KEYWORDS, \"hconcat(src[, dst]) -> dst\\n.   @overload\\n.   @code{.cpp}\\n.   std::vector<cv::Mat> matrices = { cv::Mat(4, 1, CV_8UC1, cv::Scalar(1)),\\n.   cv::Mat(4, 1, CV_8UC1, cv::Scalar(2)),\\n.   cv::Mat(4, 1, CV_8UC1, cv::Scalar(3)),};\\n.   \\n.   cv::Mat out;\\n.   cv::hconcat( matrices, out );\\n.   //out:\\n.   //[1, 2, 3;\\n.   // 1, 2, 3;\\n.   // 1, 2, 3;\\n.   // 1, 2, 3]\\n.   @endcode\\n.   @param src input array or vector of matrices. all of the matrices must have the same number of rows and the same depth.\\n.   @param dst output array. It has the same number of rows and depth as the src, and the sum of cols of the src.\\n.   same depth.\"},\n  234      {\"idct\", (PyCFunction)pyopencv_cv_idct, METH_VARARGS | METH_KEYWORDS, \"idct(src[, dst[, flags]]) -> dst\\n.   @brief Calculates the inverse Discrete Cosine Transform of a 1D or 2D array.\\n.   \\n.   idct(src, dst, flags) is equivalent to dct(src, dst, flags | DCT_INVERSE).\\n.   @param src input floating-point single-channel array.\\n.   @param dst output array of the same size and type as src.\\n.   @param flags operation flags.\\n.   @sa  dct, dft, idft, getOptimalDFTSize\"},\n  235      {\"idft\", (PyCFunction)pyopencv_cv_idft, METH_VARARGS | METH_KEYWORDS, \"idft(src[, dst[, flags[, nonzeroRows]]]) -> dst\\n.   @brief Calculates the inverse Discrete Fourier Transform of a 1D or 2D array.\\n.   \\n.   idft(src, dst, flags) is equivalent to dft(src, dst, flags | DFT_INVERSE) .\\n.   @note None of dft and idft scales the result by default. So, you should pass DFT_SCALE to one of\\n.   dft or idft explicitly to make these transforms mutually inverse.\\n.   @sa dft, dct, idct, mulSpectrums, getOptimalDFTSize\\n.   @param src input floating-point real or complex array.\\n.   @param dst output array whose size and type depend on the flags.\\n.   @param flags operation flags (see dft and cv::DftFlags).\\n.   @param nonzeroRows number of dst rows to process; the rest of the rows have undefined content (see\\n.   the convolution sample in dft description.\"},\n  ...\n  282      {\"multiply\", (PyCFunction)pyopencv_cv_multiply, METH_VARARGS | METH_KEYWORDS, \"multiply(src1, src2[, dst[, scale[, dtype]]]) -> dst\\n.   @brief Calculates the per-element scaled product of two arrays.\\n.   \\n.   The function multiply calculates the per-element product of two arrays:\\n.   \\n.   \\\\f[\\\\texttt{dst} (I)= \\\\texttt{saturate} ( \\\\texttt{scale} \\\\cdot \\\\texttt{src1} (I)  \\\\cdot \\\\texttt{src2} (I))\\\\f]\\n.   \\n.   There is also a @ref MatrixExpressions -friendly variant of the first function. See Mat::mul .\\n.   \\n.   For a not-per-element matrix product, see gemm .\\n.   \\n.   @note Saturation is not applied when the output array has the depth\\n.   CV_32S. You may even get result of an incorrect sign in the case of\\n.   overflow.\\n.   @param src1 first input array.\\n.   @param src2 second input array of the same size and the same type as src1.\\n.   @param dst output array of the same size and type as src1.\\n.   @param scale optional scale factor.\\n.   @param dtype optional depth of the output array\\n.   @sa add, subtract, divide, scaleAdd, addWeighted, accumulate, accumulateProduct, accumulateSquare,\\n.   Mat::convertTo\"},\n  283      {\"namedWindow\", (PyCFunction)pyopencv_cv_namedWindow, METH_VARARGS | METH_KEYWORDS, \"namedWindow(winname[, flags]) -> None\\n.   @brief Creates a window.\\n.   \\n.   The function namedWindow creates a window that can be used as a placeholder for images and\\n.   trackbars. Created windows are referred to by their names.\\n.   \\n.   If a window with the same name already exists, the function does nothing.\\n.   \\n.   You can call cv::destroyWindow or cv::destroyAllWindows to close the window and de-allocate any associated\\n.   memory usage. For a simple program, you do not really have to call these functions because all the\\n.   resources and windows of the application are closed automatically by the operating system upon exit.\\n.   \\n.   @note\\n.   \\n.   Qt backend supports additional flags:\\n.   -   **WINDOW_NORMAL or WINDOW_AUTOSIZE:** WINDOW_NORMAL enables you to resize the\\n.   window, whereas WINDOW_AUTOSIZE adjusts automatically the window size to fit the\\n.   displayed image (see imshow ), and you cannot change the window size manually.\\n.   -   **WINDOW_FREERATIO or WINDOW_KEEPRATIO:** WINDOW_FREERATIO adjusts the image\\n.   with no respect to its ratio, whereas WINDOW_KEEPRATIO keeps the image ratio.\\n.   -   **WINDOW_GUI_NORMAL or WINDOW_GUI_EXPANDED:** WINDOW_GUI_NORMAL is the old way to draw the window\\n.   without statusbar and toolbar, whereas WINDOW_GUI_EXPANDED is a new enhanced GUI.\\n.   By default, flags == WINDOW_AUTOSIZE | WINDOW_KEEPRATIO | WINDOW_GUI_EXPANDED\\n.   \\n.   @param winname Name of the window in the window caption that may be used as a window identifier.\\n.   @param flags Flags of the window. The supported flags are: (cv::WindowFlags)\"},\n  284:     {\"norm\", (PyCFunction)pyopencv_cv_norm, METH_VARARGS | METH_KEYWORDS, \"norm(src1[, normType[, mask]]) -> retval\\n.   @brief Calculates the  absolute norm of an array.\\n.   \\n.   This version of cv::norm calculates the absolute norm of src1. The type of norm to calculate is specified using cv::NormTypes.\\n.   \\n.   As example for one array consider the function \\\\f$r(x)= \\\\begin{pmatrix} x \\\\\\\\ 1-x \\\\end{pmatrix}, x \\\\in [-1;1]\\\\f$.\\n.   The \\\\f$ L_{1}, L_{2} \\\\f$ and \\\\f$ L_{\\\\infty} \\\\f$ norm for the sample value \\\\f$r(-1) = \\\\begin{pmatrix} -1 \\\\\\\\ 2 \\\\end{pmatrix}\\\\f$\\n.   is calculated as follows\\n.   \\\\f{align*}\\n.   \\\\| r(-1) \\\\|_{L_1} &= |-1| + |2| = 3 \\\\\\\\\\n.   \\\\| r(-1) \\\\|_{L_2} &= \\\\sqrt{(-1)^{2} + (2)^{2}} = \\\\sqrt{5} \\\\\\\\\\n.   \\\\| r(-1) \\\\|_{L_\\\\infty} &= \\\\max(|-1|,|2|) = 2\\n.   \\\\f}\\n.   and for \\\\f$r(0.5) = \\\\begin{pmatrix} 0.5 \\\\\\\\ 0.5 \\\\end{pmatrix}\\\\f$ the calculation is\\n.   \\\\f{align*}\\n.   \\\\| r(0.5) \\\\|_{L_1} &= |0.5| + |0.5| = 1 \\\\\\\\\\n.   \\\\| r(0.5) \\\\|_{L_2} &= \\\\sqrt{(0.5)^{2} + (0.5)^{2}} = \\\\sqrt{0.5} \\\\\\\\\\n.   \\\\| r(0.5) \\\\|_{L_\\\\infty} &= \\\\max(|0.5|,|0.5|) = 0.5.\\n.   \\\\f}\\n.   The following graphic shows all values for the three norm functions \\\\f$\\\\| r(x) \\\\|_{L_1}, \\\\| r(x) \\\\|_{L_2}\\\\f$ and \\\\f$\\\\| r(x) \\\\|_{L_\\\\infty}\\\\f$.\\n.   It is notable that the \\\\f$ L_{1} \\\\f$ norm forms the upper and the \\\\f$ L_{\\\\infty} \\\\f$ norm forms the lower border for the example function \\\\f$ r(x) \\\\f$.\\n.   ![Graphs for the different norm functions from the above example](pics/NormTypes_OneArray_1-2-INF.png)\\n.   \\n.   When the mask parameter is specified and it is not empty, the norm is\\n.   \\n.   If normType is not specified, NORM_L2 is used.\\n.   calculated only over the region specified by the mask.\\n.   \\n.   Multi-channel input arrays are treated as single-channel arrays, that is,\\n.   the results for all channels are combined.\\n.   \\n.   Hamming norms can only be calculated with CV_8U depth arrays.\\n.   \\n.   @param src1 first input array.\\n.   @param normType type of the norm (see cv::NormTypes).\\n.   @param mask optional operation mask; it must have the same size as src1 and CV_8UC1 type.\\n\\n\\n\\nnorm(src1, src2[, normType[, mask]]) -> retval\\n.   @brief Calculates an absolute difference norm or a relative difference norm.\\n.   \\n.   This version of cv::norm calculates the absolute difference norm\\n.   or the relative difference norm of arrays src1 and src2.\\n.   The type of norm to calculate is specified using cv::NormTypes.\\n.   \\n.   @param src1 first input array.\\n.   @param src2 second input array of the same size and the same type as src1.\\n.   @param normType type of the norm (cv::NormTypes).\\n.   @param mask optional operation mask; it must have the same size as src1 and CV_8UC1 type.\"},\n  285      {\"normalize\", (PyCFunction)pyopencv_cv_normalize, METH_VARARGS | METH_KEYWORDS, \"normalize(src, dst[, alpha[, beta[, norm_type[, dtype[, mask]]]]]) -> dst\\n.   @brief Normalizes the norm or value range of an array.\\n.   \\n.   The function cv::normalize normalizes scale and shift the input array elements so that\\n.   \\\\f[\\\\| \\\\texttt{dst} \\\\| _{L_p}= \\\\texttt{alpha}\\\\f]\\n.   (where p=Inf, 1 or 2) when normType=NORM_INF, NORM_L1, or NORM_L2, respectively; or so that\\n.   \\\\f[\\\\min _I  \\\\texttt{dst} (I)= \\\\texttt{alpha} , \\\\, \\\\, \\\\max _I  \\\\texttt{dst} (I)= \\\\texttt{beta}\\\\f]\\n.   \\n.   when normType=NORM_MINMAX (for dense arrays only). The optional mask specifies a sub-array to be\\n.   normalized. This means that the norm or min-n-max are calculated over the sub-array, and then this\\n.   sub-array is modified to be normalized. If you want to only use the mask to calculate the norm or\\n.   min-max but modify the whole array, you can use norm and Mat::convertTo.\\n.   \\n.   In case of sparse matrices, only the non-zero values are analyzed and transformed. Because of this,\\n.   the range transformation for sparse matrices is not allowed since it can shift the zero level.\\n.   \\n.   Possible usage with some positive example data:\\n.   @code{.cpp}\\n.   vector<double> positiveData = { 2.0, 8.0, 10.0 };\\n.   vector<double> normalizedData_l1, normalizedData_l2, normalizedData_inf, normalizedData_minmax;\\n.   \\n.   // Norm to probability (total count)\\n.   // sum(numbers) = 20.0\\n.   // 2.0      0.1     (2.0/20.0)\\n.   // 8.0      0.4     (8.0/20.0)\\n.   // 10.0     0.5     (10.0/20.0)\\n.   normalize(positiveData, normalizedData_l1, 1.0, 0.0, NORM_L1);\\n.   \\n.   // Norm to unit vector: ||positiveData|| = 1.0\\n.   // 2.0      0.15\\n.   // 8.0      0.62\\n.   // 10.0     0.77\\n.   normalize(positiveData, normalizedData_l2, 1.0, 0.0, NORM_L2);\\n.   \\n.   // Norm to max element\\n.   // 2.0      0.2     (2.0/10.0)\\n.   // 8.0      0.8     (8.0/10.0)\\n.   // 10.0     1.0     (10.0/10.0)\\n.   normalize(positiveData, normalizedData_inf, 1.0, 0.0, NORM_INF);\\n.   \\n.   // Norm to range [0.0;1.0]\\n.   // 2.0      0.0     (shift to left border)\\n.   // 8.0      0.75    (6.0/8.0)\\n.   // 10.0     1.0     (shift to right border)\\n.   normalize(positiveData, normalizedData_minmax, 1.0, 0.0, NORM_MINMAX);\\n.   @endcode\\n.   \\n.   @param src input array.\\n.   @param dst output array of the same size as src .\\n.   @param alpha norm value to normalize to or the lower range boundary in case of the range\\n.   normalization.\\n.   @param beta upper range boundary in case of the range normalization; it is not used for the norm\\n.   normalization.\\n.   @param norm_type normalization type (see cv::NormTypes).\\n.   @param dtype when negative, the output array has the same type as src; otherwise, it has the same\\n.   number of channels as src and the depth =CV_MAT_DEPTH(dtype).\\n.   @param mask optional operation mask.\\n.   @sa norm, Mat::convertTo, SparseMat::convertTo\"},\n  286      {\"patchNaNs\", (PyCFunction)pyopencv_cv_patchNaNs, METH_VARARGS | METH_KEYWORDS, \"patchNaNs(a[, val]) -> a\\n.   @brief converts NaN's to the given number\"},\n  ...\n  361      {\"useOptimized\", (PyCFunction)pyopencv_cv_useOptimized, METH_VARARGS | METH_KEYWORDS, \"useOptimized() -> retval\\n.   @brief Returns the status of optimized code usage.\\n.   \\n.   The function returns true if the optimized code is enabled. Otherwise, it returns false.\"},\n  362      {\"validateDisparity\", (PyCFunction)pyopencv_cv_validateDisparity, METH_VARARGS | METH_KEYWORDS, \"validateDisparity(disparity, cost, minDisparity, numberOfDisparities[, disp12MaxDisp]) -> disparity\\n.\"},\n  363:     {\"vconcat\", (PyCFunction)pyopencv_cv_vconcat, METH_VARARGS | METH_KEYWORDS, \"vconcat(src[, dst]) -> dst\\n.   @overload\\n.   @code{.cpp}\\n.   std::vector<cv::Mat> matrices = { cv::Mat(1, 4, CV_8UC1, cv::Scalar(1)),\\n.   cv::Mat(1, 4, CV_8UC1, cv::Scalar(2)),\\n.   cv::Mat(1, 4, CV_8UC1, cv::Scalar(3)),};\\n.   \\n.   cv::Mat out;\\n.   cv::vconcat( matrices, out );\\n.   //out:\\n.   //[1,   1,   1,   1;\\n.   // 2,   2,   2,   2;\\n.   // 3,   3,   3,   3]\\n.   @endcode\\n.   @param src input array or vector of matrices. all of the matrices must have the same number of cols and the same depth\\n.   @param dst output array. It has the same number of cols and depth as the src, and the sum of rows of the src.\\n.   same depth.\"},\n  364      {\"waitKey\", (PyCFunction)pyopencv_cv_waitKey, METH_VARARGS | METH_KEYWORDS, \"waitKey([, delay]) -> retval\\n.   @brief Waits for a pressed key.\\n.   \\n.   The function waitKey waits for a key event infinitely (when \\\\f$\\\\texttt{delay}\\\\leq 0\\\\f$ ) or for delay\\n.   milliseconds, when it is positive. Since the OS has a minimum time between switching threads, the\\n.   function will not wait exactly delay ms, it will wait at least delay ms, depending on what else is\\n.   running on your computer at that time. It returns the code of the pressed key or -1 if no key was\\n.   pressed before the specified time had elapsed.\\n.   \\n.   @note\\n.   \\n.   This function is the only method in HighGUI that can fetch and handle events, so it needs to be\\n.   called periodically for normal event processing unless HighGUI is used within an environment that\\n.   takes care of event processing.\\n.   \\n.   @note\\n.   \\n.   The function only works if there is at least one HighGUI window created and the window is active.\\n.   If there are several HighGUI windows, any of them can be active.\\n.   \\n.   @param delay Delay in milliseconds. 0 is the special value that means \\\"forever\\\".\"},\n  365      {\"waitKeyEx\", (PyCFunction)pyopencv_cv_waitKeyEx, METH_VARARGS | METH_KEYWORDS, \"waitKeyEx([, delay]) -> retval\\n.   @brief Similar to #waitKey, but returns full key code.\\n.   \\n.   @note\\n.   \\n.   Key code is implementation specific and depends on used backend: QT/GTK/Win32/etc\"},\n  ...\n 2144      {\"PHash_create\", (PyCFunction)pyopencv_cv_img_hash_PHash_create, METH_VARARGS | METH_KEYWORDS, \"PHash_create() -> retval\\n.\"},\n 2145      {\"RadialVarianceHash_create\", (PyCFunction)pyopencv_cv_img_hash_RadialVarianceHash_create, METH_VARARGS | METH_KEYWORDS, \"RadialVarianceHash_create([, sigma[, numOfAngleLine]]) -> retval\\n.\"},\n 2146:     {\"averageHash\", (PyCFunction)pyopencv_cv_img_hash_averageHash, METH_VARARGS | METH_KEYWORDS, \"averageHash(inputArr[, outputArr]) -> outputArr\\n.   @brief Calculates img_hash::AverageHash in one call\\n.   @param inputArr input image want to compute hash value, type should be CV_8UC4, CV_8UC3 or CV_8UC1.\\n.   @param outputArr Hash value of input, it will contain 16 hex decimal number, return type is CV_8U\"},\n 2147:     {\"blockMeanHash\", (PyCFunction)pyopencv_cv_img_hash_blockMeanHash, METH_VARARGS | METH_KEYWORDS, \"blockMeanHash(inputArr[, outputArr[, mode]]) -> outputArr\\n.   @brief Computes block mean hash of the input image\\n.   @param inputArr input image want to compute hash value, type should be CV_8UC4, CV_8UC3 or CV_8UC1.\\n.   @param outputArr Hash value of input, it will contain 16 hex decimal number, return type is CV_8U\\n.   @param mode\"},\n 2148:     {\"colorMomentHash\", (PyCFunction)pyopencv_cv_img_hash_colorMomentHash, METH_VARARGS | METH_KEYWORDS, \"colorMomentHash(inputArr[, outputArr]) -> outputArr\\n.   @brief Computes color moment hash of the input, the algorithm\\n.   is come from the paper \\\"Perceptual  Hashing  for  Color  Images\\n.   Using  Invariant Moments\\\"\\n.   @param inputArr input image want to compute hash value,\\n.   type should be CV_8UC4, CV_8UC3 or CV_8UC1.\\n.   @param outputArr 42 hash values with type CV_64F(double)\"},\n 2149:     {\"marrHildrethHash\", (PyCFunction)pyopencv_cv_img_hash_marrHildrethHash, METH_VARARGS | METH_KEYWORDS, \"marrHildrethHash(inputArr[, outputArr[, alpha[, scale]]]) -> outputArr\\n.   @brief Computes average hash value of the input image\\n.   @param inputArr input image want to compute hash value,\\n.   type should be CV_8UC4, CV_8UC3, CV_8UC1.\\n.   @param outputArr Hash value of input, it will contain 16 hex\\n.   decimal number, return type is CV_8U\\n.   @param alpha int scale factor for marr wavelet (default=2).\\n.   @param scale int level of scale factor (default = 1)\"},\n 2150:     {\"pHash\", (PyCFunction)pyopencv_cv_img_hash_pHash, METH_VARARGS | METH_KEYWORDS, \"pHash(inputArr[, outputArr]) -> outputArr\\n.   @brief Computes pHash value of the input image\\n.   @param inputArr input image want to compute hash value,\\n.   type should be CV_8UC4, CV_8UC3, CV_8UC1.\\n.   @param outputArr Hash value of input, it will contain 8 uchar value\"},\n 2151:     {\"radialVarianceHash\", (PyCFunction)pyopencv_cv_img_hash_radialVarianceHash, METH_VARARGS | METH_KEYWORDS, \"radialVarianceHash(inputArr[, outputArr[, sigma[, numOfAngleLine]]]) -> outputArr\\n.   @brief Computes radial variance hash of the input image\\n.   @param inputArr input image want to compute hash value,\\n.   type should be CV_8UC4, CV_8UC3, CV_8UC1.\\n.   @param outputArr Hash value of input\\n.   @param sigma Gaussian kernel standard deviation\\n.   @param numOfAngleLine The number of angles to consider\"},\n 2152      {NULL, NULL}\n 2153  };\n ....\n 2333  static PyMethodDef methods_motempl[] = {\n 2334      {\"calcGlobalOrientation\", (PyCFunction)pyopencv_cv_motempl_calcGlobalOrientation, METH_VARARGS | METH_KEYWORDS, \"calcGlobalOrientation(orientation, mask, mhi, timestamp, duration) -> retval\\n.   @brief Calculates a global motion orientation in a selected region.\\n.   \\n.   @param orientation Motion gradient orientation image calculated by the function calcMotionGradient\\n.   @param mask Mask image. It may be a conjunction of a valid gradient mask, also calculated by\\n.   calcMotionGradient , and the mask of a region whose direction needs to be calculated.\\n.   @param mhi Motion history image calculated by updateMotionHistory .\\n.   @param timestamp Timestamp passed to updateMotionHistory .\\n.   @param duration Maximum duration of a motion track in milliseconds, passed to updateMotionHistory\\n.   \\n.   The function calculates an average motion direction in the selected region and returns the angle\\n.   between 0 degrees and 360 degrees. The average direction is computed from the weighted orientation\\n.   histogram, where a recent motion has a larger weight and the motion occurred in the past has a\\n.   smaller weight, as recorded in mhi .\"},\n 2335:     {\"calcMotionGradient\", (PyCFunction)pyopencv_cv_motempl_calcMotionGradient, METH_VARARGS | METH_KEYWORDS, \"calcMotionGradient(mhi, delta1, delta2[, mask[, orientation[, apertureSize]]]) -> mask, orientation\\n.   @brief Calculates a gradient orientation of a motion history image.\\n.   \\n.   @param mhi Motion history single-channel floating-point image.\\n.   @param mask Output mask image that has the type CV_8UC1 and the same size as mhi . Its non-zero\\n.   elements mark pixels where the motion gradient data is correct.\\n.   @param orientation Output motion gradient orientation image that has the same type and the same\\n.   size as mhi . Each pixel of the image is a motion orientation, from 0 to 360 degrees.\\n.   @param delta1 Minimal (or maximal) allowed difference between mhi values within a pixel\\n.   neighborhood.\\n.   @param delta2 Maximal (or minimal) allowed difference between mhi values within a pixel\\n.   neighborhood. That is, the function finds the minimum ( \\\\f$m(x,y)\\\\f$ ) and maximum ( \\\\f$M(x,y)\\\\f$ ) mhi\\n.   values over \\\\f$3 \\\\times 3\\\\f$ neighborhood of each pixel and marks the motion orientation at \\\\f$(x, y)\\\\f$\\n.   as valid only if\\n.   \\\\f[\\\\min ( \\\\texttt{delta1}  ,  \\\\texttt{delta2}  )  \\\\le  M(x,y)-m(x,y)  \\\\le   \\\\max ( \\\\texttt{delta1}  , \\\\texttt{delta2} ).\\\\f]\\n.   @param apertureSize Aperture size of the Sobel operator.\\n.   \\n.   The function calculates a gradient orientation at each pixel \\\\f$(x, y)\\\\f$ as:\\n.   \\n.   \\\\f[\\\\texttt{orientation} (x,y)= \\\\arctan{\\\\frac{d\\\\texttt{mhi}/dy}{d\\\\texttt{mhi}/dx}}\\\\f]\\n.   \\n.   In fact, fastAtan2 and phase are used so that the computed angle is measured in degrees and covers\\n.   the full range 0..360. Also, the mask is filled to indicate pixels where the computed angle is\\n.   valid.\\n.   \\n.   @note\\n.   -   (Python) An example on how to perform a motion template technique can be found at\\n.   opencv_source_code/samples/python2/motempl.py\"},\n 2336      {\"segmentMotion\", (PyCFunction)pyopencv_cv_motempl_segmentMotion, METH_VARARGS | METH_KEYWORDS, \"segmentMotion(mhi, timestamp, segThresh[, segmask]) -> segmask, boundingRects\\n.   @brief Splits a motion history image into a few parts corresponding to separate independent motions (for\\n.   example, left hand, right hand).\\n.   \\n.   @param mhi Motion history image.\\n.   @param segmask Image where the found mask should be stored, single-channel, 32-bit floating-point.\\n.   @param boundingRects Vector containing ROIs of motion connected components.\\n.   @param timestamp Current time in milliseconds or other units.\\n.   @param segThresh Segmentation threshold that is recommended to be equal to the interval between\\n.   motion history \\\"steps\\\" or greater.\\n.   \\n.   The function finds all of the motion segments and marks them in segmask with individual values\\n.   (1,2,...). It also computes a vector with ROIs of motion connected components. After that the motion\\n.   direction for every component can be calculated with calcGlobalOrientation using the extracted mask\\n.   of the particular component.\"},\n 2337      {\"updateMotionHistory\", (PyCFunction)pyopencv_cv_motempl_updateMotionHistory, METH_VARARGS | METH_KEYWORDS, \"updateMotionHistory(silhouette, mhi, timestamp, duration) -> mhi\\n.   @brief Updates the motion history image by a moving silhouette.\\n.   \\n.   @param silhouette Silhouette mask that has non-zero pixels where the motion occurs.\\n.   @param mhi Motion history image that is updated by the function (single-channel, 32-bit\\n.   floating-point).\\n.   @param timestamp Current time in milliseconds or other units.\\n.   @param duration Maximal duration of the motion track in the same units as timestamp .\\n.   \\n.   The function updates the motion history image as follows:\\n.   \\n.   \\\\f[\\\\texttt{mhi} (x,y)= \\\\forkthree{\\\\texttt{timestamp}}{if \\\\(\\\\texttt{silhouette}(x,y) \\\\ne 0\\\\)}{0}{if \\\\(\\\\texttt{silhouette}(x,y) = 0\\\\) and \\\\(\\\\texttt{mhi} < (\\\\texttt{timestamp} - \\\\texttt{duration})\\\\)}{\\\\texttt{mhi}(x,y)}{otherwise}\\\\f]\\n.   \\n.   That is, MHI pixels where the motion occurs are set to the current timestamp , while the pixels\\n.   where the motion happened last time a long time ago are cleared.\\n.   \\n.   The function, together with calcMotionGradient and calcGlobalOrientation , implements a motion\\n.   templates technique described in @cite Davis97 and @cite Bradski00 .\"},\n ....\n 2587      {\"registerDepth\", (PyCFunction)pyopencv_cv_rgbd_registerDepth, METH_VARARGS | METH_KEYWORDS, \"registerDepth(unregisteredCameraMatrix, registeredCameraMatrix, registeredDistCoeffs, Rt, unregisteredDepth, outputImagePlaneSize[, registeredDepth[, depthDilation]]) -> registeredDepth\\n.   Registers depth data to an external camera\\n.   * Registration is performed by creating a depth cloud, transforming the cloud by\\n.   * the rigid body transformation between the cameras, and then projecting the\\n.   * transformed points into the RGB camera.\\n.   *\\n.   * uv_rgb = K_rgb * [R | t] * z * inv(K_ir) * uv_ir\\n.   *\\n.   * Currently does not check for negative depth values.\\n.   *\\n.   * @param unregisteredCameraMatrix the camera matrix of the depth camera\\n.   * @param registeredCameraMatrix the camera matrix of the external camera\\n.   * @param registeredDistCoeffs the distortion coefficients of the external camera\\n.   * @param Rt the rigid body transform between the cameras. Transforms points from depth camera frame to external camera frame.\\n.   * @param unregisteredDepth the input depth data\\n.   * @param outputImagePlaneSize the image plane dimensions of the external camera (width, height)\\n.   * @param registeredDepth the result of transforming the depth into the external camera\\n.   * @param depthDilation whether or not the depth is dilated to avoid holes and occlusion errors (optional)\"},\n 2588      {\"rescaleDepth\", (PyCFunction)pyopencv_cv_rgbd_rescaleDepth, METH_VARARGS | METH_KEYWORDS, \"rescaleDepth(in, depth[, out]) -> out\\n.   If the input image is of type CV_16UC1 (like the Kinect one), the image is converted to floats, divided\\n.   * by 1000 to get a depth in meters, and the values 0 are converted to std::numeric_limits<float>::quiet_NaN()\\n.   * Otherwise, the image is simply converted to floats\\n.   * @param in the depth image (if given as short int CV_U, it is assumed to be the depth in millimeters\\n.   *              (as done with the Microsoft Kinect), it is assumed in meters)\\n.   * @param depth the desired output depth (floats or double)\\n.   * @param out The rescaled float depth image\"},\n 2589:     {\"warpFrame\", (PyCFunction)pyopencv_cv_rgbd_warpFrame, METH_VARARGS | METH_KEYWORDS, \"warpFrame(image, depth, mask, Rt, cameraMatrix, distCoeff[, warpedImage[, warpedDepth[, warpedMask]]]) -> warpedImage, warpedDepth, warpedMask\\n.   Warp the image: compute 3d points from the depth, transform them using given transformation,\\n.   * then project color point cloud to an image plane.\\n.   * This function can be used to visualize results of the Odometry algorithm.\\n.   * @param image The image (of CV_8UC1 or CV_8UC3 type)\\n.   * @param depth The depth (of type used in depthTo3d fuction)\\n.   * @param mask The mask of used pixels (of CV_8UC1), it can be empty\\n.   * @param Rt The transformation that will be applied to the 3d points computed from the depth\\n.   * @param cameraMatrix Camera matrix\\n.   * @param distCoeff Distortion coefficients\\n.   * @param warpedImage The warped image.\\n.   * @param warpedDepth The warped depth.\\n.   * @param warpedMask The warped mask.\"},\n 2590      {NULL, NULL}\n 2591  };\n ....\n 2652      {\"createERFilterNM2\", (PyCFunction)pyopencv_cv_text_createERFilterNM2, METH_VARARGS | METH_KEYWORDS, \"createERFilterNM2(cb[, minProbability]) -> retval\\n.   @brief Create an Extremal Region Filter for the 2nd stage classifier of N&M algorithm @cite Neumann12.\\n.   \\n.   @param  cb :   Callback with the classifier. Default classifier can be implicitly load with function\\n.   loadClassifierNM2, e.g. from file in samples/cpp/trained_classifierNM2.xml\\n.   @param  minProbability :   The minimum probability P(er|character) allowed for retreived ER's\\n.   \\n.   In the second stage, the ERs that passed the first stage are classified into character and\\n.   non-character classes using more informative but also more computationally expensive features. The\\n.   classifier uses all the features calculated in the first stage and the following additional\\n.   features: hole area ratio, convex hull ratio, and number of outer inflexion points.\\n\\n\\n\\ncreateERFilterNM2(filename[, minProbability]) -> retval\\n.   @brief Reads an Extremal Region Filter for the 2nd stage classifier of N&M algorithm\\n.   from the provided path e.g. /path/to/cpp/trained_classifierNM2.xml\\n.   \\n.   @overload\"},\n 2653      {\"createOCRHMMTransitionsTable\", (PyCFunction)pyopencv_cv_text_createOCRHMMTransitionsTable, METH_VARARGS | METH_KEYWORDS, \"createOCRHMMTransitionsTable(vocabulary, lexicon) -> retval\\n.   @brief Utility function to create a tailored language model transitions table from a given list of words (lexicon).\\n.   *\\n.   * @param vocabulary The language vocabulary (chars when ASCII English text).\\n.   *\\n.   * @param lexicon The list of words that are expected to be found in a particular image.\\n.   *\\n.   * @param transition_probabilities_table Output table with transition probabilities between character pairs. cols == rows == vocabulary.size().\\n.   *\\n.   * The function calculate frequency statistics of character pairs from the given lexicon and fills the output transition_probabilities_table with them. The transition_probabilities_table can be used as input in the OCRHMMDecoder::create() and OCRBeamSearchDecoder::create() methods.\\n.   * @note\\n.   *    -   (C++) An alternative would be to load the default generic language transition table provided in the text module samples folder (created from ispell 42869 english words list) :\\n.   *            <https://github.com/opencv/opencv_contrib/blob/master/modules/text/samples/OCRHMM_transitions_table.xml>\\n.   *\"},\n 2654:     {\"detectRegions\", (PyCFunction)pyopencv_cv_text_detectRegions, METH_VARARGS | METH_KEYWORDS, \"detectRegions(image, er_filter1, er_filter2) -> regions\\n.   @brief Converts MSER contours (vector\\\\<Point\\\\>) to ERStat regions.\\n.   \\n.   @param image Source image CV_8UC1 from which the MSERs where extracted.\\n.   \\n.   @param contours Input vector with all the contours (vector\\\\<Point\\\\>).\\n.   \\n.   @param regions Output where the ERStat regions are stored.\\n.   \\n.   It takes as input the contours provided by the OpenCV MSER feature detector and returns as output\\n.   two vectors of ERStats. This is because MSER() output contains both MSER+ and MSER- regions in a\\n.   single vector\\\\<Point\\\\>, the function separates them in two different vectors (this is as if the\\n.   ERStats where extracted from two different channels).\\n.   \\n.   An example of MSERsToERStats in use can be found in the text detection webcam_demo:\\n.   <https://github.com/opencv/opencv_contrib/blob/master/modules/text/samples/webcam_demo.cpp>\\n\\n\\n\\ndetectRegions(image, er_filter1, er_filter2[, method[, filename[, minProbability]]]) -> groups_rects\\n.   @brief Extracts text regions from image.\\n.   \\n.   @param image Source image where text blocks needs to be extracted from.  Should be CV_8UC3 (color).\\n.   @param er_filter1 Extremal Region Filter for the 1st stage classifier of N&M algorithm @cite Neumann12\\n.   @param er_filter2 Extremal Region Filter for the 2nd stage classifier of N&M algorithm @cite Neumann12\\n.   @param groups_rects Output list of rectangle blocks with text\\n.   @param method Grouping method (see text::erGrouping_Modes). Can be one of ERGROUPING_ORIENTATION_HORIZ, ERGROUPING_ORIENTATION_ANY.\\n.   @param filename The XML or YAML file with the classifier model (e.g. samples/trained_classifier_erGrouping.xml). Only to use when grouping method is ERGROUPING_ORIENTATION_ANY.\\n.   @param minProbability The minimum probability for accepting a group. Only to use when grouping method is ERGROUPING_ORIENTATION_ANY.\"},\n 2655:     {\"erGrouping\", (PyCFunction)pyopencv_cv_text_erGrouping, METH_VARARGS | METH_KEYWORDS, \"erGrouping(image, channel, regions[, method[, filename[, minProbablity]]]) -> groups_rects\\n.   @brief Find groups of Extremal Regions that are organized as text blocks.\\n.   \\n.   @param img Original RGB or Greyscale image from wich the regions were extracted.\\n.   \\n.   @param channels Vector of single channel images CV_8UC1 from wich the regions were extracted.\\n.   \\n.   @param regions Vector of ER's retrieved from the ERFilter algorithm from each channel.\\n.   \\n.   @param groups The output of the algorithm is stored in this parameter as set of lists of indexes to\\n.   provided regions.\\n.   \\n.   @param groups_rects The output of the algorithm are stored in this parameter as list of rectangles.\\n.   \\n.   @param method Grouping method (see text::erGrouping_Modes). Can be one of ERGROUPING_ORIENTATION_HORIZ,\\n.   ERGROUPING_ORIENTATION_ANY.\\n.   \\n.   @param filename The XML or YAML file with the classifier model (e.g.\\n.   samples/trained_classifier_erGrouping.xml). Only to use when grouping method is\\n.   ERGROUPING_ORIENTATION_ANY.\\n.   \\n.   @param minProbablity The minimum probability for accepting a group. Only to use when grouping\\n.   method is ERGROUPING_ORIENTATION_ANY.\"},\n 2656      {\"loadClassifierNM1\", (PyCFunction)pyopencv_cv_text_loadClassifierNM1, METH_VARARGS | METH_KEYWORDS, \"loadClassifierNM1(filename) -> retval\\n.   @brief Allow to implicitly load the default classifier when creating an ERFilter object.\\n.   \\n.   @param filename The XML or YAML file with the classifier model (e.g. trained_classifierNM1.xml)\\n.   \\n.   returns a pointer to ERFilter::Callback.\"},\n 2657      {\"loadClassifierNM2\", (PyCFunction)pyopencv_cv_text_loadClassifierNM2, METH_VARARGS | METH_KEYWORDS, \"loadClassifierNM2(filename) -> retval\\n.   @brief Allow to implicitly load the default classifier when creating an ERFilter object.\\n.   \\n.   @param filename The XML or YAML file with the classifier model (e.g. trained_classifierNM2.xml)\\n.   \\n.   returns a pointer to ERFilter::Callback.\"},\n ....\n 2768      {\"AdaptiveManifoldFilter_create\", (PyCFunction)pyopencv_cv_ximgproc_AdaptiveManifoldFilter_create, METH_VARARGS | METH_KEYWORDS, \"AdaptiveManifoldFilter_create() -> retval\\n.\"},\n 2769      {\"PeiLinNormalization\", (PyCFunction)pyopencv_cv_ximgproc_PeiLinNormalization, METH_VARARGS | METH_KEYWORDS, \"PeiLinNormalization(I[, T]) -> T\\n.   @overload\"},\n 2770:     {\"RidgeDetectionFilter_create\", (PyCFunction)pyopencv_cv_ximgproc_RidgeDetectionFilter_create, METH_VARARGS | METH_KEYWORDS, \"RidgeDetectionFilter_create([, ddepth[, dx[, dy[, ksize[, out_dtype[, scale[, delta[, borderType]]]]]]]]) -> retval\\n.   @brief Create pointer to the Ridge detection filter.\\n.   @param ddepth  Specifies output image depth. Defualt is CV_32FC1\\n.   @param dx Order of derivative x, default is 1\\n.   @param dy  Order of derivative y, default is 1\\n.   @param ksize Sobel kernel size , default is 3\\n.   @param out_dtype Converted format for output, default is CV_8UC1\\n.   @param scale Optional scale value for derivative values, default is 1\\n.   @param delta  Optional bias added to output, default is 0\\n.   @param borderType Pixel extrapolation method, default is BORDER_DEFAULT\\n.   @see Sobel, threshold, getStructuringElement, morphologyEx.( for additional refinement)\"},\n 2771      {\"amFilter\", (PyCFunction)pyopencv_cv_ximgproc_amFilter, METH_VARARGS | METH_KEYWORDS, \"amFilter(joint, src, sigma_s, sigma_r[, dst[, adjust_outliers]]) -> dst\\n.   @brief Simple one-line Adaptive Manifold Filter call.\\n.   \\n.   @param joint joint (also called as guided) image or array of images with any numbers of channels.\\n.   \\n.   @param src filtering image with any numbers of channels.\\n.   \\n.   @param dst output image.\\n.   \\n.   @param sigma_s spatial standard deviation.\\n.   \\n.   @param sigma_r color space standard deviation, it is similar to the sigma in the color space into\\n.   bilateralFilter.\\n.   \\n.   @param adjust_outliers optional, specify perform outliers adjust operation or not, (Eq. 9) in the\\n.   original paper.\\n.   \\n.   @note Joint images with CV_8U and CV_16U depth converted to images with CV_32F depth and [0; 1]\\n.   color range before processing. Hence color space sigma sigma_r must be in [0; 1] range, unlike same\\n.   sigmas in bilateralFilter and dtFilter functions. @sa bilateralFilter, dtFilter, guidedFilter\"},\n 2772      {\"anisotropicDiffusion\", (PyCFunction)pyopencv_cv_ximgproc_anisotropicDiffusion, METH_VARARGS | METH_KEYWORDS, \"anisotropicDiffusion(src, alpha, K, niters[, dst]) -> dst\\n.   @brief Performs anisotropic diffusian on an image.\\n.   \\n.   The function applies Perona-Malik anisotropic diffusion to an image. This is the solution to the partial differential equation:\\n.   \\n.   \\\\f[{\\\\frac  {\\\\partial I}{\\\\partial t}}={\\\\mathrm  {div}}\\\\left(c(x,y,t)\\\\nabla I\\\\right)=\\\\nabla c\\\\cdot \\\\nabla I+c(x,y,t)\\\\Delta I\\\\f]\\n.   \\n.   Suggested functions for c(x,y,t) are:\\n.   \\n.   \\\\f[c\\\\left(\\\\|\\\\nabla I\\\\|\\\\right)=e^{{-\\\\left(\\\\|\\\\nabla I\\\\|/K\\\\right)^{2}}}\\\\f]\\n.   \\n.   or\\n.   \\n.   \\\\f[ c\\\\left(\\\\|\\\\nabla I\\\\|\\\\right)={\\\\frac {1}{1+\\\\left({\\\\frac  {\\\\|\\\\nabla I\\\\|}{K}}\\\\right)^{2}}} \\\\f]\\n.   \\n.   @param src Grayscale Source image.\\n.   @param dst Destination image of the same size and the same number of channels as src .\\n.   @param alpha The amount of time to step forward by on each iteration (normally, it's between 0 and 1).\\n.   @param K sensitivity to the edges\\n.   @param niters The number of iterations\"},\n ....\n 2865      {\"createSimpleWB\", (PyCFunction)pyopencv_cv_xphoto_createSimpleWB, METH_VARARGS | METH_KEYWORDS, \"createSimpleWB() -> retval\\n.   @brief Creates an instance of SimpleWB\"},\n 2866      {\"dctDenoising\", (PyCFunction)pyopencv_cv_xphoto_dctDenoising, METH_VARARGS | METH_KEYWORDS, \"dctDenoising(src, dst, sigma[, psize]) -> None\\n.   @brief The function implements simple dct-based denoising\\n.   \\n.   <http://www.ipol.im/pub/art/2011/ys-dct/>.\\n.   @param src source image\\n.   @param dst destination image\\n.   @param sigma expected noise standard deviation\\n.   @param psize size of block side where dct is computed\\n.   \\n.   @sa\\n.   fastNlMeansDenoising\"},\n 2867:     {\"inpaint\", (PyCFunction)pyopencv_cv_xphoto_inpaint, METH_VARARGS | METH_KEYWORDS, \"inpaint(src, mask, dst, algorithmType) -> None\\n.   @brief The function implements different single-image inpainting algorithms.\\n.   \\n.   See the original paper @cite He2012 for details.\\n.   \\n.   @param src source image, it could be of any type and any number of channels from 1 to 4. In case of\\n.   3- and 4-channels images the function expect them in CIELab colorspace or similar one, where first\\n.   color component shows intensity, while second and third shows colors. Nonetheless you can try any\\n.   colorspaces.\\n.   @param mask mask (CV_8UC1), where non-zero pixels indicate valid image area, while zero pixels\\n.   indicate area to be inpainted\\n.   @param dst destination image\\n.   @param algorithmType see xphoto::InpaintTypes\"},\n 2868      {NULL, NULL}\n 2869  };\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\build\\modules\\python3\\pyopencv_generated_types.h:\n 12540  {\n 12541      {\"compareSegments\", (PyCFunction)pyopencv_cv_LineSegmentDetector_compareSegments, METH_VARARGS | METH_KEYWORDS, \"compareSegments(size, lines1, lines2[, _image]) -> retval, _image\\n.   @brief Draws two groups of lines in blue and red, counting the non overlapping (mismatching) pixels.\\n.   \\n.   @param size The size of the image, where lines1 and lines2 were found.\\n.   @param lines1 The first group of lines that needs to be drawn. It is visualized in blue color.\\n.   @param lines2 The second group of lines. They visualized in red color.\\n.   @param _image Optional image, where the lines will be drawn. The image should be color(3-channel)\\n.   in order for lines1 and lines2 to be drawn in the above mentioned colors.\"},\n 12542:     {\"detect\", (PyCFunction)pyopencv_cv_LineSegmentDetector_detect, METH_VARARGS | METH_KEYWORDS, \"detect(_image[, _lines[, width[, prec[, nfa]]]]) -> _lines, width, prec, nfa\\n.   @brief Finds lines in the input image.\\n.   \\n.   This is the output of the default parameters of the algorithm on the above shown image.\\n.   \\n.   ![image](pics/building_lsd.png)\\n.   \\n.   @param _image A grayscale (CV_8UC1) input image. If only a roi needs to be selected, use:\\n.   `lsd_ptr-\\\\>detect(image(roi), lines, ...); lines += Scalar(roi.x, roi.y, roi.x, roi.y);`\\n.   @param _lines A vector of Vec4i or Vec4f elements specifying the beginning and ending point of a line. Where\\n.   Vec4i/Vec4f is (x1, y1, x2, y2), point 1 is the start, point 2 - end. Returned lines are strictly\\n.   oriented depending on the gradient.\\n.   @param width Vector of widths of the regions, where the lines are found. E.g. Width of line.\\n.   @param prec Vector of precisions with which the lines are found.\\n.   @param nfa Vector containing number of false alarms in the line region, with precision of 10%. The\\n.   bigger the value, logarithmically better the detection.\\n.   - -1 corresponds to 10 mean false alarms\\n.   - 0 corresponds to 1 mean false alarm\\n.   - 1 corresponds to 0.1 mean false alarms\\n.   This vector will be calculated only when the objects type is LSD_REFINE_ADV.\"},\n 12543      {\"drawSegments\", (PyCFunction)pyopencv_cv_LineSegmentDetector_drawSegments, METH_VARARGS | METH_KEYWORDS, \"drawSegments(_image, lines) -> _image\\n.   @brief Draws the line segments on a given image.\\n.   @param _image The image, where the lines will be drawn. Should be bigger or equal to the image,\\n.   where the lines were found.\\n.   @param lines A vector of the lines that needed to be drawn.\"},\n 12544  \n .....\n 39420  {\n 39421      {\"create\", (PyCFunction)pyopencv_cv_text_text_OCRTesseract_create_cls, METH_VARARGS | METH_KEYWORDS | METH_CLASS, \"create([, datapath[, language[, char_whitelist[, oem[, psmode]]]]]) -> retval\\n.   @brief Creates an instance of the OCRTesseract class. Initializes Tesseract.\\n.   \\n.   @param datapath the name of the parent directory of tessdata ended with \\\"/\\\", or NULL to use the\\n.   system's default directory.\\n.   @param language an ISO 639-3 code or NULL will default to \\\"eng\\\".\\n.   @param char_whitelist specifies the list of characters used for recognition. NULL defaults to\\n.   \\\"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\\\".\\n.   @param oem tesseract-ocr offers different OCR Engine Modes (OEM), by default\\n.   tesseract::OEM_DEFAULT is used. See the tesseract-ocr API documentation for other possible\\n.   values.\\n.   @param psmode tesseract-ocr offers different Page Segmentation Modes (PSM) tesseract::PSM_AUTO\\n.   (fully automatic layout analysis) is used. See the tesseract-ocr API documentation for other\\n.   possible values.\"},\n 39422:     {\"run\", (PyCFunction)pyopencv_cv_text_text_OCRTesseract_run, METH_VARARGS | METH_KEYWORDS, \"run(image, min_confidence[, component_level]) -> retval\\n.   @brief Recognize text using the tesseract-ocr API.\\n.   \\n.   Takes image on input and returns recognized text in the output_text parameter. Optionally\\n.   provides also the Rects for individual text elements found (e.g. words), and the list of those\\n.   text elements with their confidence values.\\n.   \\n.   @param image Input image CV_8UC1 or CV_8UC3\\n.   @param output_text Output text of the tesseract-ocr.\\n.   @param component_rects If provided the method will output a list of Rects for the individual\\n.   text elements found (e.g. words or text lines).\\n.   @param component_texts If provided the method will output a list of text strings for the\\n.   recognition of individual text elements found (e.g. words or text lines).\\n.   @param component_confidences If provided the method will output a list of confidence values\\n.   for the recognition of individual text elements found (e.g. words or text lines).\\n.   @param component_level OCR_LEVEL_WORD (by default), or OCR_LEVEL_TEXTLINE.\\n\\n\\n\\nrun(image, mask, min_confidence[, component_level]) -> retval\\n.\"},\n 39423      {\"setWhiteList\", (PyCFunction)pyopencv_cv_text_text_OCRTesseract_setWhiteList, METH_VARARGS | METH_KEYWORDS, \"setWhiteList(char_whitelist) -> None\\n.\"},\n 39424  \n .....\n 39648  {\n 39649      {\"create\", (PyCFunction)pyopencv_cv_text_text_OCRHMMDecoder_create_cls, METH_VARARGS | METH_KEYWORDS | METH_CLASS, \"create(classifier, vocabulary, transition_probabilities_table, emission_probabilities_table[, mode]) -> retval\\n.   @brief Creates an instance of the OCRHMMDecoder class. Initializes HMMDecoder.\\n.   \\n.   @param classifier The character classifier with built in feature extractor.\\n.   \\n.   @param vocabulary The language vocabulary (chars when ascii english text). vocabulary.size()\\n.   must be equal to the number of classes of the classifier.\\n.   \\n.   @param transition_probabilities_table Table with transition probabilities between character\\n.   pairs. cols == rows == vocabulary.size().\\n.   \\n.   @param emission_probabilities_table Table with observation emission probabilities. cols ==\\n.   rows == vocabulary.size().\\n.   \\n.   @param mode HMM Decoding algorithm. Only OCR_DECODER_VITERBI is available for the moment\\n.   (<http://en.wikipedia.org/wiki/Viterbi_algorithm>).\\n\\n\\n\\ncreate(filename, vocabulary, transition_probabilities_table, emission_probabilities_table[, mode[, classifier]]) -> retval\\n.   @brief Creates an instance of the OCRHMMDecoder class. Loads and initializes HMMDecoder from the specified path\\n.   \\n.   @overload\"},\n 39650:     {\"run\", (PyCFunction)pyopencv_cv_text_text_OCRHMMDecoder_run, METH_VARARGS | METH_KEYWORDS, \"run(image, min_confidence[, component_level]) -> retval\\n.   @brief Recognize text using HMM.\\n.   \\n.   Takes an image and a mask (where each connected component corresponds to a segmented character)\\n.   on input and returns recognized text in the output_text parameter. Optionally\\n.   provides also the Rects for individual text elements found (e.g. words), and the list of those\\n.   text elements with their confidence values.\\n.   \\n.   @param image Input image CV_8UC1 or CV_8UC3 with a single text line (or word).\\n.   @param mask Input binary image CV_8UC1 same size as input image. Each connected component in mask corresponds to a segmented character in the input image.\\n.   \\n.   @param output_text Output text. Most likely character sequence found by the HMM decoder.\\n.   \\n.   @param component_rects If provided the method will output a list of Rects for the individual\\n.   text elements found (e.g. words).\\n.   \\n.   @param component_texts If provided the method will output a list of text strings for the\\n.   recognition of individual text elements found (e.g. words).\\n.   \\n.   @param component_confidences If provided the method will output a list of confidence values\\n.   for the recognition of individual text elements found (e.g. words).\\n.   \\n.   @param component_level Only OCR_LEVEL_WORD is supported.\\n\\n\\n\\nrun(image, mask, min_confidence[, component_level]) -> retval\\n.\"},\n 39651  \n 39652      {NULL,          NULL}\n .....\n 39909  {\n 39910      {\"create\", (PyCFunction)pyopencv_cv_text_text_OCRBeamSearchDecoder_create_cls, METH_VARARGS | METH_KEYWORDS | METH_CLASS, \"create(classifier, vocabulary, transition_probabilities_table, emission_probabilities_table[, mode[, beam_size]]) -> retval\\n.   @brief Creates an instance of the OCRBeamSearchDecoder class. Initializes HMMDecoder.\\n.   \\n.   @param classifier The character classifier with built in feature extractor.\\n.   \\n.   @param vocabulary The language vocabulary (chars when ASCII English text). vocabulary.size()\\n.   must be equal to the number of classes of the classifier.\\n.   \\n.   @param transition_probabilities_table Table with transition probabilities between character\\n.   pairs. cols == rows == vocabulary.size().\\n.   \\n.   @param emission_probabilities_table Table with observation emission probabilities. cols ==\\n.   rows == vocabulary.size().\\n.   \\n.   @param mode HMM Decoding algorithm. Only OCR_DECODER_VITERBI is available for the moment\\n.   (<http://en.wikipedia.org/wiki/Viterbi_algorithm>).\\n.   \\n.   @param beam_size Size of the beam in Beam Search algorithm.\\n\\n\\n\\ncreate(filename, vocabulary, transition_probabilities_table, emission_probabilities_table[, mode[, beam_size]]) -> retval\\n.   @brief Creates an instance of the OCRBeamSearchDecoder class. Initializes HMMDecoder from the specified path.\\n.   \\n.   @overload\"},\n 39911:     {\"run\", (PyCFunction)pyopencv_cv_text_text_OCRBeamSearchDecoder_run, METH_VARARGS | METH_KEYWORDS, \"run(image, min_confidence[, component_level]) -> retval\\n.   @brief Recognize text using Beam Search.\\n.   \\n.   Takes image on input and returns recognized text in the output_text parameter. Optionally\\n.   provides also the Rects for individual text elements found (e.g. words), and the list of those\\n.   text elements with their confidence values.\\n.   \\n.   @param image Input binary image CV_8UC1 with a single text line (or word).\\n.   \\n.   @param output_text Output text. Most likely character sequence found by the HMM decoder.\\n.   \\n.   @param component_rects If provided the method will output a list of Rects for the individual\\n.   text elements found (e.g. words).\\n.   \\n.   @param component_texts If provided the method will output a list of text strings for the\\n.   recognition of individual text elements found (e.g. words).\\n.   \\n.   @param component_confidences If provided the method will output a list of confidence values\\n.   for the recognition of individual text elements found (e.g. words).\\n.   \\n.   @param component_level Only OCR_LEVEL_WORD is supported.\\n\\n\\n\\nrun(image, mask, min_confidence[, component_level]) -> retval\\n.\"},\n 39912  \n 39913      {NULL,          NULL}\n .....\n 43140      {\"DEFAULT_MAX_TRANSLATION\", (PyCFunction)pyopencv_cv_rgbd_rgbd_Odometry_DEFAULT_MAX_TRANSLATION, METH_VARARGS | METH_KEYWORDS, \"DEFAULT_MAX_TRANSLATION() -> retval\\n.\"},\n 43141      {\"DEFAULT_MIN_DEPTH\", (PyCFunction)pyopencv_cv_rgbd_rgbd_Odometry_DEFAULT_MIN_DEPTH, METH_VARARGS | METH_KEYWORDS, \"DEFAULT_MIN_DEPTH() -> retval\\n.\"},\n 43142:     {\"compute\", (PyCFunction)pyopencv_cv_rgbd_rgbd_Odometry_compute, METH_VARARGS | METH_KEYWORDS, \"compute(srcImage, srcDepth, srcMask, dstImage, dstDepth, dstMask[, Rt[, initRt]]) -> retval, Rt\\n.   Method to compute a transformation from the source frame to the destination one.\\n.   * Some odometry algorithms do not used some data of frames (eg. ICP does not use images).\\n.   * In such case corresponding arguments can be set as empty Mat.\\n.   * The method returns true if all internal computions were possible (e.g. there were enough correspondences,\\n.   * system of equations has a solution, etc) and resulting transformation satisfies some test if it's provided\\n.   * by the Odometry inheritor implementation (e.g. thresholds for maximum translation and rotation).\\n.   * @param srcImage Image data of the source frame (CV_8UC1)\\n.   * @param srcDepth Depth data of the source frame (CV_32FC1, in meters)\\n.   * @param srcMask Mask that sets which pixels have to be used from the source frame (CV_8UC1)\\n.   * @param dstImage Image data of the destination frame (CV_8UC1)\\n.   * @param dstDepth Depth data of the destination frame (CV_32FC1, in meters)\\n.   * @param dstMask Mask that sets which pixels have to be used from the destination frame (CV_8UC1)\\n.   * @param Rt Resulting transformation from the source frame to the destination one (rigid body motion):\\n.   dst_p = Rt * src_p, where dst_p is a homogeneous point in the destination frame and src_p is\\n.   homogeneous point in the source frame,\\n.   Rt is 4x4 matrix of CV_64FC1 type.\\n.   * @param initRt Initial transformation from the source frame to the destination one (optional)\"},\n 43143      {\"compute2\", (PyCFunction)pyopencv_cv_rgbd_rgbd_Odometry_compute2, METH_VARARGS | METH_KEYWORDS, \"compute2(srcFrame, dstFrame[, Rt[, initRt]]) -> retval, Rt\\n.   One more method to compute a transformation from the source frame to the destination one.\\n.   * It is designed to save on computing the frame data (image pyramids, normals, etc.).\"},\n 43144      {\"create\", (PyCFunction)pyopencv_cv_rgbd_rgbd_Odometry_create_cls, METH_VARARGS | METH_KEYWORDS | METH_CLASS, \"create(odometryType) -> retval\\n.\"},\n .....\n 45960      {\"getT\", (PyCFunction)pyopencv_cv_linemod_linemod_Detector_getT, METH_VARARGS | METH_KEYWORDS, \"getT(pyramid_level) -> retval\\n.   * \\\\brief Get sampling step T at pyramid_level.\"},\n 45961      {\"getTemplates\", (PyCFunction)pyopencv_cv_linemod_linemod_Detector_getTemplates, METH_VARARGS | METH_KEYWORDS, \"getTemplates(class_id, template_id) -> retval\\n.   * \\\\brief Get the template pyramid identified by template_id.\\n.   *\\n.   * For example, with 2 modalities (Gradient, Normal) and two pyramid levels\\n.   * (L0, L1), the order is (GradientL0, NormalL0, GradientL1, NormalL1).\"},\n 45962:     {\"match\", (PyCFunction)pyopencv_cv_linemod_linemod_Detector_match, METH_VARARGS | METH_KEYWORDS, \"match(sources, threshold[, class_ids[, quantized_images[, masks]]]) -> matches, quantized_images\\n.   * \\\\brief Detect objects by template matching.\\n.   *\\n.   * Matches globally at the lowest pyramid level, then refines locally stepping up the pyramid.\\n.   *\\n.   * \\\\param      sources   Source images, one for each modality.\\n.   * \\\\param      threshold Similarity threshold, a percentage between 0 and 100.\\n.   * \\\\param[out] matches   Template matches, sorted by similarity score.\\n.   * \\\\param      class_ids If non-empty, only search for the desired object classes.\\n.   * \\\\param[out] quantized_images Optionally return vector<Mat> of quantized images.\\n.   * \\\\param      masks     The masks for consideration during matching. The masks should be CV_8UC1\\n.   *                       where 255 represents a valid pixel.  If non-empty, the vector must be\\n.   *                       the same size as sources.  Each element must be\\n.   *                       empty or the same size as its corresponding source.\"},\n 45963      {\"numClasses\", (PyCFunction)pyopencv_cv_linemod_linemod_Detector_numClasses, METH_VARARGS | METH_KEYWORDS, \"numClasses() -> retval\\n.\"},\n 45964      {\"numTemplates\", (PyCFunction)pyopencv_cv_linemod_linemod_Detector_numTemplates, METH_VARARGS | METH_KEYWORDS, \"numTemplates() -> retval\\n.   \\n\\n\\n\\nnumTemplates(class_id) -> retval\\n.\"},\n .....\n 51022  static PyMethodDef pyopencv_ximgproc_FastLineDetector_methods[] =\n 51023  {\n 51024:     {\"detect\", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_FastLineDetector_detect, METH_VARARGS | METH_KEYWORDS, \"detect(_image[, _lines]) -> _lines\\n.   @brief Finds lines in the input image.\\n.   This is the output of the default parameters of the algorithm on the above\\n.   shown image.\\n.   \\n.   ![image](pics/corridor_fld.jpg)\\n.   \\n.   @param _image A grayscale (CV_8UC1) input image. If only a roi needs to be\\n.   selected, use: `fld_ptr-\\\\>detect(image(roi), lines, ...);\\n.   lines += Scalar(roi.x, roi.y, roi.x, roi.y);`\\n.   @param _lines A vector of Vec4f elements specifying the beginning\\n.   and ending point of a line.  Where Vec4f is (x1, y1, x2, y2), point\\n.   1 is the start, point 2 - end. Returned lines are directed so that the\\n.   brighter side is on their left.\"},\n 51025      {\"drawSegments\", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_FastLineDetector_drawSegments, METH_VARARGS | METH_KEYWORDS, \"drawSegments(_image, lines[, draw_arrow]) -> _image\\n.   @brief Draws the line segments on a given image.\\n.   @param _image The image, where the lines will be drawn. Should be bigger\\n.   or equal to the image, where the lines were found.\\n.   @param lines A vector of the lines that needed to be drawn.\\n.   @param draw_arrow If true, arrow heads will be drawn.\"},\n 51026  \n .....\n 51413      int dy=1;\n 51414      int ksize=3;\n 51415:     int out_dtype=CV_8UC1;\n 51416      double scale=1;\n 51417      double delta=0;\n .....\n 51478  static PyMethodDef pyopencv_ximgproc_RidgeDetectionFilter_methods[] =\n 51479  {\n 51480:     {\"create\", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_RidgeDetectionFilter_create_cls, METH_VARARGS | METH_KEYWORDS | METH_CLASS, \"create([, ddepth[, dx[, dy[, ksize[, out_dtype[, scale[, delta[, borderType]]]]]]]]) -> retval\\n.   @brief Create pointer to the Ridge detection filter.\\n.   @param ddepth  Specifies output image depth. Defualt is CV_32FC1\\n.   @param dx Order of derivative x, default is 1\\n.   @param dy  Order of derivative y, default is 1\\n.   @param ksize Sobel kernel size , default is 3\\n.   @param out_dtype Converted format for output, default is CV_8UC1\\n.   @param scale Optional scale value for derivative values, default is 1\\n.   @param delta  Optional bias added to output, default is 0\\n.   @param borderType Pixel extrapolation method, default is BORDER_DEFAULT\\n.   @see Sobel, threshold, getStructuringElement, morphologyEx.( for additional refinement)\"},\n 51481      {\"getRidgeFilteredImage\", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_RidgeDetectionFilter_getRidgeFilteredImage, METH_VARARGS | METH_KEYWORDS, \"getRidgeFilteredImage(_img[, out]) -> out\\n.   @brief Apply Ridge detection filter on input image.\\n.   @param _img InputArray as supported by Sobel. img can be 1-Channel or 3-Channels.\\n.   @param out OutputAray of structure as RidgeDetectionFilter::ddepth. Output image with ridges.\"},\n 51482  \n .....\n 51653  static PyMethodDef pyopencv_ximgproc_SuperpixelSEEDS_methods[] =\n 51654  {\n 51655:     {\"getLabelContourMask\", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_SuperpixelSEEDS_getLabelContourMask, METH_VARARGS | METH_KEYWORDS, \"getLabelContourMask([, image[, thick_line]]) -> image\\n.   @brief Returns the mask of the superpixel segmentation stored in SuperpixelSEEDS object.\\n.   \\n.   @param image Return: CV_8UC1 image mask where -1 indicates that the pixel is a superpixel border,\\n.   and 0 otherwise.\\n.   \\n.   @param thick_line If false, the border is only one pixel wide, otherwise all pixels at the border\\n.   are masked.\\n.   \\n.   The function return the boundaries of the superpixel segmentation.\\n.   \\n.   @note\\n.   -   (Python) A demo on how to generate superpixels in images from the webcam can be found at\\n.   opencv_source_code/samples/python2/seeds.py\\n.   -   (cpp) A demo on how to generate superpixels in images from the webcam can be found at\\n.   opencv_source_code/modules/ximgproc/samples/seeds.cpp. By adding a file image as a command\\n.   line argument, the static image will be used instead of the webcam.\\n.   -   It will show a window with the video from the webcam with the superpixel boundaries marked\\n.   in red (see below). Use Space to switch between different output modes. At the top of the\\n.   window there are 4 sliders, from which the user can change on-the-fly the number of\\n.   superpixels, the number of block levels, the strength of the boundary prior term to modify\\n.   the shape, and the number of iterations at pixel level. This is useful to play with the\\n.   parameters and set them to the user convenience. In the console the frame-rate of the\\n.   algorithm is indicated.\\n.   \\n.   ![image](pics/superpixels_demo.png)\"},\n 51656      {\"getLabels\", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_SuperpixelSEEDS_getLabels, METH_VARARGS | METH_KEYWORDS, \"getLabels([, labels_out]) -> labels_out\\n.   @brief Returns the segmentation labeling of the image.\\n.   \\n.   Each label represents a superpixel, and each pixel is assigned to one superpixel label.\\n.   \\n.   @param labels_out Return: A CV_32UC1 integer array containing the labels of the superpixel\\n.   segmentation. The labels are in the range [0, getNumberOfSuperpixels()].\\n.   \\n.   The function returns an image with ssthe labels of the superpixel segmentation. The labels are in\\n.   the range [0, getNumberOfSuperpixels()].\"},\n 51657      {\"getNumberOfSuperpixels\", (PyCFunction)pyopencv_cv_ximgproc_ximgproc_SuperpixelSEEDS_getNumberOfSuperpixels, METH_VARARGS | METH_KEYWORDS, \"getNumberOfSuperpixels() -> retval\\n.   @brief Calculates the superpixel segmentation on a given image stored in SuperpixelSEEDS object.\\n.   \\n.   The function computes the superpixels segmentation of an image with the parameters initialized\\n.   with the function createSuperpixelSEEDS().\"},\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\calib3d\\src\\calibinit.cpp:\n 1979      }\n 1980  \n 1981:     line_type = type == CV_8UC1 || type == CV_8UC3 ? CV_AA : 8;\n 1982  \n 1983      if( !found )\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\calib3d\\src\\calibration.cpp:\n 2744      int stype = disparity.type();\n 2745  \n 2746:     CV_Assert( stype == CV_8UC1 || stype == CV_16SC1 ||\n 2747                 stype == CV_32SC1 || stype == CV_32FC1 );\n 2748      CV_Assert( Q.size() == Size(4,4) );\n ....\n 2782          Vec3f* dptr = dbuf;\n 2783  \n 2784:         if( stype == CV_8UC1 )\n 2785          {\n 2786              const uchar* sptr0 = disparity.ptr<uchar>(y);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\calib3d\\src\\circlesgrid.cpp:\n   86  \n   87      Mat dists(n, n, CV_32FC1, Scalar(0));\n   88:     Mat distsMask(dists.size(), CV_8UC1, Scalar(0));\n   89      for(int i = 0; i < n; i++)\n   90      {\n   ..\n  154  \n  155  #ifdef DEBUG_CIRCLES\n  156:   Mat patternPointsImage(1024, 1248, CV_8UC1, Scalar(0));\n  157    drawPoints(patternPoints, patternPointsImage);\n  158    imshow(\"pattern points\", patternPointsImage);\n  ...\n  227  \n  228  #ifdef DEBUG_CIRCLES\n  229:   Mat cornersImage(1024, 1248, CV_8UC1, Scalar(0));\n  230    drawPoints(corners, cornersImage);\n  231    imshow(\"corners\", cornersImage);\n  ...\n  265  \n  266  #ifdef DEBUG_CIRCLES\n  267:   Mat linesImage(1024, 1248, CV_8UC1, Scalar(0));\n  268    line(linesImage, corners[maxLoc.y], corners[(maxLoc.y + 1) % n], Scalar(255));\n  269    line(linesImage, corners[maxLoc.x], corners[(maxLoc.x + 1) % n], Scalar(255));\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\calib3d\\src\\rho.cpp:\n  862  \n  863      /* Allocate dynamic memory managed by cv::Mat */\n  864:     mem.perObj.create(1, (int)(total + MEM_ALIGN), CV_8UC1);\n  865  \n  866      /* Extract aligned pointer */\n  ...\n  902  \n  903      /* Allocate dynamic memory managed by cv::Mat */\n  904:     mem.perRun.create(1, (int)(total + MEM_ALIGN), CV_8UC1);\n  905  \n  906      /* Extract aligned pointer */\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\calib3d\\src\\solvepnp.cpp:\n  313  \n  314      Mat _local_model(3, 2, CV_64FC1);\n  315:     Mat _mask_local_inliers(1, opoints.rows, CV_8UC1);\n  316  \n  317      // call Ransac\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\calib3d\\src\\stereobm.cpp:\n 1070              CV_Error( Error::StsUnmatchedSizes, \"All the images must have the same size\" );\n 1071  \n 1072:         if (leftarr.type() != CV_8UC1 || rightarr.type() != CV_8UC1)\n 1073:             CV_Error( Error::StsUnsupportedFormat, \"Both input images must have CV_8UC1\" );\n 1074  \n 1075          if (dtype != CV_16SC1 && dtype != CV_32FC1)\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\calib3d\\src\\stereosgbm.cpp:\n 2430      int type = img.type();\n 2431      Mat temp, &_buf = __buf.needed() ? __buf.getMatRef() : temp;\n 2432:     CV_Assert( type == CV_8UC1 || type == CV_16SC1 );\n 2433  \n 2434      int newVal = cvRound(_newval), maxDiff = cvRound(_maxDiff);\n ....\n 2436      CV_IPP_RUN_FAST(ipp_filterSpeckles(img, maxSpeckleSize, newVal, maxDiff, _buf));\n 2437  \n 2438:     if (type == CV_8UC1)\n 2439          filterSpecklesImpl<uchar>(img, newVal, maxSpeckleSize, maxDiff, _buf);\n 2440      else\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\calib3d\\test\\test_cornerssubpix.cpp:\n  128      const int max_pattern_size = 8;\n  129      const int min_pattern_size = 5;\n  130:     Mat bg(image_size_, CV_8UC1);\n  131      bg = Scalar(0);\n  132  \n  ...\n  245  TEST(Calib3d_CornerSubPix, regression_7204)\n  246  {\n  247:     cv::Mat image(cv::Size(70, 38), CV_8UC1, cv::Scalar::all(0));\n  248      image(cv::Rect(65, 26, 5, 5)).setTo(cv::Scalar::all(255));\n  249      image(cv::Rect(55, 31, 8, 1)).setTo(cv::Scalar::all(255));\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\calib3d\\test\\test_fundam.cpp:\n  878      types[TEMP][0] = CV_64FC1;\n  879      sizes[TEMP][1] = cvSize(pt_count,1);\n  880:     types[TEMP][1] = CV_8UC1;\n  881  \n  882      sizes[OUTPUT][0] = sizes[REF_OUTPUT][0] = cvSize(3,1);\n  883      types[OUTPUT][0] = types[REF_OUTPUT][0] = CV_64FC1;\n  884      sizes[OUTPUT][1] = sizes[REF_OUTPUT][1] = cvSize(pt_count,1);\n  885:     types[OUTPUT][1] = types[REF_OUTPUT][1] = CV_8UC1;\n  886  \n  887      test_cpp = (cvtest::randInt(rng) & 256) == 0;\n  ...\n 1169      types[TEMP][0] = CV_64FC1;\n 1170      sizes[TEMP][1] = cvSize(pt_count,1);\n 1171:     types[TEMP][1] = CV_8UC1;\n 1172      sizes[TEMP][2] = cvSize(3,3);\n 1173      types[TEMP][2] = CV_64FC1;\n ....\n 1175      types[TEMP][3] = CV_64FC1;\n 1176      sizes[TEMP][4] = cvSize(pt_count,1);\n 1177:     types[TEMP][4] = CV_8UC1;\n 1178  \n 1179      sizes[OUTPUT][0] = sizes[REF_OUTPUT][0] = cvSize(3,1);\n 1180      types[OUTPUT][0] = types[REF_OUTPUT][0] = CV_64FC1;\n 1181      sizes[OUTPUT][1] = sizes[REF_OUTPUT][1] = cvSize(pt_count,1);\n 1182:     types[OUTPUT][1] = types[REF_OUTPUT][1] = CV_8UC1;\n 1183      sizes[OUTPUT][2] = sizes[REF_OUTPUT][2] = cvSize(1,1);\n 1184      types[OUTPUT][2] = types[REF_OUTPUT][2] = CV_64FC1;\n 1185      sizes[OUTPUT][3] = sizes[REF_OUTPUT][3] = cvSize(1,1);\n 1186:     types[OUTPUT][3] = types[REF_OUTPUT][3] = CV_8UC1;\n 1187  \n 1188  }\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\calib3d\\test\\test_homography.cpp:\n  399          rng.fill(noise_2f, RNG::NORMAL, Scalar::all(0), Scalar::all(sigma));\n  400  \n  401:         cv::Mat mask(N, 1, CV_8UC1);\n  402  \n  403          for (int i = 0; i < N; ++i)\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\calib3d\\test\\test_modelest.cpp:\n  124  \n  125      sizes[OUTPUT][0] = sizes[REF_OUTPUT][0] = cvSize(1, 1);\n  126:     types[OUTPUT][0] = types[REF_OUTPUT][0] = CV_8UC1;\n  127  }\n  128  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\calib3d\\test\\test_stereomatching.cpp:\n  107      if( mask.empty() )\n  108          CV_Error( Error::StsBadArg, \"mask is empty\" );\n  109:     if( mask.type() != CV_8UC1 )\n  110:         CV_Error( Error::StsBadArg, \"mask must have CV_8UC1 type\" );\n  111      if( mask.rows != sz.height || mask.cols != sz.width )\n  112          CV_Error( Error::StsBadArg, \"mask has incorrect size\" );\n  ...\n  185      if( occludedMask )\n  186      {\n  187:         occludedMask->create(leftDisp.size(), CV_8UC1);\n  188          occludedMask->setTo(Scalar::all(0) );\n  189      }\n  190      if( nonOccludedMask )\n  191      {\n  192:         nonOccludedMask->create(leftDisp.size(), CV_8UC1);\n  193          nonOccludedMask->setTo(Scalar::all(0) );\n  194      }\n  ...\n  240      if( !unknDispMask.empty() )\n  241          curDisp.setTo( Scalar(numeric_limits<float>::min()), unknDispMask );\n  242:     Mat maxNeighbDisp; dilate( curDisp, maxNeighbDisp, Mat(3, 3, CV_8UC1, Scalar(1)) );\n  243      if( !unknDispMask.empty() )\n  244          curDisp.setTo( Scalar(numeric_limits<float>::max()), unknDispMask );\n  245:     Mat minNeighbDisp; erode( curDisp, minNeighbDisp, Mat(3, 3, CV_8UC1, Scalar(1)) );\n  246      depthDiscontMask = max( (Mat)(maxNeighbDisp-disp), (Mat)(disp-minNeighbDisp) ) > dispGap;\n  247      if( !unknDispMask.empty() )\n  248          depthDiscontMask &= ~unknDispMask;\n  249:     dilate( depthDiscontMask, depthDiscontMask, Mat(discontWidth, discontWidth, CV_8UC1, Scalar(1)) );\n  250  }\n  251  \n  ...\n  256  {\n  257      CV_Assert( border >= 0 );\n  258:     Mat mask(maskSize, CV_8UC1, Scalar(0));\n  259      int w = maskSize.width - 2*border, h = maskSize.height - 2*border;\n  260      if( w < 0 ||  h < 0 )\n  ...\n  568      absdiff( trueLeftDisp, Scalar(params.dispUnknVal), leftUnknMask );\n  569      leftUnknMask = leftUnknMask < numeric_limits<float>::epsilon();\n  570:     assert(leftUnknMask.type() == CV_8UC1);\n  571      if( !trueRightDisp.empty() )\n  572      {\n  573          absdiff( trueRightDisp, Scalar(params.dispUnknVal), rightUnknMask );\n  574          rightUnknMask = rightUnknMask < numeric_limits<float>::epsilon();\n  575:         assert(rightUnknMask.type() == CV_8UC1);\n  576      }\n  577  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\include\\opencv2\\core.hpp:\n  600      Point pnt = locations[i];\n  601  @endcode\n  602: @param src single-channel array (type CV_8UC1)\n  603  @param idx the output array, type of cv::Mat or std::vector<Point>, corresponding to non-zero indices in the input\n  604  */\n  ...\n  675  @param src1 first input array.\n  676  @param normType type of the norm (see cv::NormTypes).\n  677: @param mask optional operation mask; it must have the same size as src1 and CV_8UC1 type.\n  678  */\n  679  CV_EXPORTS_W double norm(InputArray src1, int normType = NORM_L2, InputArray mask = noArray());\n  ...\n  688  @param src2 second input array of the same size and the same type as src1.\n  689  @param normType type of the norm (cv::NormTypes).\n  690: @param mask optional operation mask; it must have the same size as src1 and CV_8UC1 type.\n  691  */\n  692  CV_EXPORTS_W double norm(InputArray src1, InputArray src2,\n  ...\n  948      Mat bgra( 100, 100, CV_8UC4, Scalar(255,0,0,255) );\n  949      Mat bgr( bgra.rows, bgra.cols, CV_8UC3 );\n  950:     Mat alpha( bgra.rows, bgra.cols, CV_8UC1 );\n  951  \n  952      // forming an array of matrices is a quite efficient operation,\n  ...\n 1109  The function horizontally concatenates two or more cv::Mat matrices (with the same number of rows).\n 1110  @code{.cpp}\n 1111:     cv::Mat matArray[] = { cv::Mat(4, 1, CV_8UC1, cv::Scalar(1)),\n 1112:                            cv::Mat(4, 1, CV_8UC1, cv::Scalar(2)),\n 1113:                            cv::Mat(4, 1, CV_8UC1, cv::Scalar(3)),};\n 1114  \n 1115      cv::Mat out;\n ....\n 1150  /** @overload\n 1151   @code{.cpp}\n 1152:     std::vector<cv::Mat> matrices = { cv::Mat(4, 1, CV_8UC1, cv::Scalar(1)),\n 1153:                                       cv::Mat(4, 1, CV_8UC1, cv::Scalar(2)),\n 1154:                                       cv::Mat(4, 1, CV_8UC1, cv::Scalar(3)),};\n 1155  \n 1156      cv::Mat out;\n ....\n 1172  The function vertically concatenates two or more cv::Mat matrices (with the same number of cols).\n 1173  @code{.cpp}\n 1174:     cv::Mat matArray[] = { cv::Mat(1, 4, CV_8UC1, cv::Scalar(1)),\n 1175:                            cv::Mat(1, 4, CV_8UC1, cv::Scalar(2)),\n 1176:                            cv::Mat(1, 4, CV_8UC1, cv::Scalar(3)),};\n 1177  \n 1178      cv::Mat out;\n ....\n 1215  /** @overload\n 1216   @code{.cpp}\n 1217:     std::vector<cv::Mat> matrices = { cv::Mat(1, 4, CV_8UC1, cv::Scalar(1)),\n 1218:                                       cv::Mat(1, 4, CV_8UC1, cv::Scalar(2)),\n 1219:                                       cv::Mat(1, 4, CV_8UC1, cv::Scalar(3)),};\n 1220  \n 1221      cv::Mat out;\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\include\\opencv2\\core\\core_c.h:\n 2859      //! returns the number of elements in the sequence\n 2860      size_t size() const;\n 2861:     //! returns the type of sequence elements (CV_8UC1 ... CV_64FC(CV_CN_MAX) ...)\n 2862      int type() const;\n 2863      //! returns the depth of sequence elements (CV_8U ... CV_64F)\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\include\\opencv2\\core\\hal\\interface.h:\n   80  #define CV_MAKE_TYPE CV_MAKETYPE\n   81  \n   82: #define CV_8UC1 CV_MAKETYPE(CV_8U,1)\n   83  #define CV_8UC2 CV_MAKETYPE(CV_8U,2)\n   84  #define CV_8UC3 CV_MAKETYPE(CV_8U,3)\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\include\\opencv2\\core\\mat.hpp:\n  609  - Use the create(nrows, ncols, type) method or the similar Mat(nrows, ncols, type[, fillValue])\n  610  constructor. A new array of the specified size and type is allocated. type has the same meaning as\n  611: in the cvCreateMat method. For example, CV_8UC1 means a 8-bit single-channel array, CV_32FC2\n  612  means a 2-channel (complex) floating-point array, and so on.\n  613  @code\n  ...\n  788      @param rows Number of rows in a 2D array.\n  789      @param cols Number of columns in a 2D array.\n  790:     @param type Array type. Use CV_8UC1, ..., CV_64FC4 to create 1-4 channel matrices, or\n  791      CV_8UC(n), ..., CV_64FC(n) to create multi-channel (up to CV_CN_MAX channels) matrices.\n  792      */\n  ...\n  796      @param size 2D array size: Size(cols, rows) . In the Size() constructor, the number of rows and the\n  797      number of columns go in the reverse order.\n  798:     @param type Array type. Use CV_8UC1, ..., CV_64FC4 to create 1-4 channel matrices, or\n  799      CV_8UC(n), ..., CV_64FC(n) to create multi-channel (up to CV_CN_MAX channels) matrices.\n  800        */\n  ...\n  804      @param rows Number of rows in a 2D array.\n  805      @param cols Number of columns in a 2D array.\n  806:     @param type Array type. Use CV_8UC1, ..., CV_64FC4 to create 1-4 channel matrices, or\n  807      CV_8UC(n), ..., CV_64FC(n) to create multi-channel (up to CV_CN_MAX channels) matrices.\n  808      @param s An optional value to initialize each matrix element with. To set all the matrix elements to\n  ...\n  815      @param size 2D array size: Size(cols, rows) . In the Size() constructor, the number of rows and the\n  816      number of columns go in the reverse order.\n  817:     @param type Array type. Use CV_8UC1, ..., CV_64FC4 to create 1-4 channel matrices, or\n  818      CV_8UC(n), ..., CV_64FC(n) to create multi-channel (up to CV_CN_MAX channels) matrices.\n  819      @param s An optional value to initialize each matrix element with. To set all the matrix elements to\n  ...\n  826      @param ndims Array dimensionality.\n  827      @param sizes Array of integers specifying an n-dimensional array shape.\n  828:     @param type Array type. Use CV_8UC1, ..., CV_64FC4 to create 1-4 channel matrices, or\n  829      CV_8UC(n), ..., CV_64FC(n) to create multi-channel (up to CV_CN_MAX channels) matrices.\n  830      */\n  ...\n  833      /** @overload\n  834      @param sizes Array of integers specifying an n-dimensional array shape.\n  835:     @param type Array type. Use CV_8UC1, ..., CV_64FC4 to create 1-4 channel matrices, or\n  836      CV_8UC(n), ..., CV_64FC(n) to create multi-channel (up to CV_CN_MAX channels) matrices.\n  837      */\n  ...\n  841      @param ndims Array dimensionality.\n  842      @param sizes Array of integers specifying an n-dimensional array shape.\n  843:     @param type Array type. Use CV_8UC1, ..., CV_64FC4 to create 1-4 channel matrices, or\n  844      CV_8UC(n), ..., CV_64FC(n) to create multi-channel (up to CV_CN_MAX channels) matrices.\n  845      @param s An optional value to initialize each matrix element with. To set all the matrix elements to\n  ...\n  851      /** @overload\n  852      @param sizes Array of integers specifying an n-dimensional array shape.\n  853:     @param type Array type. Use CV_8UC1, ..., CV_64FC4 to create 1-4 channel matrices, or\n  854      CV_8UC(n), ..., CV_64FC(n) to create multi-channel (up to CV_CN_MAX channels) matrices.\n  855      @param s An optional value to initialize each matrix element with. To set all the matrix elements to\n  ...\n  872      @param rows Number of rows in a 2D array.\n  873      @param cols Number of columns in a 2D array.\n  874:     @param type Array type. Use CV_8UC1, ..., CV_64FC4 to create 1-4 channel matrices, or\n  875      CV_8UC(n), ..., CV_64FC(n) to create multi-channel (up to CV_CN_MAX channels) matrices.\n  876      @param data Pointer to the user data. Matrix constructors that take data and step parameters do not\n  ...\n  888      @param size 2D array size: Size(cols, rows) . In the Size() constructor, the number of rows and the\n  889      number of columns go in the reverse order.\n  890:     @param type Array type. Use CV_8UC1, ..., CV_64FC4 to create 1-4 channel matrices, or\n  891      CV_8UC(n), ..., CV_64FC(n) to create multi-channel (up to CV_CN_MAX channels) matrices.\n  892      @param data Pointer to the user data. Matrix constructors that take data and step parameters do not\n  ...\n  904      @param ndims Array dimensionality.\n  905      @param sizes Array of integers specifying an n-dimensional array shape.\n  906:     @param type Array type. Use CV_8UC1, ..., CV_64FC4 to create 1-4 channel matrices, or\n  907      CV_8UC(n), ..., CV_64FC(n) to create multi-channel (up to CV_CN_MAX channels) matrices.\n  908      @param data Pointer to the user data. Matrix constructors that take data and step parameters do not\n  ...\n  918      /** @overload\n  919      @param sizes Array of integers specifying an n-dimensional array shape.\n  920:     @param type Array type. Use CV_8UC1, ..., CV_64FC4 to create 1-4 channel matrices, or\n  921      CV_8UC(n), ..., CV_64FC(n) to create multi-channel (up to CV_CN_MAX channels) matrices.\n  922      @param data Pointer to the user data. Matrix constructors that take data and step parameters do not\n  ...\n 2354      UMat(UMatUsageFlags usageFlags = USAGE_DEFAULT);\n 2355      //! constructs 2D matrix of the specified size and type\n 2356:     // (_type is CV_8UC1, CV_64FC3, CV_32SC(12) etc.)\n 2357      UMat(int rows, int cols, int type, UMatUsageFlags usageFlags = USAGE_DEFAULT);\n 2358      UMat(Size size, int type, UMatUsageFlags usageFlags = USAGE_DEFAULT);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\include\\opencv2\\core\\opengl.hpp:\n  107      @param arows Number of rows in a 2D array.\n  108      @param acols Number of columns in a 2D array.\n  109:     @param atype Array type ( CV_8UC1, ..., CV_64FC4 ). See Mat for details.\n  110      @param abufId Buffer object name.\n  111      @param autoRelease Auto release mode (if true, release will be called in object's destructor).\n  ...\n  115      /** @overload\n  116      @param asize 2D array size.\n  117:     @param atype Array type ( CV_8UC1, ..., CV_64FC4 ). See Mat for details.\n  118      @param abufId Buffer object name.\n  119      @param autoRelease Auto release mode (if true, release will be called in object's destructor).\n  ...\n  124      @param arows Number of rows in a 2D array.\n  125      @param acols Number of columns in a 2D array.\n  126:     @param atype Array type ( CV_8UC1, ..., CV_64FC4 ). See Mat for details.\n  127      @param target Buffer usage. See cv::ogl::Buffer::Target .\n  128      @param autoRelease Auto release mode (if true, release will be called in object's destructor).\n  ...\n  132      /** @overload\n  133      @param asize 2D array size.\n  134:     @param atype Array type ( CV_8UC1, ..., CV_64FC4 ). See Mat for details.\n  135      @param target Buffer usage. See cv::ogl::Buffer::Target .\n  136      @param autoRelease Auto release mode (if true, release will be called in object's destructor).\n  ...\n  149      @param arows Number of rows in a 2D array.\n  150      @param acols Number of columns in a 2D array.\n  151:     @param atype Array type ( CV_8UC1, ..., CV_64FC4 ). See Mat for details.\n  152      @param target Buffer usage. See cv::ogl::Buffer::Target .\n  153      @param autoRelease Auto release mode (if true, release will be called in object's destructor).\n  ...\n  157      /** @overload\n  158      @param asize 2D array size.\n  159:     @param atype Array type ( CV_8UC1, ..., CV_64FC4 ). See Mat for details.\n  160      @param target Buffer usage. See cv::ogl::Buffer::Target .\n  161      @param autoRelease Auto release mode (if true, release will be called in object's destructor).\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\include\\opencv2\\core\\traits.hpp:\n   62  short, int, float, double, or a tuple of values of one of these types, where all the values in the\n   63  tuple have the same type. Any primitive type from the list can be defined by an identifier in the\n   64: form CV_\\<bit-depth\\>{U|S|F}C(\\<number_of_channels\\>), for example: uchar \\~ CV_8UC1, 3-element\n   65  floating-point tuple \\~ CV_32FC3, and so on. A universal OpenCV structure that is able to store a\n   66  single instance of such a primitive data type is Vec. Multiple instances of such a type can be\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\include\\opencv2\\core\\types_c.h:\n 1402  \n 1403  #define CV_SEQ_ELTYPE_POINT          CV_32SC2  /**< (x,y) */\n 1404: #define CV_SEQ_ELTYPE_CODE           CV_8UC1   /**< freeman code: 0..7 */\n 1405  #define CV_SEQ_ELTYPE_GENERIC        0\n 1406  #define CV_SEQ_ELTYPE_PTR            CV_USRTYPE1\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\perf\\cuda\\perf_gpumat.cpp:\n   99  \n  100      cv::Mat src(size, type);\n  101:     cv::Mat mask(size, CV_8UC1);\n  102      declare.in(src, mask, WARMUP_RNG);\n  103  \n  ...\n  136  \n  137      cv::Mat src(size, type);\n  138:     cv::Mat mask(size, CV_8UC1);\n  139      declare.in(src, mask, WARMUP_RNG);\n  140  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\perf\\opencl\\perf_arithm.cpp:\n  443  OCL_PERF_TEST_P(CountNonZeroFixture, CountNonZero,\n  444                  ::testing::Combine(OCL_TEST_SIZES,\n  445:                                OCL_PERF_ENUM(CV_8UC1, CV_32FC1)))\n  446  {\n  447      const Size_MatType_t params = GetParam();\n  ...\n  751      checkDeviceMaxMemoryAllocSize(srcSize, type);\n  752  \n  753:     UMat src(srcSize, type), mask(srcSize, CV_8UC1);\n  754      Scalar mean, stddev;\n  755      declare.in(src, mask, WARMUP_RNG);\n  ...\n  936      checkDeviceMaxMemoryAllocSize(srcSize, type);\n  937  \n  938:     UMat src(srcSize, type), lb(srcSize, type), ub(srcSize, type), dst(srcSize, CV_8UC1);\n  939      declare.in(src, lb, ub, WARMUP_RNG).out(dst);\n  940  \n  ...\n  970  \n  971  OCL_PERF_TEST_P(NormalizeFixture, NormalizeWithMask,\n  972:                 ::testing::Combine(OCL_TEST_SIZES, OCL_PERF_ENUM(CV_8UC1, CV_32FC1),\n  973                                     NormalizeModes::all()))\n  974  {\n  ...\n  979      checkDeviceMaxMemoryAllocSize(srcSize, type);\n  980  \n  981:     UMat src(srcSize, type), mask(srcSize, CV_8UC1), dst(srcSize, type);\n  982      declare.in(src, mask, WARMUP_RNG).out(dst);\n  983  \n  ...\n 1096  \n 1097  OCL_PERF_TEST_P(PSNRFixture, PSNR,\n 1098:                 ::testing::Combine(OCL_TEST_SIZES, OCL_PERF_ENUM(CV_8UC1, CV_8UC4)))\n 1099  {\n 1100      const Size_MatType_t params = GetParam();\n ....\n 1122  OCL_PERF_TEST_P(ReduceMinMaxFixture, Reduce,\n 1123                  ::testing::Combine(OCL_TEST_SIZES,\n 1124:                                    OCL_PERF_ENUM(std::make_pair<MatType, MatType>(CV_8UC1, CV_8UC1),\n 1125                                                   std::make_pair<MatType, MatType>(CV_32FC4, CV_32FC4)),\n 1126                                     OCL_PERF_ENUM(0, 1),\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\perf\\opencl\\perf_bufferpool.cpp:\n   58          for (int i = 0; i < 100; i++)\n   59          {\n   60:             UMat u(sz, CV_8UC1);\n   61          }\n   62      }\n   ..\n   75          for (int i = 0; i < 100; i++)\n   76          {\n   77:             UMat u(sz, CV_8UC1);\n   78              countNonZero(u);\n   79          }\n   ..\n   98          for (int i = 0; i < 10; i++)\n   99          {\n  100:             UMat src(sz, CV_8UC1);\n  101              UMat dst;\n  102              Canny(src, dst, thresh_low, thresh_high, aperture, useL2);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\perf\\opencl\\perf_matop.cpp:\n   50      checkDeviceMaxMemoryAllocSize(srcSize, type);\n   51  \n   52:     UMat src(srcSize, type), mask(srcSize, CV_8UC1);\n   53      declare.in(src, mask, WARMUP_RNG).out(src);\n   54  \n   ..\n  115      checkDeviceMaxMemoryAllocSize(srcSize, type);\n  116  \n  117:     UMat src(srcSize, type), dst(srcSize, type), mask(srcSize, CV_8UC1);\n  118      declare.in(src, mask, WARMUP_RNG).out(dst);\n  119  \n  ...\n  132      checkDeviceMaxMemoryAllocSize(srcSize, type);\n  133  \n  134:     UMat src(srcSize, type), dst, mask(srcSize, CV_8UC1);\n  135      declare.in(src, mask, WARMUP_RNG);\n  136  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\perf\\opencl\\perf_usage_flags.cpp:\n   20      bool allocHostMem = get<1>(GetParam());\n   21  \n   22:     UMat src(sz, CV_8UC1, Scalar::all(128));\n   23  \n   24      OCL_TEST_CYCLE()\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\perf\\perf_addWeighted.cpp:\n    7  using std::tr1::get;\n    8  \n    9: #define TYPICAL_MAT_TYPES_ADWEIGHTED  CV_8UC1, CV_8UC4, CV_8SC1, CV_16UC1, CV_16SC1, CV_32SC1\n   10  #define TYPICAL_MATS_ADWEIGHTED       testing::Combine(testing::Values(szVGA, sz720p, sz1080p), testing::Values(TYPICAL_MAT_TYPES_ADWEIGHTED))\n   11  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\perf\\perf_arithm.cpp:\n    8  \n    9  #define TYPICAL_MAT_SIZES_CORE_ARITHM   ::szVGA, ::sz720p, ::sz1080p\n   10: #define TYPICAL_MAT_TYPES_CORE_ARITHM   CV_8UC1, CV_8SC1, CV_16SC1, CV_16SC2, CV_16SC3, CV_16SC4, CV_8UC4, CV_32SC1, CV_32FC1\n   11  #define TYPICAL_MATS_CORE_ARITHM        testing::Combine( testing::Values( TYPICAL_MAT_SIZES_CORE_ARITHM ), testing::Values( TYPICAL_MAT_TYPES_CORE_ARITHM ) )\n   12  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\perf\\perf_bitwise.cpp:\n    8  \n    9  #define TYPICAL_MAT_SIZES_BITW_ARITHM  TYPICAL_MAT_SIZES\n   10: #define TYPICAL_MAT_TYPES_BITW_ARITHM  CV_8UC1, CV_8SC1, CV_8UC4, CV_32SC1, CV_32SC4\n   11  #define TYPICAL_MATS_BITW_ARITHM       testing::Combine(testing::Values(TYPICAL_MAT_SIZES_BITW_ARITHM), testing::Values(TYPICAL_MAT_TYPES_BITW_ARITHM))\n   12  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\perf\\perf_compare.cpp:\n   15               testing::Combine(\n   16                   testing::Values(::perf::szVGA, ::perf::sz1080p),\n   17:                  testing::Values(CV_8UC1, CV_8UC4, CV_8SC1, CV_16UC1, CV_16SC1, CV_32SC1, CV_32FC1),\n   18                   CmpType::all()\n   19                   )\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\perf\\perf_dot.cpp:\n   12  PERF_TEST_P( MatType_Length, dot,\n   13               testing::Combine(\n   14:                  testing::Values( CV_8UC1, CV_32SC1, CV_32FC1 ),\n   15                   testing::Values( 32, 64, 128, 256, 512, 1024 )\n   16                   ))\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\perf\\perf_inRange.cpp:\n    7  using std::tr1::get;\n    8  \n    9: #define TYPICAL_MAT_TYPES_INRANGE  CV_8UC1, CV_8UC4, CV_8SC1, CV_16UC1, CV_16SC1, CV_32SC1, CV_32FC1, CV_32FC4\n   10  #define TYPICAL_MATS_INRANGE       testing::Combine(testing::Values(szVGA, sz720p, sz1080p), testing::Values(TYPICAL_MAT_TYPES_INRANGE))\n   11  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\perf\\perf_io_base64.cpp:\n   11  \n   12  #define MAT_SIZES      ::perf::sz1080p/*, ::perf::sz4320p*/\n   13: #define MAT_TYPES      CV_8UC1, CV_32FC1\n   14  #define FILE_EXTENSION String(\".xml\"), String(\".yml\"), String(\".json\")\n   15  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\perf\\perf_lut.cpp:\n   15      int maxValue = 255;\n   16  \n   17:     Mat src(sz, CV_8UC1);\n   18      randu(src, 0, maxValue);\n   19:     Mat lut(1, 256, CV_8UC1);\n   20      randu(lut, 0, maxValue);\n   21:     Mat dst(sz, CV_8UC1);\n   22  \n   23      TEST_CYCLE() LUT(src, lut, dst);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\perf\\perf_minmaxloc.cpp:\n    9  PERF_TEST_P(Size_MatType, minMaxLoc, testing::Combine(\n   10                   testing::Values(TYPICAL_MAT_SIZES),\n   11:                  testing::Values(CV_8UC1, CV_8SC1, CV_16UC1, CV_16SC1, CV_32SC1,  CV_32FC1, CV_64FC1)\n   12                   )\n   13               )\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\perf\\perf_norm.cpp:\n    8  \n    9  #define HAMMING_NORM_SIZES cv::Size(640, 480), cv::Size(1920, 1080)\n   10: #define HAMMING_NORM_TYPES CV_8UC1\n   11  \n   12  CV_FLAGS(NormType, NORM_HAMMING2, NORM_HAMMING, NORM_INF, NORM_L1, NORM_L2, NORM_TYPE_MASK, NORM_RELATIVE, NORM_MINMAX)\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\perf\\perf_sort.cpp:\n   10  \n   11  #define TYPICAL_MAT_SIZES_SORT  TYPICAL_MAT_SIZES\n   12: #define TYPICAL_MAT_TYPES_SORT  CV_8UC1, CV_16UC1, CV_32FC1\n   13  #define SORT_TYPES              SORT_EVERY_ROW | SORT_ASCENDING, SORT_EVERY_ROW | SORT_DESCENDING\n   14  #define TYPICAL_MATS_SORT       testing::Combine( testing::Values(TYPICAL_MAT_SIZES_SORT), testing::Values(TYPICAL_MAT_TYPES_SORT), testing::Values(SORT_TYPES) )\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\perf\\perf_stat.cpp:\n   88  }\n   89  \n   90: PERF_TEST_P(Size_MatType, countNonZero, testing::Combine( testing::Values( TYPICAL_MAT_SIZES ), testing::Values( CV_8UC1, CV_8SC1, CV_16UC1, CV_16SC1, CV_32SC1, CV_32FC1, CV_64FC1 ) ))\n   91  {\n   92      Size sz = get<0>(GetParam());\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\perf\\perf_umat.cpp:\n   38      OpenCLState s(get<1>(GetParam()));\n   39  \n   40:     int type = CV_8UC1;\n   41      cv::Size size = get<0>(GetParam());\n   42      size_t align_base = 4096;\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\src\\arithm.cpp:\n  713      {\n  714          int mtype = _mask.type();\n  715:         CV_Assert( (mtype == CV_8UC1 || mtype == CV_8SC1) && _mask.sameSize(*psrc1) );\n  716          reallocate = !_dst.sameSize(*psrc1) || _dst.type() != dtype;\n  717      }\n  ...\n 1682          return false;\n 1683  \n 1684:     _dst.create(ssize, CV_8UC1);\n 1685      UMat src = _src.getUMat(), dst = _dst.getUMat(), lscalaru, uscalaru;\n 1686      Mat lscalar, uscalar;\n ....\n 1787      size_t blocksize0 = (size_t)(BLOCK_SIZE + esz-1)/esz;\n 1788  \n 1789:     _dst.create(src.dims, src.size, CV_8UC1);\n 1790      Mat dst = _dst.getMat();\n 1791      InRangeFunc func = getInRangeFunc(depth);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\src\\array.cpp:\n 1468      switch( depth )\n 1469      {\n 1470:     case CV_8UC1:\n 1471          while( cn-- )\n 1472          {\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\src\\convert.cpp:\n 5348  static bool openvx_LUT(Mat src, Mat dst, Mat _lut)\n 5349  {\n 5350:     if (src.type() != CV_8UC1 || dst.type() != src.type() || _lut.type() != src.type() || !_lut.isContinuous())\n 5351          return false;\n 5352  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\src\\directx.cpp:\n  131      //case DXGI_FORMAT_R8_TYPELESS:\n  132      case DXGI_FORMAT_R8_UNORM:\n  133:     case DXGI_FORMAT_R8_UINT: return CV_8UC1;\n  134      case DXGI_FORMAT_R8_SNORM:\n  135      case DXGI_FORMAT_R8_SINT: return CV_8SC1;\n  136:     case DXGI_FORMAT_A8_UNORM: return CV_8UC1;\n  137      //case DXGI_FORMAT_R1_UNORM:\n  138      //case DXGI_FORMAT_R9G9B9E5_SHAREDEXP:\n  ...\n  196      //case D3DFMT_A4R4G4B4:\n  197      //case D3DFMT_R3G3B2:\n  198:     case D3DFMT_A8: return CV_8UC1;\n  199      //case D3DFMT_A8R3G3B2:\n  200      //case D3DFMT_X4R4G4B4:\n  ...\n  207  \n  208      case D3DFMT_A8P8: return CV_8UC2;\n  209:     case D3DFMT_P8: return CV_8UC1;\n  210  \n  211:     case D3DFMT_L8: return CV_8UC1;\n  212      case D3DFMT_A8L8: return CV_8UC2;\n  213      //case D3DFMT_A4L4:\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\src\\dxt.cpp:\n 2465      size_t bufferSize = 0;\n 2466      CLAMDDFT_Assert(clAmdFftGetTmpBufSize(plHandle, &bufferSize))\n 2467:     UMat tmpBuffer(1, (int)bufferSize, CV_8UC1);\n 2468  \n 2469      cl_mem srcarg = (cl_mem)src.handle(ACCESS_READ);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\src\\lda.cpp:\n  148      switch (m.type()) {\n  149          case CV_8SC1: return isSymmetric_<char>(m); break;\n  150:         case CV_8UC1:\n  151              return isSymmetric_<unsigned char>(m); break;\n  152          case CV_16SC1:\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\src\\matrix.cpp:\n  850  {\n  851      size_t esz = 1;\n  852:     int mtype = CV_8UC1;\n  853      if (!empty())\n  854      {\n  ...\n 3453          CV_SUPPRESS_DEPRECATED_START\n 3454          ippiTranspose_I =\n 3455:             type == CV_8UC1 ? (IppiTransposeI)ippiTranspose_8u_C1IR :\n 3456              type == CV_8UC3 ? (IppiTransposeI)ippiTranspose_8u_C3IR :\n 3457              type == CV_8UC4 ? (IppiTransposeI)ippiTranspose_8u_C4IR :\n ....\n 3473      {\n 3474          ippiTranspose =\n 3475:             type == CV_8UC1 ? (IppiTranspose)ippiTranspose_8u_C1R :\n 3476              type == CV_8UC3 ? (IppiTranspose)ippiTranspose_8u_C3R :\n 3477              type == CV_8UC4 ? (IppiTranspose)ippiTranspose_8u_C4R :\n ....\n 3744      {\n 3745          ippiSum =\n 3746:             stype == CV_8UC1 ? (IppiSum)ippiSum_8u_C1R :\n 3747              stype == CV_8UC3 ? (IppiSum)ippiSum_8u_C3R :\n 3748              stype == CV_8UC4 ? (IppiSum)ippiSum_8u_C4R :\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\src\\ocl.cpp:\n 4585      }\n 4586  \n 4587:     int type = CV_8UC1;\n 4588      switch (fmt.image_channel_order)\n 4589      {\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\src\\persistence.cpp:\n 5772          }\n 5773          else if( CV_IS_SEQ(seq) && CV_IS_SEQ_CHAIN(seq) &&\n 5774:                  CV_MAT_TYPE(seq->flags) == CV_8UC1 )\n 5775          {\n 5776              CvChain* chain = (CvChain*)seq;\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\src\\stat.cpp:\n 1051      int ddepth = std::max(sum_op == OCL_OP_SUM_SQR ? CV_32F : CV_32S, depth),\n 1052              dtype = CV_MAKE_TYPE(ddepth, cn);\n 1053:     CV_Assert(!haveMask || _mask.type() == CV_8UC1);\n 1054  \n 1055      int wgs2_aligned = 1;\n ....\n 1144              0;\n 1145          ippiSumFuncNoHint ippiSum =\n 1146:             type == CV_8UC1 ? (ippiSumFuncNoHint)ippiSum_8u_C1R :\n 1147              type == CV_8UC3 ? (ippiSumFuncNoHint)ippiSum_8u_C3R :\n 1148              type == CV_8UC4 ? (ippiSumFuncNoHint)ippiSum_8u_C4R :\n ....\n 1406              typedef IppStatus (CV_STDCALL* ippiMaskMeanFuncC1)(const void *, int, const void *, int, IppiSize, Ipp64f *);\n 1407              ippiMaskMeanFuncC1 ippiMean_C1MR =\n 1408:             type == CV_8UC1 ? (ippiMaskMeanFuncC1)ippiMean_8u_C1MR :\n 1409              type == CV_16UC1 ? (ippiMaskMeanFuncC1)ippiMean_16u_C1MR :\n 1410              type == CV_32FC1 ? (ippiMaskMeanFuncC1)ippiMean_32f_C1MR :\n ....\n 1447                  0;\n 1448              ippiMeanFuncNoHint ippiMean =\n 1449:                 type == CV_8UC1 ? (ippiMeanFuncNoHint)ippiMean_8u_C1R :\n 1450                  type == CV_8UC3 ? (ippiMeanFuncNoHint)ippiMean_8u_C3R :\n 1451                  type == CV_8UC4 ? (ippiMeanFuncNoHint)ippiMean_8u_C4R :\n ....\n 1576                  dtype = CV_MAKE_TYPE(ddepth, cn),\n 1577                  sqdtype = CV_MAKETYPE(sqddepth, cn);\n 1578:         CV_Assert(!haveMask || _mask.type() == CV_8UC1);\n 1579  \n 1580          int wgs2_aligned = 1;\n ....\n 1606          int dbsize = groups * ((haveMask ? CV_ELEM_SIZE1(CV_32S) : 0) +\n 1607                                 CV_ELEM_SIZE(sqdtype) + CV_ELEM_SIZE(dtype));\n 1608:         UMat src = _src.getUMat(), db(1, dbsize, CV_8UC1), mask = _mask.getUMat();\n 1609  \n 1610          ocl::KernelArg srcarg = ocl::KernelArg::ReadOnlyNoSize(src),\n ....\n 1677          size_t total_size = src.total();\n 1678          int rows = src.size[0], cols = rows ? (int)(total_size / rows) : 0;\n 1679:         if (src.type() != CV_8UC1|| !mask.empty() ||\n 1680                 (src.dims != 2 && !(src.isContinuous() && cols > 0 && (size_t)rows*cols == total_size))\n 1681             )\n ....\n 1790              typedef IppStatus (CV_STDCALL* ippiMaskMeanStdDevFuncC1)(const void *, int, const void *, int, IppiSize, Ipp64f *, Ipp64f *);\n 1791              ippiMaskMeanStdDevFuncC1 ippiMean_StdDev_C1MR =\n 1792:             type == CV_8UC1 ? (ippiMaskMeanStdDevFuncC1)ippiMean_StdDev_8u_C1MR :\n 1793              type == CV_16UC1 ? (ippiMaskMeanStdDevFuncC1)ippiMean_StdDev_16u_C1MR :\n 1794              type == CV_32FC1 ? (ippiMaskMeanStdDevFuncC1)ippiMean_StdDev_32f_C1MR :\n ....\n 1821              typedef IppStatus (CV_STDCALL* ippiMeanStdDevFuncC1)(const void *, int, IppiSize, Ipp64f *, Ipp64f *);\n 1822              ippiMeanStdDevFuncC1 ippiMean_StdDev_C1R =\n 1823:             type == CV_8UC1 ? (ippiMeanStdDevFuncC1)ippiMean_StdDev_8u_C1R :\n 1824              type == CV_16UC1 ? (ippiMeanStdDevFuncC1)ippiMean_StdDev_16u_C1R :\n 1825  #if (IPP_VERSION_X100 >= 810)\n ....\n 1867  \n 1868      Mat src = _src.getMat(), mask = _mask.getMat();\n 1869:     CV_Assert( mask.empty() || mask.type() == CV_8UC1 );\n 1870  \n 1871      CV_OVX_RUN(!ovx::skipSmallImages<VX_KERNEL_MEAN_STDDEV>(src.cols, src.rows),\n ....\n 2269                                   (maxVal2 ? esz : 0))\n 2270                       + 5 * MINMAX_STRUCT_ALIGNMENT;\n 2271:     UMat src = _src.getUMat(), src2 = _src2.getUMat(), db(1, dbsize, CV_8UC1), mask = _mask.getUMat();\n 2272  \n 2273      if (cn > 1 && !haveMask)\n ....\n 2334      size_t total_size = src.total();\n 2335      int rows = src.size[0], cols = rows ? (int)(total_size / rows) : 0;\n 2336:     if ((stype != CV_8UC1 && stype != CV_16SC1) || !mask.empty() ||\n 2337          (src.dims != 2 && !(src.isContinuous() && cols > 0 && (size_t)rows*cols == total_size))\n 2338          )\n ....\n 2343          ivx::Context ctx = ovx::getOpenVXContext();\n 2344          ivx::Image\n 2345:             ia = ivx::Image::createFromHandle(ctx, stype == CV_8UC1 ? VX_DF_IMAGE_U8 : VX_DF_IMAGE_S16,\n 2346:                 ivx::Image::createAddressing(cols, rows, stype == CV_8UC1 ? 1 : 2, (vx_int32)(src.step[0])), src.ptr());\n 2347  \n 2348:         ivx::Scalar vxMinVal = ivx::Scalar::create(ctx, stype == CV_8UC1 ? VX_TYPE_UINT8 : VX_TYPE_INT16, 0);\n 2349:         ivx::Scalar vxMaxVal = ivx::Scalar::create(ctx, stype == CV_8UC1 ? VX_TYPE_UINT8 : VX_TYPE_INT16, 0);\n 2350          ivx::Array vxMinInd, vxMaxInd;\n 2351          ivx::Scalar vxMinCount, vxMaxCount;\n ....\n 2365          if (minVal)\n 2366          {\n 2367:             *minVal = stype == CV_8UC1 ? vxMinVal.getValue<vx_uint8>() : vxMinVal.getValue<vx_int16>();\n 2368          }\n 2369          if (maxVal)\n 2370          {\n 2371:             *maxVal = stype == CV_8UC1 ? vxMaxVal.getValue<vx_uint8>() : vxMaxVal.getValue<vx_int16>();\n 2372          }\n 2373          if (minIdx)\n ....\n 3068              ippiMaskNormFuncC1 ippiNorm_C1MR =\n 3069                  normType == NORM_INF ?\n 3070:                 (type == CV_8UC1 ? (ippiMaskNormFuncC1)ippiNorm_Inf_8u_C1MR :\n 3071                  type == CV_16UC1 ? (ippiMaskNormFuncC1)ippiNorm_Inf_16u_C1MR :\n 3072                  type == CV_32FC1 ? (ippiMaskNormFuncC1)ippiNorm_Inf_32f_C1MR :\n 3073                  0) :\n 3074              normType == NORM_L1 ?\n 3075:                 (type == CV_8UC1 ? (ippiMaskNormFuncC1)ippiNorm_L1_8u_C1MR :\n 3076                  type == CV_16UC1 ? (ippiMaskNormFuncC1)ippiNorm_L1_16u_C1MR :\n 3077                  type == CV_32FC1 ? (ippiMaskNormFuncC1)ippiNorm_L1_32f_C1MR :\n 3078                  0) :\n 3079              normType == NORM_L2 || normType == NORM_L2SQR ?\n 3080:                 (type == CV_8UC1 ? (ippiMaskNormFuncC1)ippiNorm_L2_8u_C1MR :\n 3081                  type == CV_16UC1 ? (ippiMaskNormFuncC1)ippiNorm_L2_16u_C1MR :\n 3082                  type == CV_32FC1 ? (ippiMaskNormFuncC1)ippiNorm_L2_32f_C1MR :\n ....\n 3141              ippiNormFuncNoHint ippiNorm =\n 3142                  normType == NORM_INF ?\n 3143:                 (type == CV_8UC1 ? (ippiNormFuncNoHint)ippiNorm_Inf_8u_C1R :\n 3144                  type == CV_16UC1 ? (ippiNormFuncNoHint)ippiNorm_Inf_16u_C1R :\n 3145                  type == CV_16SC1 ? (ippiNormFuncNoHint)ippiNorm_Inf_16s_C1R :\n ....\n 3147                  0) :\n 3148                  normType == NORM_L1 ?\n 3149:                 (type == CV_8UC1 ? (ippiNormFuncNoHint)ippiNorm_L1_8u_C1R :\n 3150                  type == CV_16UC1 ? (ippiNormFuncNoHint)ippiNorm_L1_16u_C1R :\n 3151                  type == CV_16SC1 ? (ippiNormFuncNoHint)ippiNorm_L1_16s_C1R :\n 3152                  0) :\n 3153                  normType == NORM_L2 || normType == NORM_L2SQR ?\n 3154:                 (type == CV_8UC1 ? (ippiNormFuncNoHint)ippiNorm_L2_8u_C1R :\n 3155                  type == CV_16UC1 ? (ippiNormFuncNoHint)ippiNorm_L2_16u_C1R :\n 3156                  type == CV_16SC1 ? (ippiNormFuncNoHint)ippiNorm_L2_16s_C1R :\n ....\n 3426                  ippiMaskNormDiffFuncC1 ippiNormRel_C1MR =\n 3427                      normType == NORM_INF ?\n 3428:                     (type == CV_8UC1 ? (ippiMaskNormDiffFuncC1)ippiNormRel_Inf_8u_C1MR :\n 3429                      type == CV_16UC1 ? (ippiMaskNormDiffFuncC1)ippiNormRel_Inf_16u_C1MR :\n 3430                      type == CV_32FC1 ? (ippiMaskNormDiffFuncC1)ippiNormRel_Inf_32f_C1MR :\n 3431                      0) :\n 3432                      normType == NORM_L1 ?\n 3433:                     (type == CV_8UC1 ? (ippiMaskNormDiffFuncC1)ippiNormRel_L1_8u_C1MR :\n 3434                      type == CV_16UC1 ? (ippiMaskNormDiffFuncC1)ippiNormRel_L1_16u_C1MR :\n 3435                      type == CV_32FC1 ? (ippiMaskNormDiffFuncC1)ippiNormRel_L1_32f_C1MR :\n 3436                      0) :\n 3437                      normType == NORM_L2 || normType == NORM_L2SQR ?\n 3438:                     (type == CV_8UC1 ? (ippiMaskNormDiffFuncC1)ippiNormRel_L2_8u_C1MR :\n 3439                      type == CV_16UC1 ? (ippiMaskNormDiffFuncC1)ippiNormRel_L2_16u_C1MR :\n 3440                      type == CV_32FC1 ? (ippiMaskNormDiffFuncC1)ippiNormRel_L2_32f_C1MR :\n ....\n 3512              ippiMaskNormDiffFuncC1 ippiNormDiff_C1MR =\n 3513                  normType == NORM_INF ?\n 3514:                 (type == CV_8UC1 ? (ippiMaskNormDiffFuncC1)ippiNormDiff_Inf_8u_C1MR :\n 3515                  type == CV_16UC1 ? (ippiMaskNormDiffFuncC1)ippiNormDiff_Inf_16u_C1MR :\n 3516                  type == CV_32FC1 ? (ippiMaskNormDiffFuncC1)ippiNormDiff_Inf_32f_C1MR :\n 3517                  0) :\n 3518                  normType == NORM_L1 ?\n 3519:                 (type == CV_8UC1 ? (ippiMaskNormDiffFuncC1)ippiNormDiff_L1_8u_C1MR :\n 3520                  type == CV_16UC1 ? (ippiMaskNormDiffFuncC1)ippiNormDiff_L1_16u_C1MR :\n 3521                  type == CV_32FC1 ? (ippiMaskNormDiffFuncC1)ippiNormDiff_L1_32f_C1MR :\n 3522                  0) :\n 3523                  normType == NORM_L2 || normType == NORM_L2SQR ?\n 3524:                 (type == CV_8UC1 ? (ippiMaskNormDiffFuncC1)ippiNormDiff_L2_8u_C1MR :\n 3525                  type == CV_16UC1 ? (ippiMaskNormDiffFuncC1)ippiNormDiff_L2_16u_C1MR :\n 3526                  type == CV_32FC1 ? (ippiMaskNormDiffFuncC1)ippiNormDiff_L2_32f_C1MR :\n ....\n 4124  \n 4125      Mat src = _src.getMat();\n 4126:     CV_Assert( src.type() == CV_8UC1 );\n 4127      int n = countNonZero(src);\n 4128      if( n == 0 )\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\src\\umatrix.cpp:\n 1005              {\n 1006                  mask = _mask.getUMat();\n 1007:                 CV_Assert( mask.size() == size() && mask.type() == CV_8UC1 );\n 1008                  ocl::KernelArg maskarg = ocl::KernelArg::ReadOnlyNoSize(mask),\n 1009                          dstarg = ocl::KernelArg::ReadWrite(*this);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\test\\ocl\\test_arithm.cpp:\n  156  \n  157          Border maskBorder = randomBorder(0, use_roi ? MAX_VALUE : 0);\n  158:         randomSubMat(mask, mask_roi, roiSize, maskBorder, CV_8UC1, 0, 2);\n  159:         cv::threshold(mask, mask, 0.5, 255., CV_8UC1);\n  160          *mask.ptr(0) = 255; // prevent test case with mask filled 0 only\n  161  \n  ...\n 1017  {\n 1018      Size size(5, 5);\n 1019:     UMat um(size, CV_32SC1), umask(size, CV_8UC1, Scalar::all(0));\n 1020:     Mat m(size, CV_32SC1), mask(size, CV_8UC1, Scalar::all(0));\n 1021  \n 1022      Scalar cpu_mean, cpu_stddev;\n ....\n 1511  \n 1512          Border dstBorder = randomBorder(0, use_roi ? MAX_VALUE : 0);\n 1513:         randomSubMat(dst, dst_roi, roiSize, dstBorder, CV_8UC1, 5, 16);\n 1514  \n 1515          val1 = cv::Scalar(rng.uniform(-100.0, 100.0), rng.uniform(-100.0, 100.0),\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\test\\ocl\\test_image2d.cpp:\n   46          if (1 < major || (1 == major && 2 <= minor))\n   47          {\n   48:             UMat um(128, 128, CV_8UC1);\n   49              bool isFormatSupported = false, canCreateAlias = false;\n   50  \n   ..\n   73  \n   74          cv::ocl::setUseOpenCL(true);\n   75:         UMat um(128, 128, CV_8UC1);\n   76  \n   77          cv::ocl::setUseOpenCL(false);\n   ..\n   83          }\n   84          else\n   85:             std::cout << \"CV_8UC1 is not supported for OpenCL images. Test skipped.\" << std::endl;\n   86      \n   87          // reset state to the previous one\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\test\\ocl\\test_matrix_operation.cpp:\n  194      for (int j = 0; j < test_loop_times; j++)\n  195      {\n  196:         generateTestData(true); // see modules/core/src/umatrix.cpp Ln:791 => CV_Assert( mask.size() == size() && mask.type() == CV_8UC1 );\n  197  \n  198          if (use_mask)\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\test\\test_arithm.cpp:\n 1569  TEST(Multiply, FloatingPointRounding)\n 1570  {\n 1571:     cv::Mat src(1, 1, CV_8UC1, cv::Scalar::all(110)), dst;\n 1572      cv::Scalar s(147.286359696927, 1, 1 ,1);\n 1573  \n ....\n 1672      cv::Mat src1(size, src_type, cv::Scalar::all(16));\n 1673      cv::Mat src2(size, src_type, cv::Scalar::all(16));\n 1674:     cv::Mat mask(size, CV_8UC1, cv::Scalar::all(255));\n 1675  \n 1676      cv::Mat dst;\n ....\n 1734  {\n 1735      cv::Mat src(size, src_type, cv::Scalar::all(16));\n 1736:     cv::Mat mask(size, CV_8UC1, cv::Scalar::all(255));\n 1737  \n 1738      cv::Mat dst;\n ....\n 1783  {\n 1784      cv::Mat src(size, src_type, cv::Scalar::all(16));\n 1785:     cv::Mat mask(size, CV_8UC1, cv::Scalar::all(255));\n 1786  \n 1787      cv::Mat dst;\n ....\n 1835  INSTANTIATE_TEST_CASE_P(Arithm, SubtractOutputMatNotEmpty, testing::Combine(\n 1836      testing::Values(cv::Size(16, 16), cv::Size(13, 13), cv::Size(16, 13), cv::Size(13, 16)),\n 1837:     testing::Values(perf::MatType(CV_8UC1), CV_8UC3, CV_8UC4, CV_16SC1, CV_16SC3),\n 1838      testing::Values(-1, CV_16S, CV_32S, CV_32F),\n 1839      testing::Bool()));\n ....\n 1956     2,   2,   1\n 1957  };\n 1958:     Mat mask(Size(cols, rows), CV_8UC1, mask_);\n 1959:     Mat src(Size(cols, rows), CV_8UC1, src_);\n 1960      double minVal = -0.0, maxVal = -0.0;\n 1961      int minIdx[2] = { -2, -2 }, maxIdx[2] = { -2, -2 };\n ....\n 2002     2,   0,   0,   0,   0,   2,   5,   6,   5,   2,   2,   5,   4,   3,   0\n 2003  };\n 2004:     Mat mask(Size(cols, rows), CV_8UC1, mask_);\n 2005:     Mat src(Size(cols, rows), CV_8UC1, src_);\n 2006      double minVal = -0.0, maxVal = -0.0;\n 2007      int minIdx[2] = { -2, -2 }, maxIdx[2] = { -2, -2 };\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\test\\test_ds.cpp:\n  545          cxcore_struct[i] = 0;\n  546          sseq->count = cvtest::randInt( rng ) % max_struct_size;\n  547:         Mat m( 1, MAX(sseq->count,1)*elem_size, CV_8UC1, sseq->array );\n  548          cvtest::randUni( rng, m, Scalar::all(0), Scalar::all(256) );\n  549      }\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\test\\test_mat.cpp:\n   74  void getMatTypeStr( int type, string& str)\n   75  {\n   76:     str = type == CV_8UC1 ? \"CV_8UC1\" :\n   77      type == CV_8SC1 ? \"CV_8SC1\" :\n   78      type == CV_16UC1 ? \"CV_16UC1\" :\n   ..\n  171      randu( src, Scalar(0), Scalar(100) );\n  172  \n  173:     if( srcType == CV_8UC1 )\n  174          testReduce<uchar>( src, sum, avg, max, min, dim );\n  175      else if( srcType == CV_8SC1 )\n  ...\n  211      int code = cvtest::TS::OK, tempCode;\n  212  \n  213:     // CV_8UC1\n  214:     tempCode = checkCase( CV_8UC1, CV_8UC1, dim, sz );\n  215      code = tempCode != cvtest::TS::OK ? tempCode : code;\n  216  \n  217:     tempCode = checkCase( CV_8UC1, CV_32SC1, dim, sz );\n  218      code = tempCode != cvtest::TS::OK ? tempCode : code;\n  219  \n  220:     tempCode = checkCase( CV_8UC1, CV_32FC1, dim, sz );\n  221      code = tempCode != cvtest::TS::OK ? tempCode : code;\n  222  \n  223:     tempCode = checkCase( CV_8UC1, CV_64FC1, dim, sz );\n  224      code = tempCode != cvtest::TS::OK ? tempCode : code;\n  225  \n  ...\n 1591  \n 1592      Mat destImageBGR = Mat(height, width, CV_8UC3, Scalar(1, 2, 3, 0));\n 1593:     Mat destImageA = Mat(height, width, CV_8UC1, Scalar::all(4));\n 1594  \n 1595      vector<Mat> planes;\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\test\\test_math.cpp:\n 1926      types[TEMP][0] = types[TEMP][1] = types[TEMP][2] = types[TEMP][3] = types[INPUT][0];\n 1927      types[OUTPUT][0] = types[OUTPUT][1] = types[OUTPUT][2] = types[INPUT][0];\n 1928:     types[OUTPUT][3] = CV_8UC1;\n 1929      sizes[OUTPUT][0] = !have_u || !have_v ? Size(0,0) : sizes[INPUT][0];\n 1930      sizes[OUTPUT][1] = !have_u ? Size(0,0) : compact ? Size(min_size,min_size) : Size(m,m);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\test\\test_operations.cpp:\n  434          Mat rgba( 10, 10, CV_8UC4, Scalar(1,2,3,4) );\n  435          Mat bgr( rgba.rows, rgba.cols, CV_8UC3 );\n  436:         Mat alpha( rgba.rows, rgba.cols, CV_8UC1 );\n  437          Mat out[] = { bgr, alpha };\n  438          // rgba[0] -> bgr[2], rgba[1] -> bgr[1],\n  ...\n  442  \n  443          Mat bgr_exp( rgba.size(), CV_8UC3, Scalar(3,2,1));\n  444:         Mat alpha_exp( rgba.size(), CV_8UC1, Scalar(4));\n  445  \n  446          CHECK_DIFF(bgr_exp, bgr);\n  ...\n  783          try\n  784          {\n  785:             Mat m1 = Mat::zeros(1, 10, CV_8UC1);\n  786              Mat m2 = Mat::zeros(10, 10, CV_8UC3);\n  787              m1.copyTo(m2.row(1));\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\core\\test\\test_umat.cpp:\n  723          for (int i = 0; i < ITERATIONS; i++)\n  724          {\n  725:             UMat um(Size(sz.width + i, sz.height + i), CV_8UC1);\n  726:             UMat um2(Size(sz.width + 2 * i, sz.height + 2 * i), CV_8UC1);\n  727          }\n  728          c->setMaxReservedSize(oldMaxReservedSize);\n  ...\n  894  \n  895      {\n  896:         Mat m(10, 10, CV_8UC1), ref;\n  897          for (int y = 0; y < m.rows; ++y)\n  898          {\n  ...\n  923  TEST(UMat, Sync)\n  924  {\n  925:     UMat um(10, 10, CV_8UC1);\n  926  \n  927      {\n  ...\n  937  TEST(UMat, SyncTemp)\n  938  {\n  939:     Mat m(10, 10, CV_8UC1);\n  940  \n  941      {\n  ...\n  955  TEST(UMat, CopyToIfDeviceCopyIsObsolete)\n  956  {\n  957:     UMat um(7, 2, CV_8UC1);\n  958      Mat m(um.size(), um.type());\n  959      m.setTo(Scalar::all(0));\n  ...\n 1071          try\n 1072          {\n 1073:             Mat m = Mat(1000, 1000, CV_8UC1, Scalar::all(0));\n 1074              UMat u = m.getUMat(ACCESS_READ);\n 1075              UMat dst;\n ....\n 1116      try\n 1117      {\n 1118:         Mat m = Mat(1000, 1000, CV_8UC1, Scalar::all(0));\n 1119          Logic l;\n 1120          l.processData(m);\n ....\n 1142      }\n 1143      std::cout << \"Host memory: \" << cv::ocl::Device::getDefault().hostUnifiedMemory() << std::endl;\n 1144:     Mat m(Size(10, 10), CV_8UC1, Scalar::all(0));\n 1145      UMat um = m.getUMat(ACCESS_RW);\n 1146      {\n ....\n 1168      {\n 1169          const Size srcSize(320, 240);\n 1170:         const int type = CV_8UC1;\n 1171          const int dtype = CV_16UC1;\n 1172  \n ....\n 1204      {\n 1205          const Size srcSize(320, 240);\n 1206:         const int type = CV_8UC1;\n 1207          const int dtype = CV_16UC1;\n 1208  \n ....\n 1231      try\n 1232      {\n 1233:         UMat u(Size(10, 10), CV_8UC1, Scalar::all(0));\n 1234          Mat m = u.getMat(ACCESS_READ);\n 1235          UMat dst;\n ....\n 1249      try\n 1250      {\n 1251:         UMat u(Size(10, 10), CV_8UC1, Scalar::all(0));\n 1252          Mat m = u.getMat(ACCESS_READ);\n 1253          add(u, Scalar::all(1), u);\n ....\n 1265      try\n 1266      {\n 1267:         UMat u(Size(10, 10), CV_8UC1, Scalar::all(0));\n 1268          Mat m = u.getMat(ACCESS_WRITE);\n 1269          UMat dst;\n ....\n 1282      try\n 1283      {\n 1284:         UMat u(Size(10, 10), CV_8UC1, Scalar::all(0));\n 1285          Mat m = u.getMat(ACCESS_WRITE);\n 1286          add(u, Scalar::all(1), u);\n ....\n 1295  TEST(UMat, mat_umat_sync)\n 1296  {\n 1297:     UMat u(10, 10, CV_8UC1, Scalar(1));\n 1298      {\n 1299          Mat m = u.getMat(ACCESS_RW).reshape(1);\n ....\n 1308  TEST(UMat, testTempObjects_UMat)\n 1309  {\n 1310:     UMat u(10, 10, CV_8UC1, Scalar(1));\n 1311      {\n 1312          UMat u2 = u.getMat(ACCESS_RW).getUMat(ACCESS_RW);\n ....\n 1321  TEST(UMat, testTempObjects_Mat)\n 1322  {\n 1323:     Mat m(10, 10, CV_8UC1, Scalar(1));\n 1324      {\n 1325          Mat m2;\n ....\n 1336  TEST(UMat, testWrongLifetime_UMat)\n 1337  {\n 1338:     UMat u(10, 10, CV_8UC1, Scalar(1));\n 1339      {\n 1340          UMat u2 = u.getMat(ACCESS_RW).getUMat(ACCESS_RW);\n ....\n 1346  TEST(UMat, testWrongLifetime_Mat)\n 1347  {\n 1348:     Mat m(10, 10, CV_8UC1, Scalar(1));\n 1349      {\n 1350          UMat u = m.getUMat(ACCESS_RW);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaarithm\\include\\opencv2\\cudaarithm.hpp:\n  488      dst(I) = lut(src(I)) .\n  489  \n  490:     @param src Source matrix. CV_8UC1 and CV_8UC3 matrices are supported for now.\n  491      @param dst Destination matrix.\n  492      @param stream Stream for the asynchronous version.\n  ...\n  503  /** @brief Forms a border around an image.\n  504  \n  505: @param src Source image. CV_8UC1 , CV_8UC4 , CV_32SC1 , and CV_32FC1 types are supported.\n  506  @param dst Destination image with the same type as src. The size is\n  507  Size(src.cols+left+right, src.rows+top+bottom) .\n  ...\n  528  @param src1 Source matrix. Any matrices except 64F are supported.\n  529  @param normType Norm type. NORM_L1 , NORM_L2 , and NORM_INF are supported for now.\n  530: @param mask optional operation mask; it must have the same size as src1 and CV_8UC1 type.\n  531  \n  532  @sa norm\n  ...\n  551  \n  552  @param src Source image of any depth except for CV_64F .\n  553: @param mask optional operation mask; it must have the same size as src1 and CV_8UC1 type.\n  554  \n  555  @sa sum\n  ...\n  562  \n  563  @param src Source image of any depth except for CV_64F .\n  564: @param mask optional operation mask; it must have the same size as src1 and CV_8UC1 type.\n  565   */\n  566  CV_EXPORTS Scalar absSum(InputArray src, InputArray mask = noArray());\n  ...\n  571  \n  572  @param src Source image of any depth except for CV_64F .\n  573: @param mask optional operation mask; it must have the same size as src1 and CV_8UC1 type.\n  574   */\n  575  CV_EXPORTS Scalar sqrSum(InputArray src, InputArray mask = noArray());\n  ...\n  653  /** @brief Computes a mean value and a standard deviation of matrix elements.\n  654  \n  655: @param mtx Source matrix. CV_8UC1 matrices are supported for now.\n  656  @param mean Mean value.\n  657  @param stddev Standard deviation value.\n  ...\n  695  /** @brief Computes an integral image.\n  696  \n  697: @param src Source image. Only CV_8UC1 images are supported for now.\n  698  @param sum Integral image containing 32-bit unsigned integer values packed into CV_32SC1 .\n  699  @param stream Stream for the asynchronous version.\n  ...\n  705  /** @brief Computes a squared integral image.\n  706  \n  707: @param src Source image. Only CV_8UC1 images are supported for now.\n  708  @param sqsum Squared integral image containing 64-bit unsigned integer values packed into\n  709  CV_64FC1 .\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaarithm\\perf\\perf_core.cpp:\n  137  PERF_TEST_P(Sz_Type, Transpose,\n  138              Combine(CUDA_TYPICAL_MAT_SIZES,\n  139:                     Values(CV_8UC1, CV_8UC4, CV_16UC2, CV_16SC2, CV_32SC1, CV_32SC2, CV_64FC1)))\n  140  {\n  141      const cv::Size size = GET_PARAM(0);\n  ...\n  212  PERF_TEST_P(Sz_Type, LutOneChannel,\n  213              Combine(CUDA_TYPICAL_MAT_SIZES,\n  214:                     Values(CV_8UC1, CV_8UC3)))\n  215  {\n  216      const cv::Size size = GET_PARAM(0);\n  ...\n  220      declare.in(src, WARMUP_RNG);\n  221  \n  222:     cv::Mat lut(1, 256, CV_8UC1);\n  223      declare.in(lut, WARMUP_RNG);\n  224  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaarithm\\perf\\perf_reductions.cpp:\n   99      const int normType = GET_PARAM(1);\n  100  \n  101:     cv::Mat src1(size, CV_8UC1);\n  102      declare.in(src1, WARMUP_RNG);\n  103  \n  104:     cv::Mat src2(size, CV_8UC1);\n  105      declare.in(src2, WARMUP_RNG);\n  106  \n  ...\n  433      const cv::Size size = GetParam();\n  434  \n  435:     cv::Mat src(size, CV_8UC1);\n  436      declare.in(src, WARMUP_RNG);\n  437  \n  ...\n  468      const cv::Size size = GetParam();\n  469  \n  470:     cv::Mat src(size, CV_8UC1);\n  471      declare.in(src, WARMUP_RNG);\n  472  \n  ...\n  498      const cv::Size size = GetParam();\n  499  \n  500:     cv::Mat src(size, CV_8UC1);\n  501      declare.in(src, WARMUP_RNG);\n  502  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaarithm\\src\\element_operations.cpp:\n  140          CV_Assert( sdepth <= CV_64F && ddepth <= CV_64F );\n  141          CV_Assert( !scalar.empty() || (src2.type() == src1.type() && src2.size() == src1.size()) );\n  142:         CV_Assert( mask.empty() || (cn == 1 && mask.size() == size && mask.type() == CV_8UC1) );\n  143  \n  144          if (sdepth == CV_64F || ddepth == CV_64F)\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaarithm\\src\\reductions.cpp:\n  140      const GpuMat src = getInputMat(_src, stream);\n  141  \n  142:     CV_Assert( src.type() == CV_8UC1 );\n  143  \n  144      GpuMat dst = getOutputMat(_dst, 1, 2, CV_64FC1, stream);\n  ...\n  156  \n  157      BufferPool pool(stream);\n  158:     GpuMat buf = pool.getBuffer(1, bufSize, CV_8UC1);\n  159  \n  160      NppStreamHandler h(StreamAccessor::getStream(stream));\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaarithm\\test\\test_buffer_pool.cpp:\n   60  \n   61          {\n   62:             GpuMat buf0 = pool.getBuffer(Size(640, 480), CV_8UC1);\n   63              EXPECT_FALSE( buf0.empty() );\n   64  \n   65              buf0.setTo(Scalar::all(0), stream);\n   66  \n   67:             GpuMat buf1 = pool.getBuffer(Size(640, 480), CV_8UC1);\n   68              EXPECT_FALSE( buf1.empty() );\n   69  \n   ..\n   85      void CheckSimpleTest(HostMem& dst_1, HostMem& dst_2)\n   86      {\n   87:         EXPECT_MAT_NEAR(Mat(Size(640, 480), CV_8UC1, Scalar::all(1)), dst_1, 0.0);\n   88          EXPECT_MAT_NEAR(Mat(Size(1280, 1024), CV_32SC1, Scalar::all(2)), dst_2, 0.0);\n   89      }\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaarithm\\test\\test_core.cpp:\n  233      ALL_DEVICES,\n  234      DIFFERENT_SIZES,\n  235:     testing::Values(MatType(CV_8UC1),\n  236                      MatType(CV_8UC4),\n  237                      MatType(CV_16UC2),\n  ...\n  285      ALL_DEVICES,\n  286      DIFFERENT_SIZES,\n  287:     testing::Values(MatType(CV_8UC1),\n  288                      MatType(CV_8UC3),\n  289                      MatType(CV_8UC4),\n  ...\n  324  {\n  325      cv::Mat src = randomMat(size, type);\n  326:     cv::Mat lut = randomMat(cv::Size(256, 1), CV_8UC1);\n  327  \n  328      cv::Ptr<cv::cuda::LookUpTable> lutAlg = cv::cuda::createLookUpTable(lut);\n  ...\n  356      ALL_DEVICES,\n  357      DIFFERENT_SIZES,\n  358:     testing::Values(MatType(CV_8UC1), MatType(CV_8UC3)),\n  359      WHOLE_SUBMAT));\n  360  \n  ...\n  406      ALL_DEVICES,\n  407      DIFFERENT_SIZES,\n  408:     testing::Values(MatType(CV_8UC1),\n  409                      MatType(CV_8UC3),\n  410                      MatType(CV_8UC4),\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaarithm\\test\\test_element_operations.cpp:\n  141      cv::Mat mat1 = randomMat(size, stype);\n  142      cv::Mat mat2 = randomMat(size, stype);\n  143:     cv::Mat mask = randomMat(size, CV_8UC1, 0, 2);\n  144  \n  145      if ((depth.first == CV_64F || depth.second == CV_64F) && !supportFeature(devInfo, cv::cuda::NATIVE_DOUBLE))\n  ...\n  229      cv::Mat mat = randomMat(size, depth.first);\n  230      cv::Scalar val = randomScalar(0, 255);\n  231:     cv::Mat mask = randomMat(size, CV_8UC1, 0.0, 2.0);\n  232  \n  233      if ((depth.first == CV_64F || depth.second == CV_64F) && !supportFeature(devInfo, cv::cuda::NATIVE_DOUBLE))\n  ...\n  317      cv::Mat mat = randomMat(size, depth.first);\n  318      cv::Scalar val = randomScalar(0, 255);\n  319:     cv::Mat mask = randomMat(size, CV_8UC1, 0.0, 2.0);\n  320  \n  321      if ((depth.first == CV_64F || depth.second == CV_64F) && !supportFeature(devInfo, cv::cuda::NATIVE_DOUBLE))\n  ...\n  444      cv::Mat mat1 = randomMat(size, stype);\n  445      cv::Mat mat2 = randomMat(size, stype);\n  446:     cv::Mat mask = randomMat(size, CV_8UC1, 0.0, 2.0);\n  447  \n  448      if ((depth.first == CV_64F || depth.second == CV_64F) && !supportFeature(devInfo, cv::cuda::NATIVE_DOUBLE))\n  ...\n  532      cv::Mat mat = randomMat(size, depth.first);\n  533      cv::Scalar val = randomScalar(0, 255);\n  534:     cv::Mat mask = randomMat(size, CV_8UC1, 0.0, 2.0);\n  535  \n  536      if ((depth.first == CV_64F || depth.second == CV_64F) && !supportFeature(devInfo, cv::cuda::NATIVE_DOUBLE))\n  ...\n  620      cv::Mat mat = randomMat(size, depth.first);\n  621      cv::Scalar val = randomScalar(0, 255);\n  622:     cv::Mat mask = randomMat(size, CV_8UC1, 0.0, 2.0);\n  623  \n  624      if ((depth.first == CV_64F || depth.second == CV_64F) && !supportFeature(devInfo, cv::cuda::NATIVE_DOUBLE))\n  ...\n 1875      else\n 1876      {\n 1877:         cv::cuda::GpuMat dst = createMat(size, CV_8UC1, useRoi);\n 1878          cv::cuda::compare(loadMat(src1, useRoi), loadMat(src2, useRoi), dst, cmp_code);\n 1879  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaarithm\\test\\test_gpumat.cpp:\n  135      cv::Scalar val = randomScalar(0.0, 255.0);\n  136      cv::Mat mat_gold = randomMat(size, type);\n  137:     cv::Mat mask = randomMat(size, CV_8UC1, 0.0, 2.0);\n  138  \n  139      if (CV_MAT_DEPTH(type) == CV_64F && !supportFeature(devInfo, cv::cuda::NATIVE_DOUBLE))\n  ...\n  202  {\n  203      cv::Mat src = randomMat(size, type);\n  204:     cv::Mat mask = randomMat(size, CV_8UC1, 0.0, 2.0);\n  205  \n  206      if (CV_MAT_DEPTH(type) == CV_64F && !supportFeature(devInfo, cv::cuda::NATIVE_DOUBLE))\n  ...\n  349      EXPECT_EQ(10, buffer.rows);\n  350      EXPECT_EQ(20, buffer.cols);\n  351:     EXPECT_EQ(CV_8UC1, buffer.type());\n  352      EXPECT_EQ(reinterpret_cast<intptr_t>(old.data), reinterpret_cast<intptr_t>(buffer.data));\n  353  \n  ...\n  356      EXPECT_EQ(20, buffer.rows);\n  357      EXPECT_EQ(30, buffer.cols);\n  358:     EXPECT_EQ(CV_8UC1, buffer.type());\n  359      EXPECT_EQ(reinterpret_cast<intptr_t>(old.data), reinterpret_cast<intptr_t>(buffer.data));\n  360  }\n  ...\n  378      cv::cuda::GpuMat buffer;\n  379  \n  380:     cv::cuda::createContinuous(100, 100, CV_8UC1, buffer);\n  381      EXPECT_EQ(100, buffer.rows);\n  382      EXPECT_EQ(100, buffer.cols);\n  383:     EXPECT_EQ(CV_8UC1, buffer.type());\n  384      EXPECT_TRUE(buffer.isContinuous());\n  385      EXPECT_EQ(buffer.cols * sizeof(uchar), buffer.step);\n  386  \n  387:     cv::cuda::createContinuous(10, 1000, CV_8UC1, buffer);\n  388      EXPECT_EQ(10, buffer.rows);\n  389      EXPECT_EQ(1000, buffer.cols);\n  390:     EXPECT_EQ(CV_8UC1, buffer.type());\n  391      EXPECT_TRUE(buffer.isContinuous());\n  392      EXPECT_EQ(buffer.cols * sizeof(uchar), buffer.step);\n  393  \n  394:     cv::cuda::createContinuous(10, 10, CV_8UC1, buffer);\n  395      EXPECT_EQ(10, buffer.rows);\n  396      EXPECT_EQ(10, buffer.cols);\n  397:     EXPECT_EQ(CV_8UC1, buffer.type());\n  398      EXPECT_TRUE(buffer.isContinuous());\n  399      EXPECT_EQ(buffer.cols * sizeof(uchar), buffer.step);\n  400  \n  401:     cv::cuda::createContinuous(100, 100, CV_8UC1, buffer);\n  402      EXPECT_EQ(100, buffer.rows);\n  403      EXPECT_EQ(100, buffer.cols);\n  404:     EXPECT_EQ(CV_8UC1, buffer.type());\n  405      EXPECT_TRUE(buffer.isContinuous());\n  406      EXPECT_EQ(buffer.cols * sizeof(uchar), buffer.step);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaarithm\\test\\test_opengl.cpp:\n  452  }\n  453  \n  454: INSTANTIATE_TEST_CASE_P(OpenGL, Texture2D, testing::Combine(DIFFERENT_SIZES, testing::Values(CV_8UC1, CV_8UC3, CV_8UC4, CV_32FC1, CV_32FC3, CV_32FC4)));\n  455  \n  456  #endif\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaarithm\\test\\test_reductions.cpp:\n   73  {\n   74      cv::Mat src = randomMat(size, depth);\n   75:     cv::Mat mask = randomMat(size, CV_8UC1, 0, 2);\n   76  \n   77      double val = cv::cuda::norm(loadMat(src, useRoi), normCode, loadMat(mask, useRoi));\n   ..\n   85  {\n   86      cv::Mat src = randomMat(size, depth);\n   87:     cv::Mat mask = randomMat(size, CV_8UC1, 0, 2);\n   88  \n   89      cv::cuda::Stream stream;\n   ..\n  137  CUDA_TEST_P(NormDiff, Accuracy)\n  138  {\n  139:     cv::Mat src1 = randomMat(size, CV_8UC1);\n  140:     cv::Mat src2 = randomMat(size, CV_8UC1);\n  141  \n  142      double val = cv::cuda::norm(loadMat(src1, useRoi), loadMat(src2, useRoi), normCode);\n  ...\n  149  CUDA_TEST_P(NormDiff, Async)\n  150  {\n  151:     cv::Mat src1 = randomMat(size, CV_8UC1);\n  152:     cv::Mat src2 = randomMat(size, CV_8UC1);\n  153  \n  154      cv::cuda::Stream stream;\n  ...\n  441  {\n  442      cv::Mat src = randomMat(size, depth);\n  443:     cv::Mat mask = randomMat(size, CV_8UC1, 0.0, 2.0);\n  444  \n  445      if (depth == CV_64F && !supportFeature(devInfo, cv::cuda::NATIVE_DOUBLE))\n  ...\n  664  {\n  665      cv::Mat src = randomMat(size, depth);\n  666:     cv::Mat mask = randomMat(size, CV_8UC1, 0.0, 2.0);\n  667  \n  668      if (depth == CV_64F && !supportFeature(devInfo, cv::cuda::NATIVE_DOUBLE))\n  ...\n  945  {\n  946      cv::Mat src = randomMat(size, type);\n  947:     cv::Mat mask = randomMat(size, CV_8UC1, 0, 2);\n  948  \n  949      cv::cuda::GpuMat dst = createMat(size, type, useRoi);\n  ...\n  986  CUDA_TEST_P(MeanStdDev, Accuracy)\n  987  {\n  988:     cv::Mat src = randomMat(size, CV_8UC1);\n  989  \n  990      if (!supportFeature(devInfo, cv::cuda::FEATURE_SET_COMPUTE_13))\n  ...\n 1018  CUDA_TEST_P(MeanStdDev, Async)\n 1019  {\n 1020:     cv::Mat src = randomMat(size, CV_8UC1);\n 1021  \n 1022      cv::cuda::Stream stream;\n ....\n 1064  CUDA_TEST_P(Integral, Accuracy)\n 1065  {\n 1066:     cv::Mat src = randomMat(size, CV_8UC1);\n 1067  \n 1068      cv::cuda::GpuMat dst = createMat(cv::Size(src.cols + 1, src.rows + 1), CV_32SC1, useRoi);\n ....\n 1101  CUDA_TEST_P(IntegralSqr, Accuracy)\n 1102  {\n 1103:     cv::Mat src = randomMat(size, CV_8UC1);\n 1104  \n 1105      cv::cuda::GpuMat dst = createMat(cv::Size(src.cols + 1, src.rows + 1), CV_64FC1, useRoi);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaarithm\\test\\test_stream.cpp:\n   68          src = cv::cuda::HostMem(cv::cuda::HostMem::PAGE_LOCKED);\n   69  \n   70:         cv::Mat m = randomMat(cv::Size(128, 128), CV_8UC1);\n   71          m.copyTo(src);\n   72      }\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudabgsegm\\src\\mog.cpp:\n  146              initialize(frame.size(), frame.type());\n  147  \n  148:         _fgmask.create(frameSize_, CV_8UC1);\n  149          GpuMat fgmask = _fgmask.getGpuMat();\n  150  \n  ...\n  175      void MOGImpl::initialize(Size frameSize, int frameType)\n  176      {\n  177:         CV_Assert( frameType == CV_8UC1 || frameType == CV_8UC3 || frameType == CV_8UC4 );\n  178  \n  179          frameSize_ = frameSize;\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudabgsegm\\src\\mog2.cpp:\n  189              initialize(frame.size(), frame.type());\n  190  \n  191:         _fgmask.create(frameSize_, CV_8UC1);\n  192          GpuMat fgmask = _fgmask.getGpuMat();\n  193  \n  ...\n  221          using namespace cv::cuda::device::mog2;\n  222  \n  223:         CV_Assert( frameType == CV_8UC1 || frameType == CV_8UC3 || frameType == CV_8UC4 );\n  224  \n  225          frameSize_ = frameSize;\n  ...\n  239  \n  240          //make the array for keeping track of the used modes per pixel - all zeros at start\n  241:         bgmodelUsedModes_.create(frameSize_, CV_8UC1);\n  242          bgmodelUsedModes_.setTo(Scalar::all(0));\n  243  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudabgsegm\\test\\test_bgsegm.cpp:\n   89      cv::Ptr<cv::BackgroundSubtractorMOG2> mog2 = cv::cuda::createBackgroundSubtractorMOG2();\n   90      mog2->setDetectShadows(detectShadow);\n   91:     cv::cuda::GpuMat foreground = createMat(frame.size(), CV_8UC1, useRoi);\n   92  \n   93      cv::Ptr<cv::BackgroundSubtractorMOG2> mog2_gold = cv::createBackgroundSubtractorMOG2();\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudacodec\\src\\video_decoder.hpp:\n   97          cuSafeCall( cuvidMapVideoFrame(decoder_, picIdx, &ptr, &pitch, &videoProcParams) );\n   98  \n   99:         return cuda::GpuMat(targetHeight() * 3 / 2, targetWidth(), CV_8UC1, (void*) ptr, pitch);\n  100      }\n  101  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudacodec\\src\\video_reader.cpp:\n   92      {\n   93          // init context\n   94:         GpuMat temp(1, 1, CV_8UC1);\n   95          temp.release();\n   96  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudacodec\\src\\video_writer.cpp:\n  442          // Allocate the CUDA memory Pitched Surface\n  443          if (surfaceFormat_ == UYVY || surfaceFormat_ == YUY2)\n  444:             videoFrame_.create(frameSize_.height, (frameSize_.width * bpp[surfaceFormat_]) / 8, CV_8UC1);\n  445          else\n  446:             videoFrame_.create((frameSize_.height * bpp[surfaceFormat_]) / 8, frameSize_.width, CV_8UC1);\n  447  \n  448          // Create the Video Context Lock (used for synchronization)\n  ...\n  615          {\n  616              CV_Assert( frame.size() == frameSize_ );\n  617:             CV_Assert( frame.type() == CV_8UC1 || frame.type() == CV_8UC3 || frame.type() == CV_8UC4 );\n  618          }\n  619          else\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudafeatures2d\\src\\brute_force_matcher.cpp:\n  163                  const GpuMat& mask = masks[i];\n  164  \n  165:                 CV_Assert( mask.empty() || (mask.type() == CV_8UC1 && mask.cols == train.rows) );\n  166  \n  167                  *trainCollectionCPU_ptr = train;\n  ...\n  331          CV_Assert( query.channels() == 1 && query.depth() < CV_64F );\n  332          CV_Assert( train.cols == query.cols && train.type() == query.type() );\n  333:         CV_Assert( mask.empty() || (mask.type() == CV_8UC1 && mask.rows == query.rows && mask.cols == train.rows) );\n  334  \n  335          typedef void (*caller_t)(const PtrStepSzb& query, const PtrStepSzb& train, const PtrStepSzb& mask,\n  ...\n  591          CV_Assert( query.channels() == 1 && query.depth() < CV_64F );\n  592          CV_Assert( train.cols == query.cols && train.type() == query.type() );\n  593:         CV_Assert( mask.empty() || (mask.type() == CV_8UC1 && mask.rows == query.rows && mask.cols == train.rows) );\n  594  \n  595          typedef void (*caller_t)(const PtrStepSzb& query, const PtrStepSzb& train, int k, const PtrStepSzb& mask,\n  ...\n  860          CV_Assert( query.channels() == 1 && query.depth() < CV_64F );\n  861          CV_Assert( train.cols == query.cols && train.type() == query.type() );\n  862:         CV_Assert( mask.empty() || (mask.type() == CV_8UC1 && mask.rows == query.rows && mask.cols == train.rows) );\n  863  \n  864          typedef void (*caller_t)(const PtrStepSzb& query, const PtrStepSzb& train, float maxDistance, const PtrStepSzb& mask,\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudafeatures2d\\src\\fast.cpp:\n  118          const GpuMat mask = _mask.getGpuMat();\n  119  \n  120:         CV_Assert( img.type() == CV_8UC1 );\n  121:         CV_Assert( mask.empty() || (mask.type() == CV_8UC1 && mask.size() == img.size()) );\n  122  \n  123          BufferPool pool(stream);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudafeatures2d\\src\\orb.cpp:\n  568          pattern_.upload(h_pattern);\n  569  \n  570:         blurFilter_ = cuda::createGaussianFilter(CV_8UC1, -1, Size(7, 7), 2, 2, BORDER_REFLECT_101);\n  571      }\n  572  \n  ...\n  664          const GpuMat mask = _mask.getGpuMat();\n  665  \n  666:         CV_Assert( image.type() == CV_8UC1 );\n  667:         CV_Assert( mask.empty() || (mask.type() == CV_8UC1 && mask.size() == image.size()) );\n  668  \n  669          imagePyr_.resize(nLevels_);\n  ...\n  677  \n  678              ensureSizeIsEnough(sz, image.type(), imagePyr_[level]);\n  679:             ensureSizeIsEnough(sz, CV_8UC1, maskPyr_[level]);\n  680              maskPyr_[level].setTo(Scalar::all(255));\n  681  \n  ...\n  710  \n  711              // Filter keypoints by image border\n  712:             ensureSizeIsEnough(sz, CV_8UC1, buf_);\n  713              buf_.setTo(Scalar::all(0), stream);\n  714              Rect inner(edgeThreshold_, edgeThreshold_, sz.width - 2 * edgeThreshold_, sz.height - 2 * edgeThreshold_);\n  ...\n  797          }\n  798  \n  799:         ensureSizeIsEnough(nAllkeypoints, descriptorSize(), CV_8UC1, _descriptors);\n  800          GpuMat descriptors = _descriptors.getGpuMat();\n  801  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudafeatures2d\\test\\test_features2d.cpp:\n  162      ASSERT_FALSE(image.empty());\n  163  \n  164:     cv::Mat mask(image.size(), CV_8UC1, cv::Scalar::all(1));\n  165      mask(cv::Range(0, image.rows / 2), cv::Range(0, image.cols / 2)).setTo(cv::Scalar::all(0));\n  166  \n  ...\n  294      if (useMask)\n  295      {\n  296:         mask.create(query.rows, train.rows, CV_8UC1);\n  297          mask.setTo(cv::Scalar::all(1));\n  298      }\n  ...\n  329      for (int mi = 0; mi < 2; mi++)\n  330      {\n  331:         masks[mi] = cv::cuda::GpuMat(query.rows, train.rows/2, CV_8UC1, cv::Scalar::all(1));\n  332          for (int di = 0; di < queryDescCount/2; di++)\n  333              masks[mi].col(di * countFactor).setTo(cv::Scalar::all(0));\n  ...\n  379      if (useMask)\n  380      {\n  381:         mask.create(query.rows, train.rows, CV_8UC1);\n  382          mask.setTo(cv::Scalar::all(1));\n  383      }\n  ...\n  419      if (useMask)\n  420      {\n  421:         mask.create(query.rows, train.rows, CV_8UC1);\n  422          mask.setTo(cv::Scalar::all(1));\n  423      }\n  ...\n  466      for (int mi = 0; mi < 2; mi++ )\n  467      {\n  468:         masks[mi] = cv::cuda::GpuMat(query.rows, train.rows / 2, CV_8UC1, cv::Scalar::all(1));\n  469          for (int di = 0; di < queryDescCount / 2; di++)\n  470              masks[mi].col(di * countFactor).setTo(cv::Scalar::all(0));\n  ...\n  529      for (int mi = 0; mi < 2; mi++ )\n  530      {\n  531:         masks[mi] = cv::cuda::GpuMat(query.rows, train.rows / 2, CV_8UC1, cv::Scalar::all(1));\n  532          for (int di = 0; di < queryDescCount / 2; di++)\n  533              masks[mi].col(di * countFactor).setTo(cv::Scalar::all(0));\n  ...\n  599          if (useMask)\n  600          {\n  601:             mask.create(query.rows, train.rows, CV_8UC1);\n  602              mask.setTo(cv::Scalar::all(1));\n  603          }\n  ...\n  643      for (int mi = 0; mi < 2; mi++)\n  644      {\n  645:         masks[mi] = cv::cuda::GpuMat(query.rows, train.rows / 2, CV_8UC1, cv::Scalar::all(1));\n  646          for (int di = 0; di < queryDescCount / 2; di++)\n  647              masks[mi].col(di * countFactor).setTo(cv::Scalar::all(0));\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudafilters\\include\\opencv2\\cudafilters.hpp:\n   90  /** @brief Creates a normalized 2D box filter.\n   91  \n   92: @param srcType Input image type. Only CV_8UC1, CV_8UC4 and CV_32FC1 are supported for now.\n   93  @param dstType Output image type. Only the same type as src is supported for now.\n   94  @param ksize Kernel size.\n   ..\n  251  -   **MORPH_TOPHAT** \"top hat\"\n  252  -   **MORPH_BLACKHAT** \"black hat\"\n  253: @param srcType Input/output image type. Only CV_8UC1, CV_8UC4, CV_32FC1 and CV_32FC4 are supported.\n  254  @param kernel 2D 8-bit structuring element for the morphological operation.\n  255  @param anchor Anchor position within the structuring element. Negative values mean that the anchor\n  ...\n  266  /** @brief Creates the maximum filter.\n  267  \n  268: @param srcType Input/output image type. Only CV_8UC1 and CV_8UC4 are supported.\n  269  @param ksize Kernel size.\n  270  @param anchor Anchor point. The default value (-1) means that the anchor is at the kernel center.\n  ...\n  278  /** @brief Creates the minimum filter.\n  279  \n  280: @param srcType Input/output image type. Only CV_8UC1 and CV_8UC4 are supported.\n  281  @param ksize Kernel size.\n  282  @param anchor Anchor point. The default value (-1) means that the anchor is at the kernel center.\n  ...\n  293  /** @brief Creates a horizontal 1D box filter.\n  294  \n  295: @param srcType Input image type. Only CV_8UC1 type is supported for now.\n  296  @param dstType Output image type. Only CV_32FC1 type is supported for now.\n  297  @param ksize Kernel size.\n  ...\n  304  /** @brief Creates a vertical 1D box filter.\n  305  \n  306: @param srcType Input image type. Only CV_8UC1 type is supported for now.\n  307  @param dstType Output image type. Only CV_32FC1 type is supported for now.\n  308  @param ksize Kernel size.\n  ...\n  319  /** @brief Performs median filtering for each point of the source image.\n  320  \n  321: @param srcType type of of source image. Only CV_8UC1 images are supported for now.\n  322  @param windowSize Size of the kernerl used for the filtering. Uses a (windowSize x windowSize) filter.\n  323  @param partition Specifies the parallel granularity of the workload. This parameter should be used GPU experts when optimizing performance.\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudafilters\\perf\\perf_filters.cpp:\n   54  PERF_TEST_P(Sz_Type_KernelSz, Blur,\n   55              Combine(CUDA_TYPICAL_MAT_SIZES,\n   56:                     Values(CV_8UC1, CV_8UC4, CV_32FC1),\n   57                      Values(3, 5, 7)))\n   58  {\n   ..\n   90  // Filter2D\n   91  \n   92: PERF_TEST_P(Sz_Type_KernelSz, Filter2D, Combine(CUDA_TYPICAL_MAT_SIZES, Values(CV_8UC1, CV_8UC4, CV_32FC1, CV_32FC4), Values(3, 5, 7, 9, 11, 13, 15)))\n   93  {\n   94      declare.time(20.0);\n   ..\n  128  // Laplacian\n  129  \n  130: PERF_TEST_P(Sz_Type_KernelSz, Laplacian, Combine(CUDA_TYPICAL_MAT_SIZES, Values(CV_8UC1, CV_8UC4, CV_32FC1, CV_32FC4), Values(1, 3)))\n  131  {\n  132      declare.time(20.0);\n  ...\n  163  // Sobel\n  164  \n  165: PERF_TEST_P(Sz_Type_KernelSz, Sobel, Combine(CUDA_TYPICAL_MAT_SIZES, Values(CV_8UC1, CV_8UC4, CV_32FC1), Values(3, 5, 7, 9, 11, 13, 15)))\n  166  {\n  167      declare.time(20.0);\n  ...\n  198  // Scharr\n  199  \n  200: PERF_TEST_P(Sz_Type, Scharr, Combine(CUDA_TYPICAL_MAT_SIZES, Values(CV_8UC1, CV_8UC4, CV_32FC1)))\n  201  {\n  202      declare.time(20.0);\n  ...\n  232  // GaussianBlur\n  233  \n  234: PERF_TEST_P(Sz_Type_KernelSz, GaussianBlur, Combine(CUDA_TYPICAL_MAT_SIZES, Values(CV_8UC1, CV_8UC4, CV_32FC1), Values(3, 5, 7, 9, 11, 13, 15)))\n  235  {\n  236      declare.time(20.0);\n  ...\n  267  // Erode\n  268  \n  269: PERF_TEST_P(Sz_Type, Erode, Combine(CUDA_TYPICAL_MAT_SIZES, Values(CV_8UC1, CV_8UC4)))\n  270  {\n  271      declare.time(20.0);\n  ...\n  303  // Dilate\n  304  \n  305: PERF_TEST_P(Sz_Type, Dilate, Combine(CUDA_TYPICAL_MAT_SIZES, Values(CV_8UC1, CV_8UC4)))\n  306  {\n  307      declare.time(20.0);\n  ...\n  343  DEF_PARAM_TEST(Sz_Type_Op, cv::Size, MatType, MorphOp);\n  344  \n  345: PERF_TEST_P(Sz_Type_Op, MorphologyEx, Combine(CUDA_TYPICAL_MAT_SIZES, Values(CV_8UC1, CV_8UC4), MorphOp::all()))\n  346  {\n  347      declare.time(20.0);\n  ...\n  383  DEF_PARAM_TEST(Sz_KernelSz, cv::Size, int);\n  384  \n  385: //PERF_TEST_P(Sz_Type_KernelSz, Median, Combine(CUDA_TYPICAL_MAT_SIZES, Values(CV_8UC1,CV_8UC1), Values(3, 5, 7, 9, 11, 13, 15)))\n  386  PERF_TEST_P(Sz_KernelSz, Median, Combine(CUDA_TYPICAL_MAT_SIZES, Values(3, 5, 7, 9, 11, 13, 15)))\n  387  {\n  ...\n  390      const cv::Size size = GET_PARAM(0);\n  391      // const int type = GET_PARAM(1);\n  392:     const int type = CV_8UC1;\n  393      const int kernel = GET_PARAM(1);\n  394  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudafilters\\src\\filtering.cpp:\n  120          ksize_(ksize), anchor_(anchor), type_(srcType), borderMode_(borderMode), borderVal_(borderVal)\n  121      {\n  122:         CV_Assert( srcType == CV_8UC1 || srcType == CV_8UC4 || srcType == CV_32FC1);\n  123          CV_Assert( dstType == srcType );\n  124  \n  ...\n  249          switch (srcType)\n  250          {\n  251:         case CV_8UC1:\n  252              func_ = cv::cuda::device::filter2D<uchar, uchar>;\n  253              break;\n  ...\n  556  \n  557          CV_Assert( op == MORPH_ERODE || op == MORPH_DILATE );\n  558:         CV_Assert( srcType == CV_8UC1 || srcType == CV_8UC4 || srcType == CV_32FC1 || srcType == CV_32FC4 );\n  559  \n  560          Mat kernel = _kernel.getMat();\n  ...\n  584          kernel.convertTo(kernel8U, CV_8U);\n  585  \n  586:         kernel_ = cuda::createContinuous(kernel.size(), CV_8UC1);\n  587          kernel_.upload(kernel8U);\n  588  \n  589:         if(srcType == CV_8UC1 || srcType == CV_8UC4)\n  590          {\n  591              func8u_ = funcs8u[op][CV_MAT_CN(srcType)];\n  ...\n  633          oAnchor.y = anchor_.y;\n  634  \n  635:         if (type_ == CV_8UC1 || type_ == CV_8UC4)\n  636          {\n  637              nppSafeCall( func8u_(srcRoi.ptr<Npp8u>(), static_cast<int>(srcRoi.step), dst.ptr<Npp8u>(), static_cast<int>(dst.step),\n  ...\n  865          static const nppFilterRank_t minFuncs[] = {0, nppiFilterMin_8u_C1R, 0, 0, nppiFilterMin_8u_C4R};\n  866  \n  867:         CV_Assert( srcType == CV_8UC1 || srcType == CV_8UC4 );\n  868  \n  869          normalizeAnchor(anchor_, ksize_);\n  ...\n  945          srcType_(srcType), dstType_(dstType), ksize_(ksize), anchor_(anchor), borderMode_(borderMode), borderVal_(borderVal)\n  946      {\n  947:         CV_Assert( srcType_ == CV_8UC1 );\n  948          CV_Assert( dstType_ == CV_32FC1 );\n  949  \n  ...\n 1006          srcType_(srcType), dstType_(dstType), ksize_(ksize), anchor_(anchor), borderMode_(borderMode), borderVal_(borderVal)\n 1007      {\n 1008:         CV_Assert( srcType_ == CV_8UC1 );\n 1009          CV_Assert( dstType_ == CV_32FC1 );\n 1010  \n ....\n 1075          windowSize(_windowSize),partitions(_partitions)\n 1076      {\n 1077:         CV_Assert( srcType == CV_8UC1 );\n 1078          CV_Assert(windowSize>=3);\n 1079          CV_Assert(_partitions>=1);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudafilters\\test\\test_filters.cpp:\n  111      ALL_DEVICES,\n  112      DIFFERENT_SIZES,\n  113:     testing::Values(MatType(CV_8UC1), MatType(CV_8UC4), MatType(CV_32FC1)),\n  114      testing::Values(KSize(cv::Size(3, 3)), KSize(cv::Size(5, 5)), KSize(cv::Size(7, 7))),\n  115      testing::Values(Anchor(cv::Point(-1, -1)), Anchor(cv::Point(0, 0)), Anchor(cv::Point(2, 2))),\n  ...\n  163      ALL_DEVICES,\n  164      DIFFERENT_SIZES,\n  165:     testing::Values(MatType(CV_8UC1), MatType(CV_8UC4), MatType(CV_16UC1), MatType(CV_16UC4), MatType(CV_32FC1), MatType(CV_32FC4)),\n  166      testing::Values(KSize(cv::Size(3, 3)), KSize(cv::Size(5, 5)), KSize(cv::Size(7, 7)), KSize(cv::Size(11, 11)), KSize(cv::Size(13, 13)), KSize(cv::Size(15, 15))),\n  167      testing::Values(Anchor(cv::Point(-1, -1)), Anchor(cv::Point(0, 0)), Anchor(cv::Point(2, 2))),\n  ...\n  210      ALL_DEVICES,\n  211      DIFFERENT_SIZES,\n  212:     testing::Values(MatType(CV_8UC1), MatType(CV_8UC4), MatType(CV_32FC1)),\n  213      testing::Values(KSize(cv::Size(1, 1)), KSize(cv::Size(3, 3))),\n  214      WHOLE_SUBMAT));\n  ...\n  534      ALL_DEVICES,\n  535      DIFFERENT_SIZES,\n  536:     testing::Values(MatType(CV_8UC1), MatType(CV_8UC4)),\n  537      testing::Values(Anchor(cv::Point(-1, -1)), Anchor(cv::Point(0, 0)), Anchor(cv::Point(2, 2))),\n  538      testing::Values(Iterations(1), Iterations(2), Iterations(3)),\n  ...\n  585      ALL_DEVICES,\n  586      DIFFERENT_SIZES,\n  587:     testing::Values(MatType(CV_8UC1), MatType(CV_8UC4)),\n  588      testing::Values(Anchor(cv::Point(-1, -1)), Anchor(cv::Point(0, 0)), Anchor(cv::Point(2, 2))),\n  589      testing::Values(Iterations(1), Iterations(2), Iterations(3)),\n  ...\n  640      ALL_DEVICES,\n  641      DIFFERENT_SIZES,\n  642:     testing::Values(MatType(CV_8UC1), MatType(CV_8UC4)),\n  643      MorphOp::all(),\n  644      testing::Values(Anchor(cv::Point(-1, -1)), Anchor(cv::Point(0, 0)), Anchor(cv::Point(2, 2))),\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaimgproc\\include\\opencv2\\cudaimgproc.hpp:\n  196  /** @brief Calculates histogram for one channel 8-bit image.\n  197  \n  198: @param src Source image with CV_8UC1 type.\n  199  @param hist Destination histogram with one row, 256 columns, and the CV_32SC1 type.\n  200  @param stream Stream for the asynchronous version.\n  ...\n  204  /** @brief Calculates histogram for one channel 8-bit image confined in given mask.\n  205  \n  206: @param src Source image with CV_8UC1 type.\n  207  @param hist Destination histogram with one row, 256 columns, and the CV_32SC1 type.\n  208: @param mask A mask image same size as src and of type CV_8UC1.\n  209  @param stream Stream for the asynchronous version.\n  210   */\n  ...\n  213  /** @brief Equalizes the histogram of a grayscale image.\n  214  \n  215: @param src Source image with CV_8UC1 type.\n  216  @param dst Destination image.\n  217  @param stream Stream for the asynchronous version.\n  ...\n  229      /** @brief Equalizes the histogram of a grayscale image using Contrast Limited Adaptive Histogram Equalization.\n  230  \n  231:     @param src Source image with CV_8UC1 type.\n  232      @param dst Destination image.\n  233      @param stream Stream for the asynchronous version.\n  ...\n  532  /** @brief Creates implementation for Harris cornerness criteria.\n  533  \n  534: @param srcType Input source type. Only CV_8UC1 and CV_32FC1 are supported for now.\n  535  @param blockSize Neighborhood size.\n  536  @param ksize Aperture parameter for the Sobel operator.\n  ...\n  546  cornerness criteria).\n  547  \n  548: @param srcType Input source type. Only CV_8UC1 and CV_32FC1 are supported for now.\n  549  @param blockSize Neighborhood size.\n  550  @param ksize Aperture parameter for the Sobel operator.\n  ...\n  569      positions).\n  570      @param mask Optional region of interest. If the image is not empty (it needs to have the type\n  571:     CV_8UC1 and the same size as image ), it specifies the region in which the corners are detected.\n  572      @param stream Stream for the asynchronous version.\n  573       */\n  ...\n  577  /** @brief Creates implementation for cuda::CornersDetector .\n  578  \n  579: @param srcType Input source type. Only CV_8UC1 and CV_32FC1 are supported for now.\n  580  @param maxCorners Maximum number of corners to return. If there are more corners than are found,\n  581  the strongest of them is returned.\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaimgproc\\perf\\perf_color.cpp:\n  160      const int code = GET_PARAM(1);\n  161  \n  162:     cv::Mat src(size, CV_8UC1);\n  163      declare.in(src, WARMUP_RNG);\n  164  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaimgproc\\perf\\perf_corners.cpp:\n   54  PERF_TEST_P(Image_Type_Border_BlockSz_ApertureSz, CornerHarris,\n   55              Combine(Values<string>(\"gpu/stereobm/aloe-L.png\"),\n   56:                     Values(CV_8UC1, CV_32FC1),\n   57                      Values(BorderMode(cv::BORDER_REFLECT101), BorderMode(cv::BORDER_REPLICATE), BorderMode(cv::BORDER_REFLECT)),\n   58                      Values(3, 5, 7),\n   ..\n   98  PERF_TEST_P(Image_Type_Border_BlockSz_ApertureSz, CornerMinEigenVal,\n   99              Combine(Values<string>(\"gpu/stereobm/aloe-L.png\"),\n  100:                     Values(CV_8UC1, CV_32FC1),\n  101                      Values(BorderMode(cv::BORDER_REFLECT101), BorderMode(cv::BORDER_REPLICATE), BorderMode(cv::BORDER_REFLECT)),\n  102                      Values(3, 5, 7),\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaimgproc\\perf\\perf_histogram.cpp:\n  133      const cv::Size size = GetParam();\n  134  \n  135:     cv::Mat src(size, CV_8UC1);\n  136      declare.in(src, WARMUP_RNG);\n  137  \n  ...\n  159      const cv::Size size = GetParam();\n  160  \n  161:     cv::Mat src(size, CV_8UC1);\n  162      declare.in(src, WARMUP_RNG);\n  163  \n  ...\n  193      const double clipLimit = GET_PARAM(1);\n  194  \n  195:     cv::Mat src(size, CV_8UC1);\n  196      declare.in(src, WARMUP_RNG);\n  197  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaimgproc\\perf\\perf_hough.cpp:\n   92      const int threshold = 300;\n   93  \n   94:     cv::Mat src(size, CV_8UC1, cv::Scalar::all(0));\n   95      cv::line(src, cv::Point(0, 100), cv::Point(src.cols, 100), cv::Scalar::all(255), 1);\n   96      cv::line(src, cv::Point(0, 200), cv::Point(src.cols, 200), cv::Scalar::all(255), 1);\n   ..\n  195      const int votesThreshold = 15;\n  196  \n  197:     cv::Mat src(size, CV_8UC1, cv::Scalar::all(0));\n  198      cv::circle(src, cv::Point(100, 100), 20, cv::Scalar::all(255), -1);\n  199      cv::circle(src, cv::Point(200, 200), 25, cv::Scalar::all(255), -1);\n  ...\n  237      ASSERT_FALSE(templ.empty());\n  238  \n  239:     cv::Mat image(imageSize, CV_8UC1, cv::Scalar::all(0));\n  240      templ.copyTo(image(cv::Rect(50, 50, templ.cols, templ.rows)));\n  241  \n  ...\n  285      ASSERT_FALSE(templ.empty());\n  286  \n  287:     cv::Mat image(imageSize, CV_8UC1, cv::Scalar::all(0));\n  288      templ.copyTo(image(cv::Rect(50, 50, templ.cols, templ.rows)));\n  289  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaimgproc\\src\\canny.cpp:\n  134          GpuMat image = _image.getGpuMat();\n  135  \n  136:         CV_Assert( image.type() == CV_8UC1 );\n  137          CV_Assert( deviceSupports(SHARED_ATOMICS) );\n  138  \n  ...\n  142          createBuf(image.size());\n  143  \n  144:         _edges.create(image.size(), CV_8UC1);\n  145          GpuMat edges = _edges.getGpuMat();\n  146  \n  ...\n  186          createBuf(dx.size());\n  187  \n  188:         _edges.create(dx.size(), CV_8UC1);\n  189          GpuMat edges = _edges.getGpuMat();\n  190  \n  ...\n  204          if (apperture_size_ != 3 && apperture_size_ != old_apperture_size_)\n  205          {\n  206:             filterDX_ = cuda::createDerivFilter(CV_8UC1, CV_32S, 1, 0, apperture_size_, false, 1, BORDER_REPLICATE);\n  207:             filterDY_ = cuda::createDerivFilter(CV_8UC1, CV_32S, 0, 1, apperture_size_, false, 1, BORDER_REPLICATE);\n  208              old_apperture_size_ = apperture_size_;\n  209          }\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaimgproc\\src\\color.cpp:\n  451          CV_Assert( src.channels() == 2 );\n  452  \n  453:         _dst.create(src.size(), CV_8UC1);\n  454          GpuMat dst = _dst.getGpuMat();\n  455  \n  ...\n  464          CV_Assert( src.channels() == 2 );\n  465  \n  466:         _dst.create(src.size(), CV_8UC1);\n  467          GpuMat dst = _dst.getGpuMat();\n  468  \n  ...\n 1856          GpuMat src = _src.getGpuMat();\n 1857  \n 1858:         CV_Assert( src.type() == CV_8UC1 || src.type() == CV_16UC1 );\n 1859          CV_Assert( src.rows > 2 && src.cols > 2 );\n 1860          CV_Assert( dcn == 3 || dcn == 4 );\n ....\n 1894          GpuMat src = _src.getGpuMat();\n 1895  \n 1896:         CV_Assert( src.type() == CV_8UC1 || src.type() == CV_16UC1 );\n 1897          CV_Assert( src.rows > 2 && src.cols > 2 );\n 1898  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaimgproc\\src\\generalized_hough.cpp:\n  172  #ifdef HAVE_OPENCV_CUDAFILTERS\n  173          canny_ = cuda::createCannyEdgeDetector(cannyLowThresh_, cannyHighThresh_);\n  174:         filterDx_ = cuda::createSobelFilter(CV_8UC1, CV_32S, 1, 0);\n  175:         filterDy_ = cuda::createSobelFilter(CV_8UC1, CV_32S, 0, 1);\n  176  #endif\n  177      }\n  ...\n  182          GpuMat src = _src.getGpuMat();\n  183  \n  184:         CV_Assert( src.type() == CV_8UC1 );\n  185          CV_Assert( cannyLowThresh_ > 0 && cannyLowThresh_ < cannyHighThresh_ );\n  186  \n  ...\n  191          filterDy_->apply(src, dy);\n  192  \n  193:         ensureSizeIsEnough(src.size(), CV_8UC1, edges);\n  194  \n  195          canny_->setLowThreshold(cannyLowThresh_);\n  ...\n  224          dy.getGpuMat().copyTo(templDy_);\n  225  \n  226:         CV_Assert( templEdges_.type() == CV_8UC1 );\n  227          CV_Assert( templDx_.type() == CV_32FC1 && templDx_.size() == templEdges_.size() );\n  228          CV_Assert( templDy_.type() == templDx_.type() && templDy_.size() == templEdges_.size() );\n  ...\n  274          dy.getGpuMat().copyTo(imageDy_);\n  275  \n  276:         CV_Assert( imageEdges_.type() == CV_8UC1 );\n  277          CV_Assert( imageDx_.type() == CV_32FC1 && imageDx_.size() == imageEdges_.size() );\n  278          CV_Assert( imageDy_.type() == imageDx_.type() && imageDy_.size() == imageEdges_.size() );\n  ...\n  314          };\n  315  \n  316:         CV_Assert( edges.type() == CV_8UC1 );\n  317          CV_Assert( dx.size() == edges.size() );\n  318          CV_Assert( dy.type() == dx.type() && dy.size() == edges.size() );\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaimgproc\\src\\gftt.cpp:\n  103          GpuMat mask = _mask.getGpuMat();\n  104  \n  105:         CV_Assert( mask.empty() || (mask.type() == CV_8UC1 && mask.size() == image.size()) );\n  106  \n  107          ensureSizeIsEnough(image.size(), CV_32FC1, eig_);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaimgproc\\src\\histogram.cpp:\n   83      GpuMat mask = _mask.getGpuMat();\n   84  \n   85:     CV_Assert( src.type() == CV_8UC1 );\n   86:     CV_Assert( mask.empty() || mask.type() == CV_8UC1 );\n   87      CV_Assert( mask.empty() || mask.size() == src.size() );\n   88  \n   ..\n  110      GpuMat src = _src.getGpuMat();\n  111  \n  112:     CV_Assert( src.type() == CV_8UC1 );\n  113  \n  114      _dst.create(src.size(), src.type());\n  ...\n  121  \n  122      BufferPool pool(_stream);\n  123:     GpuMat buf = pool.getBuffer(1, static_cast<int>(bufSize), CV_8UC1);\n  124  \n  125      GpuMat hist(1, 256, CV_32SC1, buf.data);\n  126      GpuMat lut(1, 256, CV_32SC1, buf.data + 256 * sizeof(int));\n  127:     GpuMat intBuf(1, intBufSize, CV_8UC1, buf.data + 2 * 256 * sizeof(int));\n  128  \n  129      cuda::calcHist(src, hist, _stream);\n  ...\n  187          GpuMat src = _src.getGpuMat();\n  188  \n  189:         CV_Assert( src.type() == CV_8UC1 );\n  190  \n  191          _dst.create( src.size(), src.type() );\n  ...\n  194          const int histSize = 256;\n  195  \n  196:         ensureSizeIsEnough(tilesX_ * tilesY_, histSize, CV_8UC1, lut_);\n  197  \n  198          cudaStream_t stream = StreamAccessor::getStream(s);\n  ...\n  309  \n  310              BufferPool pool(stream);\n  311:             GpuMat buf = pool.getBuffer(1, buf_size, CV_8UC1);\n  312  \n  313              NppStreamHandler h(stream);\n  ...\n  343  \n  344              BufferPool pool(stream);\n  345:             GpuMat buf = pool.getBuffer(1, buf_size, CV_8UC1);\n  346  \n  347              NppStreamHandler h(stream);\n  ...\n  413  \n  414              BufferPool pool(stream);\n  415:             GpuMat buf = pool.getBuffer(1, buf_size, CV_8UC1);\n  416  \n  417              NppStreamHandler h(stream);\n  ...\n  454  \n  455              BufferPool pool(stream);\n  456:             GpuMat buf = pool.getBuffer(1, buf_size, CV_8UC1);\n  457  \n  458              NppStreamHandler h(stream);\n  ...\n  518      }\n  519  \n  520:     CV_Assert( src.type() == CV_8UC1 || src.type() == CV_16UC1 || src.type() == CV_16SC1 );\n  521  \n  522      hist_callers[src.depth()](src, hist, histSize, lowerLevel, upperLevel, stream);\n  ...\n  557      GpuMat levels = _levels.getGpuMat();\n  558  \n  559:     CV_Assert( src.type() == CV_8UC1 || src.type() == CV_16UC1 || src.type() == CV_16SC1 || src.type() == CV_32FC1 );\n  560  \n  561      hist_callers[src.depth()](src, hist, levels, stream);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaimgproc\\src\\hough_circles.cpp:\n  152          canny_ = cuda::createCannyEdgeDetector(std::max(cannyThreshold_ / 2, 1), cannyThreshold_);\n  153  \n  154:         filterDx_ = cuda::createSobelFilter(CV_8UC1, CV_32S, 1, 0);\n  155:         filterDy_ = cuda::createSobelFilter(CV_8UC1, CV_32S, 0, 1);\n  156      }\n  157  \n  ...\n  166          GpuMat src = _src.getGpuMat();\n  167  \n  168:         CV_Assert( src.type() == CV_8UC1 );\n  169          CV_Assert( src.cols < std::numeric_limits<unsigned short>::max() );\n  170          CV_Assert( src.rows < std::numeric_limits<unsigned short>::max() );\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaimgproc\\src\\hough_lines.cpp:\n  137          GpuMat src = _src.getGpuMat();\n  138  \n  139:         CV_Assert( src.type() == CV_8UC1 );\n  140          CV_Assert( src.cols < std::numeric_limits<unsigned short>::max() );\n  141          CV_Assert( src.rows < std::numeric_limits<unsigned short>::max() );\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaimgproc\\src\\hough_segments.cpp:\n  141          GpuMat src = _src.getGpuMat();\n  142  \n  143:         CV_Assert( src.type() == CV_8UC1 );\n  144          CV_Assert( src.cols < std::numeric_limits<unsigned short>::max() );\n  145          CV_Assert( src.rows < std::numeric_limits<unsigned short>::max() );\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaimgproc\\test\\test_bilateral_filter.cpp:\n   91      ALL_DEVICES,\n   92      testing::Values(cv::Size(128, 128), cv::Size(113, 113), cv::Size(639, 481)),\n   93:     testing::Values(MatType(CV_8UC1), MatType(CV_8UC3), MatType(CV_32FC1), MatType(CV_32FC3))\n   94      ));\n   95  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaimgproc\\test\\test_blend.cpp:\n  119      ALL_DEVICES,\n  120      DIFFERENT_SIZES,\n  121:     testing::Values(MatType(CV_8UC1), MatType(CV_8UC3), MatType(CV_8UC4), MatType(CV_32FC1), MatType(CV_32FC3), MatType(CV_32FC4)),\n  122      WHOLE_SUBMAT));\n  123  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaimgproc\\test\\test_corners.cpp:\n   96  INSTANTIATE_TEST_CASE_P(CUDA_ImgProc, CornerHarris, testing::Combine(\n   97      ALL_DEVICES,\n   98:     testing::Values(MatType(CV_8UC1), MatType(CV_32FC1)),\n   99      testing::Values(BorderType(cv::BORDER_REFLECT101), BorderType(cv::BORDER_REPLICATE), BorderType(cv::BORDER_REFLECT)),\n  100      testing::Values(BlockSize(3), BlockSize(5), BlockSize(7)),\n  ...\n  142  INSTANTIATE_TEST_CASE_P(CUDA_ImgProc, CornerMinEigen, testing::Combine(\n  143      ALL_DEVICES,\n  144:     testing::Values(MatType(CV_8UC1), MatType(CV_32FC1)),\n  145      testing::Values(BorderType(cv::BORDER_REFLECT101), BorderType(cv::BORDER_REPLICATE), BorderType(cv::BORDER_REFLECT)),\n  146      testing::Values(BlockSize(3), BlockSize(5), BlockSize(7)),\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaimgproc\\test\\test_gftt.cpp:\n  115      double qualityLevel = 0.01;\n  116  \n  117:     cv::cuda::GpuMat src(100, 100, CV_8UC1, cv::Scalar::all(0));\n  118      cv::cuda::GpuMat corners(1, maxCorners, CV_32FC2);\n  119  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaimgproc\\test\\test_histogram.cpp:\n   68  CUDA_TEST_P(HistEven, Accuracy)\n   69  {\n   70:     cv::Mat src = randomMat(size, CV_8UC1);\n   71  \n   72      int hbins = 30;\n   ..\n  113  CUDA_TEST_P(CalcHist, Accuracy)\n  114  {\n  115:     cv::Mat src = randomMat(size, CV_8UC1);\n  116  \n  117      cv::cuda::GpuMat hist;\n  ...\n  154  CUDA_TEST_P(CalcHistWithMask, Accuracy)\n  155  {\n  156:     cv::Mat src = randomMat(size, CV_8UC1);\n  157:     cv::Mat mask = randomMat(size, CV_8UC1);\n  158      cv::Mat(mask, cv::Rect(0, 0, size.width / 2, size.height / 2)).setTo(0);\n  159  \n  ...\n  199  CUDA_TEST_P(EqualizeHist, Accuracy)\n  200  {\n  201:     cv::Mat src = randomMat(size, CV_8UC1);\n  202  \n  203      cv::cuda::GpuMat dst;\n  ...\n  240  CUDA_TEST_P(CLAHE, Accuracy)\n  241  {\n  242:     cv::Mat src = randomMat(size, CV_8UC1);\n  243  \n  244      cv::Ptr<cv::cuda::CLAHE> clahe = cv::cuda::createCLAHE(clipLimit);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaimgproc\\test\\test_hough.cpp:\n   94      const int threshold = 100;\n   95  \n   96:     cv::Mat src(size, CV_8UC1);\n   97      generateLines(src);\n   98  \n   ..\n  105      hough->downloadResults(d_lines, lines);\n  106  \n  107:     cv::Mat dst(size, CV_8UC1);\n  108      drawLines(dst, lines);\n  109  \n  ...\n  150      circles_gold[3] = cv::Vec3i(80, 10, maxRadius);\n  151  \n  152:     cv::Mat src(size, CV_8UC1);\n  153      drawCircles(src, circles_gold, true);\n  154  \n  ...\n  213      pos_gold[2] = cv::Point(2 * templCenter.x + 40, 2 * templCenter.y + 40);\n  214  \n  215:     cv::Mat image(templ.rows * 3, templ.cols * 3, CV_8UC1, cv::Scalar::all(0));\n  216      for (size_t i = 0; i < gold_count; ++i)\n  217      {\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudalegacy\\src\\bm.cpp:\n   60  void cv::cuda::calcOpticalFlowBM(const GpuMat& prev, const GpuMat& curr, Size blockSize, Size shiftSize, Size maxRange, bool usePrevious, GpuMat& velx, GpuMat& vely, GpuMat& buf, Stream& st)\n   61  {\n   62:     CV_Assert( prev.type() == CV_8UC1 );\n   63      CV_Assert( curr.size() == prev.size() && curr.type() == prev.type() );\n   64  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudalegacy\\src\\bm_fast.cpp:\n   62  void cv::cuda::FastOpticalFlowBM::operator ()(const GpuMat& I0, const GpuMat& I1, GpuMat& flowx, GpuMat& flowy, int search_window, int block_window, Stream& stream)\n   63  {\n   64:     CV_Assert( I0.type() == CV_8UC1 );\n   65      CV_Assert( I1.size() == I0.size() && I1.type() == I0.type() );\n   66  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudalegacy\\src\\fgd.cpp:\n  498          Pbcc_.setTo(Scalar::all(0));\n  499  \n  500:         cuda::ensureSizeIsEnough(size, CV_8UC1, is_trained_st_model_);\n  501          is_trained_st_model_.setTo(Scalar::all(0));\n  502  \n  503:         cuda::ensureSizeIsEnough(size, CV_8UC1, is_trained_dyn_model_);\n  504          is_trained_dyn_model_.setTo(Scalar::all(0));\n  505  \n  ...\n  698          frameSize_ = firstFrame.size();\n  699  \n  700:         cuda::ensureSizeIsEnough(firstFrame.size(), CV_8UC1, foreground_);\n  701  \n  702          copyChannels(firstFrame, background_, 4);\n  703          copyChannels(firstFrame, prevFrame_, 4);\n  704  \n  705:         cuda::ensureSizeIsEnough(firstFrame.size(), CV_8UC1, Ftd_);\n  706:         cuda::ensureSizeIsEnough(firstFrame.size(), CV_8UC1, Fbd_);\n  707  \n  708          stat_.create(firstFrame.size(), params_);\n  ...\n  715              Point anchor(params_.perform_morphing, params_.perform_morphing);\n  716  \n  717:             dilateFilter_ = cuda::createMorphologyFilter(MORPH_DILATE, CV_8UC1, kernel, anchor);\n  718:             erodeFilter_ = cuda::createMorphologyFilter(MORPH_ERODE, CV_8UC1, kernel, anchor);\n  719          }\n  720  #endif\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudalegacy\\src\\gmg.cpp:\n  207          }\n  208  \n  209:         _fgmask.create(frameSize_, CV_8UC1);\n  210          GpuMat fgmask = _fgmask.getGpuMat();\n  211  \n  ...\n  262  #if defined(HAVE_OPENCV_CUDAFILTERS) && defined(HAVE_OPENCV_CUDAARITHM)\n  263          if (smoothingRadius_ > 0)\n  264:             boxFilter_ = cuda::createBoxFilter(CV_8UC1, -1, Size(smoothingRadius_, smoothingRadius_));\n  265  #endif\n  266  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudalegacy\\src\\graphcuts.cpp:\n   96      CV_Assert(f);\n   97  \n   98:     if (image.size() != mask.size() || mask.type() != CV_8UC1)\n   99:         mask.create(image.size(), CV_8UC1);\n  100  \n  101      cudaStream_t stream = StreamAccessor::getStream(s);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudalegacy\\test\\NCVTestSourceProvider.hpp:\n  110          this->dataHeight = image.rows;\n  111  \n  112:         cv::Mat hdr(image.size(), CV_8UC1, data.get()->ptr(), data.get()->pitch());\n  113          image.copyTo(hdr);\n  114  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudalegacy\\test\\test_labeling.cpp:\n  175      cv::threshold(image, image, 150, 255, cv::THRESH_BINARY);\n  176  \n  177:     ASSERT_TRUE(image.type() == CV_8UC1);\n  178  \n  179      GreedyLabeling host(image);\n  ...\n  181  \n  182      cv::cuda::GpuMat mask;\n  183:     mask.create(image.rows, image.cols, CV_8UC1);\n  184  \n  185      cv::cuda::GpuMat components;\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaobjdetect\\include\\opencv2\\cudaobjdetect.hpp:\n  160      /** @brief Performs object detection without a multi-scale window.\n  161  \n  162:     @param img Source image. CV_8UC1 and CV_8UC4 types are supported for now.\n  163      @param found_locations Left-top corner points of detected objects boundaries.\n  164      @param confidences Optional output array for confidences.\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaobjdetect\\src\\cascadeclassifier.cpp:\n  763  \n  764          // copy data structures on gpu\n  765:         stage_mat.upload(cv::Mat(1, (int) (stages.size() * sizeof(Stage)), CV_8UC1, (uchar*)&(stages[0]) ));\n  766          trees_mat.upload(cv::Mat(cl_trees).reshape(1,1));\n  767          nodes_mat.upload(cv::Mat(cl_nodes).reshape(1,1));\n  ...\n  780          if (resuzeBuffer.empty() || frame.width > resuzeBuffer.cols || frame.height > resuzeBuffer.rows)\n  781          {\n  782:             resuzeBuffer.create(frame, CV_8UC1);\n  783  \n  784              integral.create(frame.height + 1, integralFactor * (frame.width + 1), CV_32SC1);\n  ...\n  794              Ncv32u bufSize;\n  795              ncvSafeCall( nppiStIntegralGetSize_8u32u(roiSize, &bufSize, prop) );\n  796:             integralBuffer.create(1, bufSize, CV_8UC1);\n  797          #endif\n  798  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaobjdetect\\src\\hog.cpp:\n  332          const GpuMat img = _img.getGpuMat();\n  333  \n  334:         CV_Assert( img.type() == CV_8UC1 || img.type() == CV_8UC4 );\n  335          CV_Assert( win_stride_.width % block_stride_.width == 0 && win_stride_.height % block_stride_.height == 0 );\n  336  \n  ...\n  348          if (confidences == NULL)\n  349          {\n  350:             GpuMat labels = pool.getBuffer(1, wins_per_img.area(), CV_8UC1);\n  351  \n  352              hog::classify_hists(win_size_.height, win_size_.width,\n  ...\n  413          const GpuMat img = _img.getGpuMat();\n  414  \n  415:         CV_Assert( img.type() == CV_8UC1 || img.type() == CV_8UC4 );\n  416          CV_Assert( confidences == NULL || group_threshold_ == 0 );\n  417  \n  ...\n  457                  switch (img.type())\n  458                  {\n  459:                     case CV_8UC1: hog::resize_8UC1(img, smaller_img); break;\n  460                      case CV_8UC4: hog::resize_8UC4(img, smaller_img); break;\n  461                  }\n  ...\n  488          const GpuMat img = _img.getGpuMat();\n  489  \n  490:         CV_Assert( img.type() == CV_8UC1 || img.type() == CV_8UC4 );\n  491          CV_Assert( win_stride_.width % block_stride_.width == 0 && win_stride_.height % block_stride_.height == 0 );\n  492  \n  ...\n  551          switch (img.type())\n  552          {\n  553:             case CV_8UC1:\n  554                  hog::compute_gradients_8UC1(nbins_,\n  555                                              img.rows, img.cols, img,\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaoptflow\\src\\brox.cpp:\n  176  \n  177          size_t bufSize = getBufSize(desc, frame0Mat, frame1Mat, uMat, vMat, textureAlignment);\n  178:         GpuMat buf = pool.getBuffer(1, static_cast<int>(bufSize), CV_8UC1);\n  179  \n  180          NCVMemStackAllocator gpuAllocator(NCVMemoryTypeDevice, bufSize, static_cast<Ncv32u>(textureAlignment), buf.ptr());\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaoptflow\\src\\pyrlk.cpp:\n  169  \n  170  \n  171:         ensureSizeIsEnough(1, prevPts.cols, CV_8UC1, status);\n  172          status.setTo(Scalar::all(1), stream);\n  173  \n  ...\n  238      void PyrLKOpticalFlowBase::dense(const GpuMat& prevImg, const GpuMat& nextImg, GpuMat& u, GpuMat& v, Stream& stream)\n  239      {\n  240:         CV_Assert( prevImg.type() == CV_8UC1 );\n  241          CV_Assert( prevImg.size() == nextImg.size() && prevImg.type() == nextImg.type() );\n  242          CV_Assert( maxLevel_ >= 0 );\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaoptflow\\src\\tvl1flow.cpp:\n  180      void OpticalFlowDual_TVL1_Impl::calcImpl(const GpuMat& I0, const GpuMat& I1, GpuMat& flowx, GpuMat& flowy, Stream& stream)\n  181      {\n  182:         CV_Assert( I0.type() == CV_8UC1 || I0.type() == CV_32FC1 );\n  183          CV_Assert( I0.size() == I1.size() );\n  184          CV_Assert( I0.type() == I1.type() );\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudaoptflow\\test\\test_optflow.cpp:\n  235  \n  236      std::vector<unsigned char> status(d_status.cols);\n  237:     cv::Mat status_mat(1, d_status.cols, CV_8UC1, (void*)&status[0]);\n  238      d_status.download(status_mat);\n  239  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudastereo\\include\\opencv2\\cudastereo.hpp:\n  254      /** @brief Refines a disparity map using joint bilateral filtering.\n  255  \n  256:     @param disparity Input disparity map. CV_8UC1 and CV_16SC1 types are supported.\n  257:     @param image Input image. CV_8UC1 and CV_8UC3 types are supported.\n  258      @param dst Destination disparity map. It has the same size and type as disparity .\n  259      @param stream Stream for the asynchronous version.\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudastereo\\src\\disparity_bilateral_filter.cpp:\n  182  \n  183          CV_Assert( disp.type() == CV_8U || disp.type() == CV_16S );\n  184:         CV_Assert( img.type() == CV_8UC1 || img.type() == CV_8UC3 );\n  185          CV_Assert( disp.size() == img.size() );\n  186  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudastereo\\src\\stereobm.cpp:\n  146          GpuMat right = _right.getGpuMat();\n  147  \n  148:         CV_Assert( left.type() == CV_8UC1 );\n  149          CV_Assert( left.size() == right.size() && left.type() == right.type() );\n  150  \n  151:         _disparity.create(left.size(), CV_8UC1);\n  152          GpuMat disparity = _disparity.getGpuMat();\n  153  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudastereo\\src\\stereobp.cpp:\n  183          GpuMat right = _right.getGpuMat();\n  184  \n  185:         CV_Assert( left.type() == CV_8UC1 || left.type() == CV_8UC3 || left.type() == CV_8UC4 );\n  186          CV_Assert( left.size() == right.size() && left.type() == right.type() );\n  187  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudastereo\\src\\stereocsbp.cpp:\n  158          GpuMat right = _right.getGpuMat();\n  159  \n  160:         CV_Assert( left.type() == CV_8UC1 || left.type() == CV_8UC3 || left.type() == CV_8UC4 );\n  161          CV_Assert( left.size() == right.size() && left.type() == right.type() );\n  162  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudawarping\\test\\test_pyramids.cpp:\n   84      ALL_DEVICES,\n   85      DIFFERENT_SIZES,\n   86:     testing::Values(MatType(CV_8UC1), MatType(CV_8UC3), MatType(CV_8UC4), MatType(CV_16UC1), MatType(CV_16UC3), MatType(CV_16UC4), MatType(CV_32FC1), MatType(CV_32FC3), MatType(CV_32FC4)),\n   87      WHOLE_SUBMAT));\n   88  \n   ..\n  124      ALL_DEVICES,\n  125      DIFFERENT_SIZES,\n  126:     testing::Values(MatType(CV_8UC1), MatType(CV_8UC3), MatType(CV_8UC4), MatType(CV_16UC1), MatType(CV_16UC3), MatType(CV_16UC4), MatType(CV_32FC1), MatType(CV_32FC3), MatType(CV_32FC4)),\n  127      WHOLE_SUBMAT));\n  128  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudawarping\\test\\test_remap.cpp:\n  173      ALL_DEVICES,\n  174      DIFFERENT_SIZES,\n  175:     testing::Values(MatType(CV_8UC1), MatType(CV_8UC3), MatType(CV_8UC4), MatType(CV_32FC1), MatType(CV_32FC3), MatType(CV_32FC4)),\n  176      testing::Values(Interpolation(cv::INTER_NEAREST), Interpolation(cv::INTER_LINEAR), Interpolation(cv::INTER_CUBIC)),\n  177      testing::Values(BorderType(cv::BORDER_REFLECT101), BorderType(cv::BORDER_REPLICATE), BorderType(cv::BORDER_CONSTANT), BorderType(cv::BORDER_REFLECT), BorderType(cv::BORDER_WRAP)),\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudawarping\\test\\test_resize.cpp:\n  156      ALL_DEVICES,\n  157      DIFFERENT_SIZES,\n  158:     testing::Values(MatType(CV_8UC1), MatType(CV_8UC3), MatType(CV_8UC4), MatType(CV_16UC1), MatType(CV_16UC3), MatType(CV_16UC4), MatType(CV_32FC1), MatType(CV_32FC3), MatType(CV_32FC4)),\n  159      testing::Values(0.3, 0.5, 1.5, 2.0),\n  160      testing::Values(Interpolation(cv::INTER_NEAREST), Interpolation(cv::INTER_LINEAR), Interpolation(cv::INTER_CUBIC)),\n  ...\n  202      ALL_DEVICES,\n  203      DIFFERENT_SIZES,\n  204:     testing::Values(MatType(CV_8UC1), MatType(CV_8UC3), MatType(CV_8UC4), MatType(CV_16UC1), MatType(CV_16UC3), MatType(CV_16UC4), MatType(CV_32FC1), MatType(CV_32FC3), MatType(CV_32FC4)),\n  205      testing::Values(0.3, 0.5),\n  206      testing::Values(Interpolation(cv::INTER_NEAREST), Interpolation(cv::INTER_AREA)),\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudawarping\\test\\test_warp_affine.cpp:\n   82  {\n   83      cv::Mat M = createTransfomMatrix(size, CV_PI / 4);\n   84:     cv::Mat src = randomMat(randomSize(200, 400), CV_8UC1);\n   85  \n   86      cv::cuda::GpuMat xmap, ymap;\n   ..\n  226      ALL_DEVICES,\n  227      DIFFERENT_SIZES,\n  228:     testing::Values(MatType(CV_8UC1), MatType(CV_8UC3), MatType(CV_8UC4), MatType(CV_16UC1), MatType(CV_16UC3), MatType(CV_16UC4), MatType(CV_32FC1), MatType(CV_32FC3), MatType(CV_32FC4)),\n  229      DIRECT_INVERSE,\n  230      testing::Values(Interpolation(cv::INTER_NEAREST), Interpolation(cv::INTER_LINEAR), Interpolation(cv::INTER_CUBIC)),\n  ...\n  274  INSTANTIATE_TEST_CASE_P(CUDA_Warping, WarpAffineNPP, testing::Combine(\n  275      ALL_DEVICES,\n  276:     testing::Values(MatType(CV_8UC1), MatType(CV_8UC3), MatType(CV_8UC4), MatType(CV_32FC1), MatType(CV_32FC3), MatType(CV_32FC4)),\n  277      DIRECT_INVERSE,\n  278      testing::Values(Interpolation(cv::INTER_NEAREST), Interpolation(cv::INTER_LINEAR), Interpolation(cv::INTER_CUBIC))));\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\cudawarping\\test\\test_warp_perspective.cpp:\n   87      cv::cuda::buildWarpPerspectiveMaps(M, inverse, size, xmap, ymap);\n   88  \n   89:     cv::Mat src = randomMat(randomSize(200, 400), CV_8UC1);\n   90      int interpolation = cv::INTER_NEAREST;\n   91      int borderMode = cv::BORDER_CONSTANT;\n   ..\n  229      ALL_DEVICES,\n  230      DIFFERENT_SIZES,\n  231:     testing::Values(MatType(CV_8UC1), MatType(CV_8UC3), MatType(CV_8UC4), MatType(CV_16UC1), MatType(CV_16UC3), MatType(CV_16UC4), MatType(CV_32FC1), MatType(CV_32FC3), MatType(CV_32FC4)),\n  232      DIRECT_INVERSE,\n  233      testing::Values(Interpolation(cv::INTER_NEAREST), Interpolation(cv::INTER_LINEAR), Interpolation(cv::INTER_CUBIC)),\n  ...\n  277  INSTANTIATE_TEST_CASE_P(CUDA_Warping, WarpPerspectiveNPP, testing::Combine(\n  278      ALL_DEVICES,\n  279:     testing::Values(MatType(CV_8UC1), MatType(CV_8UC3), MatType(CV_8UC4), MatType(CV_32FC1), MatType(CV_32FC3), MatType(CV_32FC4)),\n  280      DIRECT_INVERSE,\n  281      testing::Values(Interpolation(cv::INTER_NEAREST), Interpolation(cv::INTER_LINEAR), Interpolation(cv::INTER_CUBIC))));\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\features2d\\src\\blobdetector.cpp:\n  317          grayscaleImage = image.getMat();\n  318  \n  319:     if (grayscaleImage.type() != CV_8UC1) {\n  320          CV_Error(Error::StsUnsupportedFormat, \"Blob detector only supports 8-bit images!\");\n  321      }\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\features2d\\src\\brisk.cpp:\n  653  {\n  654    Mat image = _image.getMat(), mask = _mask.getMat();\n  655:   if( image.type() != CV_8UC1 )\n  656        cvtColor(image, image, COLOR_BGR2GRAY);\n  657  \n  ...\n  835  {\n  836    Mat image = _image.getMat(), mask = _mask.getMat();\n  837:   if( image.type() != CV_8UC1 )\n  838        cvtColor(_image, image, COLOR_BGR2GRAY);\n  839  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\features2d\\src\\draw.cpp:\n  100              image.copyTo( outImage );\n  101          }\n  102:         else if( image.type() == CV_8UC1 )\n  103          {\n  104              cvtColor( image, outImage, COLOR_GRAY2BGR );\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\features2d\\src\\evaluation.cpp:\n  424          overlapThreshold = 1.f - 0.5f;\n  425  \n  426:         thresholdedOverlapMask->create( (int)keypoints1.size(), (int)keypoints2t.size(), CV_8UC1 );\n  427          thresholdedOverlapMask->setTo( Scalar::all(0) );\n  428      }\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\features2d\\src\\fast.cpp:\n  368  \n  369      Mat imgMat = _img.getMat();\n  370:     if(imgMat.empty() || imgMat.type() != CV_8UC1)\n  371          return false;\n  372  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\features2d\\src\\kaze\\AKAZEFeatures.cpp:\n  733        Mat &kpts = (*keypoints_by_layers_)[i];\n  734        // this mask will hold positions of keypoints in this level\n  735:       kpts = Mat::zeros(e.Ldet.size(), CV_8UC1);\n  736  \n  737        // if border is too big we shouldn't search any keypoints\n  ...\n 1202            : options_.descriptor_size; // the random bit selection length binary descriptor\n 1203      descriptor_size = divUp(descriptor_bits, 8);\n 1204:     descriptor_type = CV_8UC1;\n 1205    }\n 1206    descriptors.create((int)kpts.size(), descriptor_size, descriptor_type);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\features2d\\src\\matchers.cpp:\n  622                  int rows = trainDescCollection[i].empty() ? utrainDescCollection[i].rows : trainDescCollection[i].rows;\n  623                      CV_Assert( masks[i].rows == queryDescriptorsCount &&\n  624:                         masks[i].cols == rows && masks[i].type() == CV_8UC1);\n  625              }\n  626          }\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\features2d\\src\\orb.cpp:\n  132                  std::vector<KeyPoint>& pts, int blockSize, float harris_k)\n  133  {\n  134:     CV_Assert( img.type() == CV_8UC1 && blockSize*blockSize <= 2048 );\n  135  \n  136      size_t ptidx, ptsize = pts.size();\n  ...\n  978  \n  979      Mat image = _image.getMat(), mask = _mask.getMat();\n  980:     if( image.type() != CV_8UC1 )\n  981          cvtColor(_image, image, COLOR_BGR2GRAY);\n  982  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\features2d\\test\\test_descriptors_invariance.cpp:\n   67      Mat image1, mask1;\n   68      const int borderSize = 16;\n   69:     Mat mask0(image0.size(), CV_8UC1, Scalar(0));\n   70      mask0(Rect(borderSize, borderSize, mask0.cols - 2*borderSize, mask0.rows - 2*borderSize)).setTo(Scalar(255));\n   71  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\features2d\\test\\test_detectors_invariance.cpp:\n   87      Mat image1, mask1;\n   88      const int borderSize = 16;\n   89:     Mat mask0(image0.size(), CV_8UC1, Scalar(0));\n   90      mask0(Rect(borderSize, borderSize, mask0.cols - 2*borderSize, mask0.rows - 2*borderSize)).setTo(Scalar(255));\n   91  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\features2d\\test\\test_matchers_algorithmic.cpp:\n  259          for(int mi = 0; mi < 2; mi++ )\n  260          {\n  261:             masks[mi] = Mat(query.rows, train.rows/2, CV_8UC1, Scalar::all(1));\n  262              for( int di = 0; di < queryDescCount/2; di++ )\n  263                  masks[mi].col(di*countFactor).setTo(Scalar::all(0));\n  ...\n  356          for(int mi = 0; mi < 2; mi++ )\n  357          {\n  358:             masks[mi] = Mat(query.rows, train.rows/2, CV_8UC1, Scalar::all(1));\n  359              for( int di = 0; di < queryDescCount/2; di++ )\n  360                  masks[mi].col(di*countFactor).setTo(Scalar::all(0));\n  ...\n  459          for(int mi = 0; mi < 2; mi++ )\n  460          {\n  461:             masks[mi] = Mat(query.rows, train.rows/2, CV_8UC1, Scalar::all(1));\n  462              for( int di = 0; di < queryDescCount/2; di++ )\n  463                  masks[mi].col(di*countFactor).setTo(Scalar::all(0));\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\features2d\\test\\test_orb.cpp:\n   53      ASSERT_FALSE(image.empty());\n   54  \n   55:     Mat roi(image.size(), CV_8UC1, Scalar(0));\n   56  \n   57      Point poly[] = {Point(100, 20), Point(300, 50), Point(400, 200), Point(10, 500)};\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\flann\\test\\test_lshtable_badarg.cpp:\n   69      Caller caller;\n   70      Size featuresSize = cvtest::randomSize(rng, 10.0);\n   71:     caller.features = cvtest::randomMat(rng, featuresSize, CV_8UC1, 0, 255, false);\n   72      caller.table_number = 12;\n   73      caller.multi_probe_level = 2;\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\highgui\\src\\window_QT.cpp:\n 2946  }\n 2947  \n 2948: //only if CV_8UC1 or CV_8UC3\n 2949  void DefaultViewPort::drawStatusBar()\n 2950  {\n 2951:     if (nbChannelOriginImage!=CV_8UC1 && nbChannelOriginImage!=CV_8UC3)\n 2952          return;\n 2953  \n ....\n 2971          }\n 2972  \n 2973:         if (nbChannelOriginImage==CV_8UC1)\n 2974          {\n 2975              //all the channel have the same value (because of cvconvertimage), so only the r channel is dsplayed\n ....\n 2983  }\n 2984  \n 2985: //accept only CV_8UC1 and CV_8UC8 image for now\n 2986  void DefaultViewPort::drawImgRegion(QPainter *painter)\n 2987  {\n 2988:     if (nbChannelOriginImage!=CV_8UC1 && nbChannelOriginImage!=CV_8UC3)\n 2989          return;\n 2990  \n ....\n 3062              }\n 3063  \n 3064:             if (nbChannelOriginImage==CV_8UC1)\n 3065              {\n 3066                  QString val = tr(\"%1\").arg(qRed(rgbValue));\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgcodecs\\src\\grfmt_bmp.cpp:\n  178      }\n  179      // in 32 bit case alpha channel is used - so require CV_8UC4 type\n  180:     m_type = iscolor ? (m_bpp == 32 ? CV_8UC4 : CV_8UC3 ) : CV_8UC1;\n  181      m_origin = m_height > 0 ? IPL_ORIGIN_BL : IPL_ORIGIN_TL;\n  182      m_height = std::abs(m_height);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgcodecs\\src\\grfmt_gdal.cpp:\n   68          /// GRAYSCALE\n   69          case GPI_Gray:\n   70:             if( gdalType == GDT_Byte    ){ return CV_8UC1;  }\n   71              if( gdalType == GDT_UInt16  ){ return CV_16UC1; }\n   72              if( gdalType == GDT_Int16   ){ return CV_16SC1; }\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgcodecs\\src\\grfmt_gdcm.cpp:\n  109              {\n  110                  case gdcm::PixelFormat::INT8: m_type = CV_8SC1; break;\n  111:                 case gdcm::PixelFormat::UINT8: m_type = CV_8UC1; break;\n  112                  case gdcm::PixelFormat::INT16: m_type = CV_16SC1; break;\n  113                  case gdcm::PixelFormat::UINT16: m_type = CV_16UC1; break;\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgcodecs\\src\\grfmt_jpeg.cpp:\n  249              m_width = state->cinfo.output_width;\n  250              m_height = state->cinfo.output_height;\n  251:             m_type = state->cinfo.num_components > 1 ? CV_8UC3 : CV_8UC1;\n  252              result = true;\n  253          }\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgcodecs\\src\\grfmt_png.cpp:\n  204                                  break;\n  205                              default:\n  206:                                 m_type = CV_8UC1;\n  207                          }\n  208                          if( bit_depth == 16 )\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgcodecs\\src\\grfmt_pxm.cpp:\n  165  \n  166          m_binary = code >= '4';\n  167:         m_type = m_bpp > 8 ? CV_8UC3 : CV_8UC1;\n  168  \n  169          m_width = ReadNumber(m_strm);\n  ...\n  419          int t = CV_MAKETYPE(img.depth(), channels);\n  420          m_buf->reserve( alignSize(256 + (isBinary ? fileStep*height :\n  421:             ((t == CV_8UC1 ? 4 : t == CV_8UC3 ? 4*3+2 :\n  422              t == CV_16UC1 ? 6 : 6*3+2)*width+1)*height), 256));\n  423      }\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgcodecs\\src\\grfmt_sunras.cpp:\n  122                      }\n  123  \n  124:                     m_type = IsColorPalette( m_palette, m_bpp ) ? CV_8UC3 : CV_8UC1;\n  125                      m_offset = m_strm.getPos();\n  126  \n  ...\n  131              else\n  132              {\n  133:                 m_type = m_bpp > 8 ? CV_8UC3 : CV_8UC1;\n  134  \n  135                  if( CV_MAT_CN(m_type) == 1 )\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgcodecs\\src\\grfmt_webp.cpp:\n  164      if( m_width > 0 && m_height > 0 )\n  165      {\n  166:         bool convert_grayscale = (img.type() == CV_8UC1); // IMREAD_GRAYSCALE requested\n  167  \n  168          if (img.cols != m_width || img.rows != m_height || img.type() != m_type)\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgcodecs\\test\\test_tiff.cpp:\n   21  {\n   22      // see issue #2161\n   23:     cv::Mat big(16384, 16384, CV_8UC1, cv::Scalar::all(0));\n   24      string file3 = cv::tempfile(\".tiff\");\n   25      string file4 = cv::tempfile(\".tiff\");\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\include\\opencv2\\imgproc.hpp:\n  247                          //!< \\f[\\texttt{dst} = \\mathrm{blackhat} ( \\texttt{src} , \\texttt{element} )= \\mathrm{close} ( \\texttt{src} , \\texttt{element} )- \\texttt{src}\\f]\n  248      MORPH_HITMISS  = 7  //!< \"hit or miss\"\n  249:                         //!<   .- Only supported for CV_8UC1 binary images. A tutorial can be found in the documentation\n  250  };\n  251  \n  ...\n 1210      ![image](pics/building_lsd.png)\n 1211  \n 1212:     @param _image A grayscale (CV_8UC1) input image. If only a roi needs to be selected, use:\n 1213      `lsd_ptr-\\>detect(image(roi), lines, ...); lines += Scalar(roi.x, roi.y, roi.x, roi.y);`\n 1214      @param _lines A vector of Vec4i or Vec4f elements specifying the beginning and ending point of a line. Where\n ....\n 1906  @param minDistance Minimum possible Euclidean distance between the returned corners.\n 1907  @param mask Optional region of interest. If the image is not empty (it needs to have the type\n 1908: CV_8UC1 and the same size as image ), it specifies the region in which the corners are detected.\n 1909  @param blockSize Size of an average block for computing a derivative covariation matrix over each\n 1910  pixel neighborhood. See cornerEigenValsAndVecs .\n ....\n 4266  /** @brief Applies a GNU Octave/MATLAB equivalent colormap on a given image.\n 4267  \n 4268: @param src The source image, grayscale or colored of type CV_8UC1 or CV_8UC3.\n 4269  @param dst The result is the colormapped source image. Note: Mat::create is called on dst.\n 4270  @param colormap The colormap to apply, see cv::ColormapTypes\n ....\n 4274  /** @brief Applies a user colormap on a given image.\n 4275  \n 4276: @param src The source image, grayscale or colored of type CV_8UC1 or CV_8UC3.\n 4277  @param dst The result is the colormapped source image. Note: Mat::create is called on dst.\n 4278: @param userColor The colormap to apply of type CV_8UC1 or CV_8UC3 and size 256\n 4279  */\n 4280  CV_EXPORTS_W void applyColorMap(InputArray src, OutputArray dst, InputArray userColor);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\perf\\opencl\\perf_filters.cpp:\n   84  \n   85  OCL_PERF_TEST_P(SqrBoxFilterFixture, SqrBoxFilter,\n   86:                 ::testing::Combine(OCL_TEST_SIZES, OCL_PERF_ENUM(CV_8UC1, CV_8UC4, CV_32FC1, CV_32FC4),\n   87                                     OCL_PERF_ENUM(Size(3, 3), Size(20, 3), Size(3, 20), Size(20, 20))))\n   88  {\n   ..\n  293      const double sigmacolor = 50.0, sigmaspace = 50.0;\n  294  \n  295:     checkDeviceMaxMemoryAllocSize(srcSize, CV_8UC1);\n  296  \n  297:     UMat src(srcSize, CV_8UC1), dst(srcSize, CV_8UC1);\n  298      declare.in(src, WARMUP_RNG).out(dst);\n  299  \n  ...\n  314      const int ksize = get<1>(params);\n  315  \n  316:     checkDeviceMaxMemoryAllocSize(srcSize, CV_8UC1);\n  317  \n  318:     UMat src(srcSize, CV_8UC1), dst(srcSize, CV_8UC1);\n  319      declare.in(src, WARMUP_RNG).out(dst);\n  320  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\perf\\opencl\\perf_houghLines.cpp:\n   37      int threshold = 250;\n   38  \n   39:     UMat usrc(srcSize, CV_8UC1), lines(1, 1, CV_32FC2);\n   40:     Mat src(srcSize, CV_8UC1);\n   41      src.setTo(Scalar::all(0));\n   42      line(src, Point(0, 100), Point(src.cols, 100), Scalar::all(255), 1);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\perf\\opencl\\perf_imgproc.cpp:\n   60      const double eps = 1;\n   61  \n   62:     checkDeviceMaxMemoryAllocSize(srcSize, CV_8UC1);\n   63  \n   64:     UMat src(srcSize, CV_8UC1), dst(srcSize, CV_8UC1);\n   65      declare.in(src, WARMUP_RNG).out(dst);\n   66  \n   ..\n   84      ranges[1] = 256;\n   85  \n   86:     checkDeviceMaxMemoryAllocSize(srcSize, CV_8UC1);\n   87  \n   88:     UMat src(srcSize, CV_8UC1), hist(256, 1, CV_32FC1);\n   89      declare.in(src, WARMUP_RNG).out(hist);\n   90  \n   ..\n  108      ranges[1] = 256;\n  109  \n  110:     checkDeviceMaxMemoryAllocSize(srcSize, CV_8UC1);\n  111  \n  112:     UMat src(srcSize, CV_8UC1), hist(256, 1, CV_32FC1), dst(srcSize, CV_8UC1);\n  113      declare.in(src, WARMUP_RNG).out(hist);\n  114  \n  ...\n  153  \n  154  OCL_PERF_TEST_P(CornerMinEigenValFixture, CornerMinEigenVal,\n  155:             ::testing::Combine(OCL_TEST_SIZES, OCL_PERF_ENUM(CV_8UC1, CV_32FC1)))\n  156  {\n  157      const Size_MatType_t params = GetParam();\n  ...\n  175  \n  176  OCL_PERF_TEST_P(CornerHarrisFixture, CornerHarris,\n  177:             ::testing::Combine(OCL_TEST_SIZES, OCL_PERF_ENUM(CV_8UC1, CV_32FC1)))\n  178  {\n  179      const Size_MatType_t params = GetParam();\n  ...\n  196  \n  197  OCL_PERF_TEST_P(PreCornerDetectFixture, PreCornerDetect,\n  198:             ::testing::Combine(OCL_TEST_SIZES, OCL_PERF_ENUM(CV_8UC1, CV_32FC1)))\n  199  {\n  200      const Size_MatType_t params = GetParam();\n  ...\n  225      checkDeviceMaxMemoryAllocSize(srcSize, ddepth);\n  226  \n  227:     UMat src(srcSize, CV_8UC1), dst(srcSize + Size(1, 1), ddepth);\n  228      declare.in(src, WARMUP_RNG).out(dst);\n  229  \n  ...\n  241      checkDeviceMaxMemoryAllocSize(srcSize, ddepth);\n  242  \n  243:     UMat src(srcSize, CV_8UC1), sum(srcSize + Size(1, 1), ddepth), sqsum(srcSize + Size(1, 1), CV_32F);\n  244      declare.in(src, WARMUP_RNG).out(sum, sqsum);\n  245  \n  ...\n  284      const Size srcSize = GetParam();\n  285  \n  286:     checkDeviceMaxMemoryAllocSize(srcSize, CV_8UC1);\n  287  \n  288:     UMat src(srcSize, CV_8UC1), dst(srcSize, CV_8UC1);\n  289      const double clipLimit = 40.0;\n  290      declare.in(src, WARMUP_RNG).out(dst);\n  ...\n  313      UMat img;\n  314      cv::resize(_img, img, imgSize);\n  315:     UMat edges(img.size(), CV_8UC1);\n  316  \n  317      declare.in(img).out(edges);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\perf\\opencl\\perf_matchTemplate.cpp:\n   18              testing::Values(cv::Size(11, 11), cv::Size(16, 16), cv::Size(41, 41)),\n   19              MethodType::all(),\n   20:             testing::Values(CV_8UC1, CV_8UC3, CV_32FC1, CV_32FC3)\n   21              )\n   22          )\n   ..\n   74      const Size srcSize = GetParam(), templSize(5, 5);\n   75  \n   76:     UMat src(srcSize, CV_8UC1), templ(templSize, CV_8UC1);\n   77      const Size dstSize(src.cols - templ.cols + 1, src.rows - templ.rows + 1);\n   78:     UMat dst(dstSize, CV_8UC1);\n   79  \n   80      declare.in(src, templ, WARMUP_RNG).out(dst);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\perf\\opencl\\perf_moments.cpp:\n   66  \n   67      cv::Moments m;\n   68:     UMat src(srcSize, CV_8UC1);\n   69      declare.in(src, WARMUP_RNG);\n   70  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\perf\\perf_accumulate.cpp:\n   25      int dstType = get<1>(GetParam());\n   26  \n   27:     Mat src(sz, CV_8UC1);\n   28      Mat dst(sz, dstType);\n   29  \n   ..\n   55      int dstType = get<1>(GetParam());\n   56  \n   57:     Mat src(sz, CV_8UC1);\n   58      Mat dst(sz, dstType);\n   59  \n   ..\n   70      testing::Combine(\n   71          testing::Values(::perf::szODD, ::perf::szQVGA, ::perf::szVGA, ::perf::sz1080p),\n   72:         testing::Values(CV_8UC1, CV_32FC1)\n   73      )\n   74  )\n   ..\n   85      int dstType = get<1>(GetParam());\n   86  \n   87:     Mat src(sz, CV_8UC1);\n   88      Mat dst(sz, dstType);\n   89  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\perf\\perf_bilateral.cpp:\n    8  using std::tr1::get;\n    9  \n   10: CV_ENUM(Mat_Type, CV_8UC1, CV_8UC3, CV_32FC1, CV_32FC3)\n   11  \n   12  typedef TestBaseWithParam< tr1::tuple<Size, int, Mat_Type> > TestBilateralFilter;\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\perf\\perf_blur.cpp:\n   13              testing::Combine(\n   14                  testing::Values(szODD, szQVGA, szVGA, sz720p),\n   15:                 testing::Values(CV_8UC1, CV_8UC4, CV_16UC1, CV_16SC1, CV_32FC1),\n   16                  testing::Values(3, 5)\n   17                  )\n   ..\n   47              testing::Combine(\n   48                  testing::Values(szODD, szQVGA, szVGA, sz720p),\n   49:                 testing::Values(CV_8UC1, CV_8UC4, CV_16UC1, CV_16SC1, CV_32FC1),\n   50                  BorderType3x3::all()\n   51                  )\n   ..\n   69              testing::Combine(\n   70                  testing::Values(szODD, szQVGA, szVGA, sz720p),\n   71:                 testing::Values(CV_8UC1, CV_8UC4, CV_16UC1, CV_16SC1, CV_32FC1),\n   72                  BorderType3x3::all()\n   73                  )\n   ..\n   91              testing::Combine(\n   92                  testing::Values(szVGA, sz720p),\n   93:                 testing::Values(CV_8UC1, CV_8UC4, CV_16UC1, CV_16SC1, CV_32FC1),\n   94                  BorderType::all()\n   95                  )\n   ..\n  116              testing::Combine(\n  117                  testing::Values(szODD, szQVGA, szVGA, sz720p),\n  118:                 testing::Values(CV_8UC1, CV_16SC1, CV_32SC1, CV_32FC1, CV_32FC3),\n  119                  BorderType3x3::all()\n  120                  )\n  ...\n  138              testing::Combine(\n  139                  testing::Values(szODD, szQVGA, szVGA, sz720p),\n  140:                 testing::Values(CV_8UC1, CV_16SC1, CV_32SC1, CV_32FC1, CV_32FC3),\n  141                  BorderType3x3::all()\n  142                  )\n  ...\n  166              testing::Combine(\n  167                  testing::Values(szODD, szQVGA, szVGA, sz720p),\n  168:                 testing::Values(CV_8UC1, CV_8UC4, CV_16UC1, CV_16SC1, CV_32FC1),\n  169                  BorderType::all()\n  170                  )\n  ...\n  188              testing::Combine(\n  189                  testing::Values(szVGA, sz720p),\n  190:                 testing::Values(CV_8UC1, CV_8UC4, CV_16UC1, CV_16SC1, CV_32FC1, CV_32FC3),\n  191                  BorderType::all()\n  192                  )\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\perf\\perf_cvt_color.cpp:\n  368      int mode = get<1>(GetParam());\n  369  \n  370:     Mat src(sz, CV_8UC1);\n  371      Mat dst(sz, CV_8UC3);\n  372  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\perf\\perf_distanceTransform.cpp:\n   11  {\n   12      Size size = GetParam();\n   13:     Mat src(size, CV_8UC1);\n   14      Mat dst(size, CV_32FC1);\n   15      CvMat srcStub = src;\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\perf\\perf_filter2d.cpp:\n   57      borderMode = get<2>(GetParam());\n   58  \n   59:     Mat src(sz, CV_8UC1);\n   60      Mat dst(sz, CV_16SC1);\n   61  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\perf\\perf_histogram.cpp:\n  130      const double clipLimit = get<1>(GetParam());\n  131  \n  132:     Mat src(size, CV_8UC1);\n  133      declare.in(src, WARMUP_RNG);\n  134  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\perf\\perf_integral.cpp:\n   13              testing::Combine(\n   14                  testing::Values(TYPICAL_MAT_SIZES),\n   15:                 testing::Values(CV_8UC1, CV_8UC4),\n   16                  testing::Values(CV_32S, CV_32F, CV_64F)\n   17                  )\n   ..\n   35              testing::Combine(\n   36                  testing::Values(::perf::szVGA, ::perf::sz1080p),\n   37:                 testing::Values(CV_8UC1, CV_8UC4),\n   38                  testing::Values(CV_32S, CV_32F)\n   39                  )\n   ..\n   60               testing::Combine(\n   61                   testing::Values( ::perf::szVGA, ::perf::szODD , ::perf::sz1080p ),\n   62:                  testing::Values( CV_8UC1, CV_8UC4 ),\n   63                   testing::Values( CV_32S, CV_32F )\n   64                   )\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\perf\\perf_matchTemplate.cpp:\n   27      int method = get<2>(GetParam());\n   28  \n   29:     Mat img(imgSz, CV_8UC1);\n   30:     Mat tmpl(tmplSz, CV_8UC1);\n   31      Mat result(imgSz - tmplSz + Size(1,1), CV_32F);\n   32  \n   ..\n   61      int method = get<2>(GetParam());\n   62  \n   63:     Mat img(imgSz, CV_8UC1);\n   64:     Mat tmpl(tmplSz, CV_8UC1);\n   65      Mat result(imgSz - tmplSz + Size(1,1), CV_32F);\n   66  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\perf\\perf_morph.cpp:\n    7  using std::tr1::get;\n    8  \n    9: #define TYPICAL_MAT_TYPES_MORPH  CV_8UC1, CV_8UC4\n   10  #define TYPICAL_MATS_MORPH       testing::Combine(SZ_ALL_GA, testing::Values(TYPICAL_MAT_TYPES_MORPH))\n   11  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\perf\\perf_pyramids.cpp:\n    9  PERF_TEST_P(Size_MatType, pyrDown, testing::Combine(\n   10                  testing::Values(sz1080p, sz720p, szVGA, szQVGA, szODD),\n   11:                 testing::Values(CV_8UC1, CV_8UC3, CV_8UC4, CV_16SC1, CV_16SC3, CV_16SC4, CV_32FC1, CV_32FC3, CV_32FC4)\n   12                  )\n   13              )\n   ..\n   30  PERF_TEST_P(Size_MatType, pyrDown_ovx, testing::Combine(\n   31      testing::Values(sz1080p, sz720p, szVGA, szQVGA, szODD),\n   32:     testing::Values(CV_8UC1, CV_8UC3, CV_8UC4, CV_16SC1, CV_16SC3, CV_16SC4, CV_32FC1, CV_32FC3, CV_32FC4)\n   33  )\n   34  )\n   ..\n   51  PERF_TEST_P(Size_MatType, pyrUp, testing::Combine(\n   52                  testing::Values(sz720p, szVGA, szQVGA, szODD),\n   53:                 testing::Values(CV_8UC1, CV_8UC3, CV_8UC4, CV_16SC1, CV_16SC3, CV_16SC4, CV_32FC1, CV_32FC3, CV_32FC4)\n   54                  )\n   55              )\n   ..\n   72  PERF_TEST_P(Size_MatType, buildPyramid, testing::Combine(\n   73                  testing::Values(sz1080p, sz720p, szVGA, szQVGA, szODD),\n   74:                 testing::Values(CV_8UC1, CV_8UC3, CV_8UC4, CV_32FC1, CV_32FC3, CV_32FC4)\n   75                  )\n   76              )\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\perf\\perf_resize.cpp:\n   12  PERF_TEST_P(MatInfo_Size_Size, resizeUpLinear,\n   13              testing::Values(\n   14:                 MatInfo_Size_Size_t(CV_8UC1, szVGA, szqHD),\n   15:                 MatInfo_Size_Size_t(CV_8UC1, szVGA, sz720p),\n   16                  MatInfo_Size_Size_t(CV_8UC4, szVGA, sz720p)\n   17                  )\n   ..\n   37  PERF_TEST_P(MatInfo_Size_Size, resizeDownLinear,\n   38              testing::Values(\n   39:                 MatInfo_Size_Size_t(CV_8UC1, szVGA, szQVGA),\n   40                  MatInfo_Size_Size_t(CV_8UC4, szqHD, szVGA),\n   41:                 MatInfo_Size_Size_t(CV_8UC1, sz720p, Size(120 * sz720p.width / sz720p.height, 120)),//face detection min_face_size = 20%\n   42                  MatInfo_Size_Size_t(CV_8UC4, sz720p, szVGA),\n   43                  MatInfo_Size_Size_t(CV_8UC4, sz720p, szQVGA)\n   ..\n   68  PERF_TEST_P(MatInfo_Size_Scale, ResizeAreaFast,\n   69              testing::Combine(\n   70:                 testing::Values(CV_8UC1, CV_8UC3, CV_8UC4, CV_16UC1, CV_16UC3, CV_16UC4),\n   71                  testing::Values(szVGA, szqHD, sz720p, sz1080p),\n   72                  testing::Values(2)\n   ..\n   98  PERF_TEST_P(MatInfo_Size_Scale_Area, ResizeArea,\n   99              testing::Combine(\n  100:                 testing::Values(CV_8UC1, CV_8UC4),\n  101                  testing::Values(szVGA, szqHD, sz720p),\n  102                  testing::Values(2.4, 3.4, 1.3)\n  ...\n  126  PERF_TEST_P(MatInfo_Size_Scale_NN, ResizeNN,\n  127      testing::Combine(\n  128:         testing::Values(CV_8UC1, CV_8UC2, CV_8UC4),\n  129          testing::Values(szVGA, szqHD, sz720p, sz1080p, sz2160p),\n  130          testing::Values(2.4, 3.4, 1.3)\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\perf\\perf_spatialgradient.cpp:\n   23      int borderType = std::tr1::get<2>(GetParam());\n   24  \n   25:     Mat src(size, CV_8UC1);\n   26      Mat dx(size, CV_16SC1);\n   27      Mat dy(size, CV_16SC1);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\perf\\perf_threshold.cpp:\n   15              testing::Combine(\n   16                  testing::Values(TYPICAL_MAT_SIZES),\n   17:                 testing::Values(CV_8UC1, CV_16SC1, CV_32FC1, CV_64FC1),\n   18                  ThreshType::all()\n   19                  )\n   ..\n   45      Size sz = GetParam();\n   46  \n   47:     Mat src(sz, CV_8UC1);\n   48:     Mat dst(sz, CV_8UC1);\n   49  \n   50      double maxval = theRNG().uniform(1, 254);\n   ..\n   81      double C = 10.0;\n   82  \n   83:     int type = CV_8UC1;\n   84      Mat src(sz, type);\n   85      Mat dst(sz, type);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\perf\\perf_warp.cpp:\n   66      Scalar borderColor = Scalar::all(150);\n   67  \n   68:     Mat src(szSrc, CV_8UC1), dst(sz, CV_8UC1);\n   69      cvtest::fillGradient(src);\n   70      if (borderMode == BORDER_CONSTANT) cvtest::smoothBorder(src, borderColor, 1);\n   ..\n  134      Scalar borderColor = Scalar::all(150);\n  135  \n  136:     Mat src(szSrc, CV_8UC1), dst(sz, CV_8UC1);\n  137      cvtest::fillGradient(src);\n  138      if (borderMode == BORDER_CONSTANT) cvtest::smoothBorder(src, borderColor, 1);\n  ...\n  162                   InterType::all(),\n  163                   BorderMode::all(),\n  164:                  Values( CV_8UC1, CV_8UC4 )\n  165                   )\n  166               )\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\accum.cpp:\n  251          return false;\n  252      if(!_mask.empty() ||\n  253:        (opType == VX_ACCUMULATE_WEIGHTED_OP && dstMat.type() != CV_8UC1  ) ||\n  254         (opType != VX_ACCUMULATE_WEIGHTED_OP && dstMat.type() != CV_16SC1 ) ||\n  255:        srcMat.type() != CV_8UC1)\n  256      {\n  257          return false;\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\canny.cpp:\n  277          return false;\n  278  \n  279:     _dst.create(size, CV_8UC1);\n  280      UMat dst = _dst.getUMat();\n  281  \n  ...\n  313          haveSIMD = hasSIMD128();\n  314          if(haveSIMD)\n  315:             _map.create(src.rows + 2, (int)alignSize((size_t)(src.cols + CV_MALLOC_SIMD128 + 1), CV_MALLOC_SIMD128), CV_8UC1);\n  316          else\n  317  #endif\n  318:             _map.create(src.rows + 2, src.cols + 2,  CV_8UC1);\n  319          map = _map;\n  320          map.row(0).setTo(1);\n  ...\n  333          haveSIMD = hasSIMD128();\n  334          if(haveSIMD)\n  335:             _map.create(src.rows + 2, (int)alignSize((size_t)(src.cols + CV_MALLOC_SIMD128 + 1), CV_MALLOC_SIMD128), CV_8UC1);\n  336          else\n  337  #endif\n  338:             _map.create(src.rows + 2, src.cols + 2,  CV_8UC1);\n  339          map = _map;\n  340          map.row(0).setTo(1);\n  ...\n  974  \n  975      // we don't support inplace parameters in case with RGB/BGR src\n  976:     CV_Assert((_dst.getObj() != _src.getObj() || _src.type() == CV_8UC1) && \"Inplace parameters are not supported\");\n  977  \n  978      _dst.create(size, CV_8U);\n  ...\n  998      CV_OVX_RUN(\n  999          false && /* disabling due to accuracy issues */\n 1000:             src.type() == CV_8UC1 &&\n 1001              !src.isSubmatrix() &&\n 1002              src.cols >= aperture_size &&\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\clahe.cpp:\n   69  \n   70          cv::UMat src = _src.getUMat();\n   71:         _dst.create(tilesX * tilesY, 256, CV_8UC1);\n   72          cv::UMat dst = _dst.getUMat();\n   73  \n   ..\n  358          CV_INSTRUMENT_REGION()\n  359  \n  360:         CV_Assert( _src.type() == CV_8UC1 || _src.type() == CV_16UC1 );\n  361  \n  362  #ifdef HAVE_OPENCL\n  363:         bool useOpenCL = cv::ocl::useOpenCL() && _src.isUMat() && _src.dims()<=2 && _src.type() == CV_8UC1;\n  364  #endif\n  365  \n  366:         int histSize = _src.type() == CV_8UC1 ? 256 : 65536;\n  367  \n  368          cv::Size tileSize;\n  ...\n  418  \n  419          cv::Ptr<cv::ParallelLoopBody> calcLutBody;\n  420:         if (_src.type() == CV_8UC1)\n  421              calcLutBody = cv::makePtr<CLAHE_CalcLut_Body<uchar, 256, 0> >(srcForLut, lut_, tileSize, tilesX_, clipLimit, lutScale);\n  422          else if (_src.type() == CV_16UC1)\n  ...\n  428  \n  429          cv::Ptr<cv::ParallelLoopBody> interpolationBody;\n  430:         if (_src.type() == CV_8UC1)\n  431              interpolationBody = cv::makePtr<CLAHE_Interpolation_Body<uchar, 0> >(src, dst, lut_, tileSize, tilesX_, tilesY_);\n  432          else if (_src.type() == CV_16UC1)\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\color.cpp:\n 11103              CV_Assert( scn == 2 && depth == CV_8U );\n 11104              gbits = code == COLOR_BGR5652GRAY ? 6 : 5;\n 11105:             _dst.create(sz, CV_8UC1);\n 11106              dst = _dst.getMat();\n 11107              hal::cvtBGR5x5toGray(src.data, src.step, dst.data, dst.step, src.cols, src.rows, gbits);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\colormap.cpp:\n  121      switch(x.type()) {\n  122          case CV_8SC1: return interp1_<char>(x,Y,xi); break;\n  123:         case CV_8UC1: return interp1_<unsigned char>(x,Y,xi); break;\n  124          case CV_16SC1: return interp1_<short>(x,Y,xi); break;\n  125          case CV_16UC1: return interp1_<unsigned short>(x,Y,xi); break;\n  ...\n  145          // Applies the colormap on a given image.\n  146          //\n  147:         // This function expects BGR-aligned data of type CV_8UC1 or CV_8UC3.\n  148          // Throws an error for wrong-aligned lookup table, which must be\n  149          // of size 256 in the latest OpenCV release (2.3.1).\n  ...\n  514              CV_Error(Error::StsAssert, \"cv::LUT only supports tables of size 256.\");\n  515          Mat src = _src.getMat();\n  516:         if(src.type() != CV_8UC1  &&  src.type() != CV_8UC3)\n  517:             CV_Error(Error::StsBadArg, \"cv::ColorMap only supports source images of type CV_8UC1 or CV_8UC3\");\n  518          // Turn into a BGR matrix into its grayscale representation.\n  519          if(src.type() == CV_8UC3)\n  ...\n  568          if (userColor.size() != Size(1,256))\n  569              CV_Error(Error::StsAssert, \"cv::LUT only supports tables of size 256.\");\n  570:         if (userColor.type() != CV_8UC1 && userColor.type() != CV_8UC3)\n  571:             CV_Error(Error::StsAssert, \"cv::LUT only supports tables CV_8UC1 or CV_8UC3.\");\n  572          colormap::UserColorMap cm(userColor.getMat());\n  573  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\contours.cpp:\n  196            (CV_MAT_TYPE(mat->type) == CV_32SC1 && mode == CV_RETR_FLOODFILL)) )\n  197          CV_Error( CV_StsUnsupportedFormat,\n  198:                   \"[Start]FindContours supports only CV_8UC1 images when mode != CV_RETR_FLOODFILL \"\n  199                    \"otherwise supports CV_32SC1 images only\" );\n  200  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\corner.cpp:\n  267      scale = 1.0/scale;\n  268  \n  269:     CV_Assert( src.type() == CV_8UC1 || src.type() == CV_32FC1 );\n  270  \n  271      Mat Dx, Dy;\n  ...\n  409  \n  410      int type = _src.type(), depth = CV_MAT_DEPTH(type);\n  411:     if ( !(type == CV_8UC1 || type == CV_32FC1) )\n  412          return false;\n  413  \n  ...\n  522              float norm_coef = 0.f;\n  523  \n  524:             if (src.type() == CV_8UC1)\n  525              {\n  526                  getBufferSizeFunc = (ippiMinEigenValGetBufferSize) ippiMinEigenValGetBufferSize_8u32f_C1R;\n  ...\n  602          bool isolated = (borderType & BORDER_ISOLATED) != 0;\n  603  \n  604:         if ( (ksize == 3 || ksize == 5) && (type == CV_8UC1 || type == CV_32FC1) &&\n  605              (borderTypeNI == BORDER_CONSTANT || borderTypeNI == BORDER_REPLICATE) && cn == 1 && (!src.isSubmatrix() || isolated) )\n  606          {\n  607              IppiSize roisize = { src.cols, src.rows };\n  608              IppiMaskSize masksize = ksize == 5 ? ippMskSize5x5 : ippMskSize3x3;\n  609:             IppDataType datatype = type == CV_8UC1 ? ipp8u : ipp32f;\n  610              Ipp32s bufsize = 0;\n  611  \n  ...\n  663      bool isolated = (borderType & BORDER_ISOLATED) != 0;\n  664  #endif\n  665:     CV_IPP_RUN(((ksize == 3 || ksize == 5) && (_src.type() == CV_8UC1 || _src.type() == CV_32FC1) &&\n  666          (borderTypeNI == BORDER_CONSTANT || borderTypeNI == BORDER_REPLICATE) && CV_MAT_CN(_src.type()) == 1 &&\n  667          (!_src.isSubmatrix() || isolated)) && IPP_VERSION_X100 >= 810, ipp_cornerHarris( src, dst, blockSize, ksize, k, borderType ));\n  ...\n  691  \n  692      int type = _src.type();\n  693:     CV_Assert( type == CV_8UC1 || type == CV_32FC1 );\n  694  \n  695      CV_OCL_RUN( _src.dims() <= 2 && _dst.isUMat(),\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\deriv.cpp:\n  192                               double scale, double delta, int borderType)\n  193      {\n  194:         if (_src.type() != CV_8UC1 || _dst.type() != CV_16SC1 ||\n  195              ksize != 3 || scale != 1.0 || delta != 0.0 ||\n  196              (dx | dy) != 1 || (dx + dy) != 1 ||\n  ...\n  360      int type = _src.type(), sdepth = CV_MAT_DEPTH(type), cn = CV_MAT_CN(type);\n  361  \n  362:     if ( !(dev.isIntel() && (type == CV_8UC1) && (ddepth == CV_8U) &&\n  363           (_src.offset() == 0) && (_src.step() % 4 == 0) &&\n  364           (_src.cols() % 16 == 0) && (_src.rows() % 2 == 0)) )\n  ...\n  650      int type = _src.type(), sdepth = CV_MAT_DEPTH(type), cn = CV_MAT_CN(type);\n  651  \n  652:     if ( !(dev.isIntel() && (type == CV_8UC1) && (ddepth == CV_8U) &&\n  653           (borderType != BORDER_WRAP) &&\n  654           (_src.offset() == 0) && (_src.step() % 4 == 0) &&\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\distransform.cpp:\n  560      CV_Assert( src.size() == dst.size() );\n  561  \n  562:     CV_Assert( src.type() == CV_8UC1 && dst.type() == CV_32FC1 );\n  563      int i, m = src.rows, n = src.cols;\n  564  \n  ...\n  615      int dststep = (int)dst.step;\n  616  \n  617:     CV_Assert( src.type() == CV_8UC1 && dst.type() == CV_8UC1 );\n  618      CV_Assert( src.size() == dst.size() );\n  619  \n  ...\n  686      Mat src = _src.getMat();\n  687  \n  688:     CV_Assert( src.type() == CV_8UC1);\n  689  \n  690:     _dst.create( src.size(), CV_8UC1);\n  691      Mat dst = _dst.getMat();\n  692  \n  ...\n  718      bool need_labels = _labels.needed();\n  719  \n  720:     CV_Assert( src.type() == CV_8UC1);\n  721  \n  722      _dst.create( src.size(), CV_32F);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\featureselect.cpp:\n  280      using namespace ivx;\n  281  \n  282:     if(image.type() != CV_8UC1) return false;\n  283  \n  284      //OpenVX implementations don't have to provide other sizes\n  ...\n  364  \n  365      CV_Assert( qualityLevel > 0 && minDistance >= 0 && maxCorners >= 0 );\n  366:     CV_Assert( _mask.empty() || (_mask.type() == CV_8UC1 && _mask.sameSize(_image)) );\n  367  \n  368      CV_OCL_RUN(_image.dims() <= 2 && _image.isUMat(),\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\filter.cpp:\n 4400      src.locateROI(srcWholeSize, srcOffset);\n 4401  \n 4402:     bool fast8uc1 = type == CV_8UC1 && srcOffset.x % 4 == 0 &&\n 4403              src.cols % 4 == 0 && src.step % 4 == 0;\n 4404  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\floodfill.cpp:\n  526          if( k != elem_size )\n  527          {\n  528:             if( type == CV_8UC1 )\n  529                  floodFill_CnIR(img, seedPoint, nv_buf.b[0], &comp, flags, &buffer);\n  530              else if( type == CV_8UC3 )\n  ...\n  548      if( mask.empty() )\n  549      {\n  550:         Mat tempMask( size.height + 2, size.width + 2, CV_8UC1 );\n  551          tempMask.setTo(Scalar::all(0));\n  552          mask = tempMask;\n  ...\n  589      uchar newMaskVal = (uchar)((flags & 0xff00) == 0 ? 1 : ((flags >> 8) & 255));\n  590  \n  591:     if( type == CV_8UC1 )\n  592          floodFillGrad_CnIR<uchar, uchar, int, Diff8uC1>(\n  593                  img, mask, seedPoint, nv_buf.b[0], newMaskVal,\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\generalized_hough.cpp:\n  112          Mat src = _src.getMat();\n  113  \n  114:         CV_Assert( src.type() == CV_8UC1 );\n  115          CV_Assert( cannyLowThresh_ > 0 && cannyLowThresh_ < cannyHighThresh_ );\n  116  \n  ...\n  139          dy.getMat().copyTo(templDy_);\n  140  \n  141:         CV_Assert( templEdges_.type() == CV_8UC1 );\n  142          CV_Assert( templDx_.type() == CV_32FC1 && templDx_.size() == templEdges_.size() );\n  143          CV_Assert( templDy_.type() == templDx_.type() && templDy_.size() == templEdges_.size() );\n  ...\n  183          dy.getMat().copyTo(imageDy_);\n  184  \n  185:         CV_Assert( imageEdges_.type() == CV_8UC1 );\n  186          CV_Assert( imageDx_.type() == CV_32FC1 && imageDx_.size() == imageEdges_.size() );\n  187          CV_Assert( imageDy_.type() == imageDx_.type() && imageDy_.size() == imageEdges_.size() );\n  ...\n  418          CV_INSTRUMENT_REGION()\n  419  \n  420:         CV_Assert( imageEdges_.type() == CV_8UC1 );\n  421          CV_Assert( imageDx_.type() == CV_32FC1 && imageDx_.size() == imageSize_);\n  422          CV_Assert( imageDy_.type() == imageDx_.type() && imageDy_.size() == imageSize_);\n  ...\n  733      void GeneralizedHoughGuilImpl::getContourPoints(const Mat& edges, const Mat& dx, const Mat& dy, std::vector<ContourPoint>& points)\n  734      {\n  735:         CV_Assert( edges.type() == CV_8UC1 );\n  736          CV_Assert( dx.type() == CV_32FC1 && dx.size == edges.size );\n  737          CV_Assert( dy.type() == dx.type() && dy.size == edges.size );\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\grabcut.cpp:\n  325      if( mask.empty() )\n  326          CV_Error( CV_StsBadArg, \"mask is empty\" );\n  327:     if( mask.type() != CV_8UC1 )\n  328:         CV_Error( CV_StsBadArg, \"mask must have CV_8UC1 type\" );\n  329      if( mask.cols != img.cols || mask.rows != img.rows )\n  330          CV_Error( CV_StsBadArg, \"mask must have as many rows and cols as img\" );\n  ...\n  346  static void initMaskWithRect( Mat& mask, Size imgSize, Rect rect )\n  347  {\n  348:     mask.create( imgSize, CV_8UC1 );\n  349      mask.setTo( GC_BGD );\n  350  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\histogram.cpp:\n 1194  {\n 1195      IppiHistogram_C1 ippFunction =\n 1196:         (type == CV_8UC1) ? (IppiHistogram_C1)ippiHistogram_8u_C1R :\n 1197          (type == CV_16UC1) ? (IppiHistogram_C1)ippiHistogram_16u_C1R :\n 1198          (type == CV_32FC1) ? (IppiHistogram_C1)ippiHistogram_32f_C1R :\n ....\n 1447      CV_OVX_RUN(\n 1448          images && histSize &&\n 1449:         nimages == 1 && images[0].type() == CV_8UC1 && dims == 1 && _mask.getMat().empty() &&\n 1450          (!channels || channels[0] == 0) && !accumulate && uniform &&\n 1451          ranges && ranges[0] &&\n ....\n 1482      Size imsize;\n 1483  \n 1484:     CV_Assert( mask.empty() || mask.type() == CV_8UC1 );\n 1485      histPrepareImages( images, nimages, channels, mask, dims, hist.size, ranges,\n 1486                         uniform, ptrs, deltas, imsize, uniranges );\n ....\n 1660      Size imsize;\n 1661  \n 1662:     CV_Assert( mask.empty() || mask.type() == CV_8UC1 );\n 1663      histPrepareImages( images, nimages, channels, mask, dims, hist.hdr->size, ranges,\n 1664                         uniform, ptrs, deltas, imsize, uniranges );\n ....\n 3850  \n 3851      wgs = std::min<size_t>(ocl::Device::getDefault().maxWorkGroupSize(), BINS);\n 3852:     UMat lut(1, 256, CV_8UC1);\n 3853      ocl::Kernel k2(\"calcLUT\", ocl::imgproc::histogram_oclsrc,\n 3854                    format(\"-D BINS=%d -D HISTS_COUNT=%d -D WGS=%d\",\n ....\n 3911      CV_INSTRUMENT_REGION()\n 3912  \n 3913:     CV_Assert( _src.type() == CV_8UC1 );\n 3914  \n 3915      if (_src.empty())\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\hough.cpp:\n   85      float irho = 1 / rho;\n   86  \n   87:     CV_Assert( img.type() == CV_8UC1 );\n   88  \n   89      const uchar* image = img.ptr();\n   ..\n  223      std::vector<hough_index> lst;\n  224  \n  225:     CV_Assert( img.type() == CV_8UC1 );\n  226      CV_Assert( linesMax > 0 );\n  227  \n  ...\n  423      RNG rng((uint64)-1);\n  424  \n  425:     CV_Assert( image.type() == CV_8UC1 );\n  426  \n  427      int width = image.cols;\n  ...\n  461  \n  462      Mat accum = Mat::zeros( numangle, numrho, CV_32SC1 );\n  463:     Mat mask( height, width, CV_8UC1 );\n  464      std::vector<float> trigtab(numangle*2);\n  465  \n  ...\n  732                             double min_theta, double max_theta)\n  733  {\n  734:     CV_Assert(_src.type() == CV_8UC1);\n  735  \n  736      if (max_theta < 0 || max_theta > CV_PI ) {\n  ...\n  792                             double minLineLength, double maxGap)\n  793  {\n  794:     CV_Assert(_src.type() == CV_8UC1);\n  795  \n  796      if (!(rho > 0 && theta > 0)) {\n  ...\n 1492      CV_INSTRUMENT_REGION()\n 1493  \n 1494:     CV_Assert(!_image.empty() && _image.type() == CV_8UC1 && (_image.isMat() || _image.isUMat()));\n 1495      CV_Assert(_circles.isMat() || _circles.isVector());\n 1496  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\imgwarp.cpp:\n 1738  \n 1739      CV_OVX_RUN(\n 1740:         src.type() == CV_8UC1 && dst.type() == CV_8UC1 &&\n 1741          !ovx::skipSmallImages<VX_KERNEL_REMAP>(src.cols, src.rows) &&\n 1742          (borderType& ~BORDER_ISOLATED) == BORDER_CONSTANT &&\n ....\n 1769  \n 1770              ippiRemap ippFunc =\n 1771:                 type == CV_8UC1 ? (ippiRemap)ippiRemap_8u_C1R :\n 1772                  type == CV_8UC3 ? (ippiRemap)ippiRemap_8u_C3R :\n 1773                  type == CV_8UC4 ? (ippiRemap)ippiRemap_8u_C4R :\n ....\n 2465          interpolation = INTER_LINEAR;\n 2466  \n 2467:     if ( !dev.isIntel() || !(type == CV_8UC1) ||\n 2468:          !(dtype == CV_8UC1) || !(_dst.cols() % 4 == 0) ||\n 2469           !(borderType == cv::BORDER_CONSTANT &&\n 2470            (interpolation == cv::INTER_NEAREST || interpolation == cv::INTER_LINEAR || interpolation == cv::INTER_CUBIC)))\n ....\n 2726              {\n 2727                  ippFunc =\n 2728:                 type == CV_8UC1 ? (ippiWarpAffineBackFunc)ippiWarpAffineBack_8u_C1R :\n 2729                  type == CV_8UC3 ? (ippiWarpAffineBackFunc)ippiWarpAffineBack_8u_C3R :\n 2730                  type == CV_8UC4 ? (ippiWarpAffineBackFunc)ippiWarpAffineBack_8u_C4R :\n ....\n 2740              {\n 2741                  ippFunc =\n 2742:                 type == CV_8UC1 ? (ippiWarpAffineBackFunc)ippiWarpAffine_8u_C1R :\n 2743                  type == CV_8UC3 ? (ippiWarpAffineBackFunc)ippiWarpAffine_8u_C3R :\n 2744                  type == CV_8UC4 ? (ippiWarpAffineBackFunc)ippiWarpAffine_8u_C4R :\n ....\n 3015              if ((flags & WARP_INVERSE_MAP) != 0)\n 3016              {\n 3017:                 ippFunc = type == CV_8UC1 ? (ippiWarpPerspectiveFunc)ippiWarpPerspectiveBack_8u_C1R :\n 3018                  type == CV_8UC3 ? (ippiWarpPerspectiveFunc)ippiWarpPerspectiveBack_8u_C3R :\n 3019                  type == CV_8UC4 ? (ippiWarpPerspectiveFunc)ippiWarpPerspectiveBack_8u_C4R :\n ....\n 3027              else\n 3028              {\n 3029:                 ippFunc = type == CV_8UC1 ? (ippiWarpPerspectiveFunc)ippiWarpPerspective_8u_C1R :\n 3030                  type == CV_8UC3 ? (ippiWarpPerspectiveFunc)ippiWarpPerspective_8u_C3R :\n 3031                  type == CV_8UC4 ? (ippiWarpPerspectiveFunc)ippiWarpPerspective_8u_C4R :\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\lsd.cpp:\n  188   * Detect lines in the input image.\n  189   *\n  190:  * @param _image    A grayscale(CV_8UC1) input image.\n  191   *                  If only a roi needs to be selected, use\n  192   *                  lsd_ptr->detect(image(roi), ..., lines);\n  ...\n  414  \n  415      image = _image.getMat();\n  416:     CV_Assert(!image.empty() && image.type() == CV_8UC1);\n  417  \n  418      std::vector<Vec4f> lines;\n  ...\n  464  \n  465      // // Initialize region only when needed\n  466:     // Mat region = Mat::zeros(scaled_image.size(), CV_8UC1);\n  467      used = Mat_<uchar>::zeros(scaled_image.size()); // zeros = NOTUSED\n  468      std::vector<RegionPoint> reg;\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\moments.cpp:\n  574  \n  575  #if IPP_VERSION_X100 < 201801\n  576:     // Degradations for CV_8UC1\n  577:     if(src.type() == CV_8UC1)\n  578          return false;\n  579  #endif\n  ...\n  588  \n  589      ippiMoments ippiMoments64f =\n  590:         (type == CV_8UC1)?(ippiMoments)ippiMoments64f_8u_C1R:\n  591          (type == CV_16UC1)?(ippiMoments)ippiMoments64f_16u_C1R:\n  592          (type == CV_32FC1)?(ippiMoments)ippiMoments64f_32f_C1R:\n  ...\n  668  \n  669  #ifdef HAVE_OPENCL\n  670:     CV_OCL_RUN_(type == CV_8UC1 && _src.isUMat(), ocl_moments(_src, m, binary), m);\n  671  #endif\n  672  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\morph.cpp:\n 1430          actual_op = op;\n 1431  \n 1432:     if (type != CV_8UC1 ||\n 1433          !((_src.offset() == 0) && (_src.step() % 4 == 0)) ||\n 1434          !((_src.cols() % 16 == 0) && (_src.rows() % 2 == 0)) ||\n ....\n 2102          break;\n 2103      case MORPH_HITMISS:\n 2104:         CV_Assert(src.type() == CV_8UC1);\n 2105          if(countNonZero(kernel) <=0)\n 2106          {\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\pyramids.cpp:\n 1168      if (ocl::Device::getDefault().isIntel() && channels == 1)\n 1169      {\n 1170:         if (type == CV_8UC1 && src.cols % 2 == 0)\n 1171          {\n 1172              buildOptions.clear();\n ....\n 1220              int type = src.type();\n 1221              CV_SUPPRESS_DEPRECATED_START\n 1222:             ippiPyrUp pyrUpFunc = type == CV_8UC1 ? (ippiPyrUp) ippiPyrUp_Gauss5x5_8u_C1R :\n 1223                                    type == CV_8UC3 ? (ippiPyrUp) ippiPyrUp_Gauss5x5_8u_C3R :\n 1224                                    type == CV_32FC1 ? (ippiPyrUp) ippiPyrUp_Gauss5x5_32f_C1R :\n ....\n 1409              int type = src.type();\n 1410              CV_SUPPRESS_DEPRECATED_START\n 1411:             ippiPyrUp pyrUpFunc = type == CV_8UC1 ? (ippiPyrUp) ippiPyrUp_Gauss5x5_8u_C1R :\n 1412                                    type == CV_8UC3 ? (ippiPyrUp) ippiPyrUp_Gauss5x5_8u_C3R :\n 1413                                    type == CV_32FC1 ? (ippiPyrUp) ippiPyrUp_Gauss5x5_32f_C1R :\n ....\n 1522              ippiPyramidLayerDownFree pyrFreeFunc = 0;\n 1523  \n 1524:             if (type == CV_8UC1)\n 1525              {\n 1526                  pyrInitAllocFunc = (ippiPyramidLayerDownInitAlloc) ippiPyramidLayerDownInitAlloc_8u_C1R;\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\resize.cpp:\n 2632              int wdepth = std::max(depth, CV_32S), wtype = CV_MAKETYPE(wdepth, cn);\n 2633              UMat coeffs;\n 2634:             Mat(1, static_cast<int>(_buffer.size()), CV_8UC1, (uchar *)_buffer).copyTo(coeffs);\n 2635  \n 2636              k.create(\"resizeLN\", ocl::imgproc::resize_oclsrc,\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\samplers.cpp:\n  391          int srctype = image.type();\n  392          ippiGetRectSubPixFunc ippiCopySubpixIntersect =\n  393:             srctype == CV_8UC1 && ddepth == CV_8U ? (ippiGetRectSubPixFunc)ippiCopySubpixIntersect_8u_C1R :\n  394:             srctype == CV_8UC1 && ddepth == CV_32F ? (ippiGetRectSubPixFunc)ippiCopySubpixIntersect_8u32f_C1R :\n  395              srctype == CV_32FC1 && ddepth == CV_32F ? (ippiGetRectSubPixFunc)ippiCopySubpixIntersect_32f_C1R : 0;\n  396  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\segmentation.cpp:\n  398      }\n  399  \n  400:     mask0.create(src0.rows, src0.cols, CV_8UC1);\n  401      //CV_CALL( submask = (uchar*)cvAlloc( (sp+2)*(sp+2) ));\n  402  \n  ...\n  418          {\n  419              cv::Size size1 = dst_pyramid[level+1].size();\n  420:             cv::Mat m( size.height, size.width, CV_8UC1, mask0.ptr() );\n  421              dstep = (int)dst_pyramid[level+1].step;\n  422              dptr = dst_pyramid[level+1].ptr() + dstep + cn;\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\shapedescr.cpp:\n 1331              mat = 0;\n 1332          }\n 1333:         else if( CV_MAT_TYPE(mat->type) != CV_8UC1 &&\n 1334                  CV_MAT_TYPE(mat->type) != CV_8SC1 )\n 1335              CV_Error( CV_StsUnsupportedFormat,\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\smooth.cpp:\n 1071          anchor.y = ksize.height / 2;\n 1072  \n 1073:     if ( !(dev.isIntel() && (type == CV_8UC1) &&\n 1074           (_src.offset() == 0) && (_src.step() % 4 == 0) &&\n 1075           (_src.cols() % 16 == 0) && (_src.rows() % 2 == 0) &&\n ....\n 1407      {\n 1408          if (ddepth < 0)\n 1409:             ddepth = CV_8UC1;\n 1410:         if (_src.type() != CV_8UC1 || ddepth != CV_8U || !normalize ||\n 1411              _src.cols() < 3 || _src.rows() < 3 ||\n 1412              ksize.width != 3 || ksize.height != 3 ||\n ....\n 1433          }\n 1434  \n 1435:         _dst.create(src.size(), CV_8UC1);\n 1436          Mat dst = _dst.getMat();\n 1437  \n ....\n 1809      int type = _src.type(), sdepth = CV_MAT_DEPTH(type), cn = CV_MAT_CN(type);\n 1810  \n 1811:     if ( !(dev.isIntel() && (type == CV_8UC1) &&\n 1812           (_src.offset() == 0) && (_src.step() % 4 == 0) &&\n 1813           ((ksize.width == 5 && (_src.cols() % 4 == 0)) ||\n ....\n 1890          ksize.height = cvRound(sigma2*6 + 1) | 1;\n 1891  \n 1892:     if (_src.type() != CV_8UC1 ||\n 1893          _src.cols() < 3 || _src.rows() < 3 ||\n 1894          ksize.width != 3 || ksize.height != 3)\n ....\n 2943      static bool openvx_medianFilter(InputArray _src, OutputArray _dst, int ksize)\n 2944      {\n 2945:         if (_src.type() != CV_8UC1 || _dst.type() != CV_8U\n 2946  #ifndef VX_VERSION_1_1\n 2947              || ksize != 3\n ....\n 3006                          return false;\n 3007                      }\n 3008:                     Mat mask(ksize, ksize, CV_8UC1, Scalar(255));\n 3009                      mtx = ivx::Matrix::create(ctx, VX_TYPE_UINT8, ksize, ksize);\n 3010                      mtx.copyFrom(mask);\n ....\n 3455      Size size = src.size();\n 3456  \n 3457:     CV_Assert( (src.type() == CV_8UC1 || src.type() == CV_8UC3) && src.data != dst.data );\n 3458  \n 3459      if( sigma_color <= 0 )\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\spatialgradient.cpp:\n   84      Mat src = _src.getMat();\n   85      CV_Assert( !src.empty() );\n   86:     CV_Assert( src.type() == CV_8UC1 );\n   87      CV_Assert( borderType == BORDER_DEFAULT || borderType == BORDER_REPLICATE );\n   88  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\sumpixels.cpp:\n  315      bool doubleSupport = ocl::Device::getDefault().doubleFPConfig() > 0;\n  316  \n  317:     if ( (_src.type() != CV_8UC1) ||\n  318          !(sdepth == CV_32S || sdepth == CV_32F || (doubleSupport && sdepth == CV_64F)))\n  319          return false;\n  ...\n  355      bool doubleSupport = ocl::Device::getDefault().doubleFPConfig() > 0;\n  356  \n  357:     if ( _src.type() != CV_8UC1 || (!doubleSupport && (sdepth == CV_64F || sqdepth == CV_64F)) )\n  358          return false;\n  359  \n  ...\n  425          if(depth == CV_8U && sdepth == CV_32S)\n  426              return CV_INSTRUMENT_FUN_IPP(ippiIntegral_8u32s_C1R, (const Ipp8u*)src, (int)srcstep, (Ipp32s*)sum, (int)sumstep, size, 0) >= 0;\n  427:         else if(depth == CV_8UC1 && sdepth == CV_32F)\n  428              return CV_INSTRUMENT_FUN_IPP(ippiIntegral_8u32f_C1R, (const Ipp8u*)src, (int)srcstep, (Ipp32f*)sum, (int)sumstep, size, 0) >= 0;\n  429          else if(depth == CV_32FC1 && sdepth == CV_32F)\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\src\\thresh.cpp:\n 1400      if( automatic_thresh == CV_THRESH_OTSU )\n 1401      {\n 1402:         CV_Assert( src.type() == CV_8UC1 );\n 1403          thresh = getThreshVal_Otsu_8u( src );\n 1404      }\n 1405      else if( automatic_thresh == CV_THRESH_TRIANGLE )\n 1406      {\n 1407:         CV_Assert( src.type() == CV_8UC1 );\n 1408          thresh = getThreshVal_Triangle_8u( src );\n 1409      }\n ....\n 1518  \n 1519      Mat src = _src.getMat();\n 1520:     CV_Assert( src.type() == CV_8UC1 );\n 1521      CV_Assert( blockSize % 2 == 1 && blockSize > 1 );\n 1522      Size size = src.size();\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\test\\ocl\\test_accumulate.cpp:\n   82  \n   83          Border maskBorder = randomBorder(0, useRoi ? MAX_VALUE : 0);\n   84:         randomSubMat(mask, mask_roi, roiSize, maskBorder, CV_8UC1, -MAX_VALUE, MAX_VALUE);\n   85          threshold(mask, mask, 80, 255, THRESH_BINARY);\n   86  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\test\\ocl\\test_filters.cpp:\n  443      {\n  444          random_roi();\n  445:         Mat kernel = ksize==0 ? Mat() : randomMat(kernelSize, CV_8UC1, 0, 3);\n  446  \n  447          OCL_OFF(cv::erode(src_roi, dst_roi, kernel, Point(-1, -1), iterations) );\n  ...\n  465      {\n  466          random_roi();\n  467:         Mat kernel = ksize==0 ? Mat() : randomMat(kernelSize, CV_8UC1, 0, 3);\n  468  \n  469          OCL_OFF(cv::dilate(src_roi, dst_roi, kernel, Point(-1, -1), iterations) );\n  ...\n  544      {\n  545          random_roi();\n  546:         Mat kernel = ksize==0 ? Mat() : randomMat(kernelSize, CV_8UC1, 0, 3);\n  547  \n  548          OCL_OFF(cv::dilate(src_roi, dst_roi, kernel, Point(-1, -1), iterations) );\n  ...\n  621      {\n  622          random_roi();\n  623:         Mat kernel = randomMat(kernelSize, CV_8UC1, 0, 3);\n  624  \n  625          OCL_OFF(cv::morphologyEx(src_roi, dst_roi, op, kernel, Point(-1, -1), iterations) );\n  ...\n  644              (int)BORDER_REFLECT_101|BORDER_ISOLATED*/) // WRAP and ISOLATED are not supported by cv:: version\n  645  \n  646: #define FILTER_TYPES Values(CV_8UC1, CV_8UC3, CV_8UC4, CV_16UC1, CV_16UC3, CV_16UC4, CV_32FC1, CV_32FC3, CV_32FC4)\n  647  \n  648  OCL_INSTANTIATE_TEST_CASE_P(Filter, Bilateral, Combine(\n  649:                             Values(CV_8UC1, CV_8UC3),\n  650                              Values(5, 9), // kernel size\n  651                              Values(Size(0, 0)), // not used\n  ...\n  665  \n  666  OCL_INSTANTIATE_TEST_CASE_P(Filter, Laplacian3_cols16_rows2, Combine(\n  667:                             Values((MatType)CV_8UC1),\n  668                              Values(3), // kernel size\n  669                              Values(Size(0, 0)), // not used\n  ...\n  683  \n  684  OCL_INSTANTIATE_TEST_CASE_P(Filter, Sobel3x3_cols16_rows2, Combine(\n  685:                             Values((MatType)CV_8UC1),\n  686                              Values(3), // kernel size\n  687                              Values(Size(1, 0), Size(1, 1), Size(2, 0), Size(2, 1)), // dx, dy\n  ...\n  719  \n  720  OCL_INSTANTIATE_TEST_CASE_P(Filter, GaussianBlur_multicols, Combine(\n  721:                             Values((MatType)CV_8UC1),\n  722                              Values(3, 5), // kernel size\n  723                              Values(Size(0, 0)), // not used\n  ...\n  728  \n  729  OCL_INSTANTIATE_TEST_CASE_P(Filter, Erode, Combine(\n  730:                             Values(CV_8UC1, CV_8UC3, CV_8UC4, CV_32FC1, CV_32FC3, CV_32FC4, CV_64FC1, CV_64FC4),\n  731                              Values(0, 3, 5, 7), // kernel size, 0 means kernel = Mat()\n  732                              Values(Size(0, 0)), //not used\n  ...\n  737  \n  738  OCL_INSTANTIATE_TEST_CASE_P(Filter, Dilate, Combine(\n  739:                             Values(CV_8UC1, CV_8UC3, CV_8UC4, CV_32FC1, CV_32FC3, CV_32FC4, CV_64FC1, CV_64FC4),\n  740                              Values(0, 3, 5, 7), // kernel size, 0 means kernel = Mat()\n  741                              Values(Size(0, 0)), // not used\n  ...\n  746  \n  747  OCL_INSTANTIATE_TEST_CASE_P(Filter, MorphFilter3x3_cols16_rows2, Combine(\n  748:                             Values((MatType)CV_8UC1),\n  749                              Values(0, 3), // kernel size, 0 means kernel = Mat()\n  750                              Values(Size(0, 0)), // not used\n  ...\n  755  \n  756  OCL_INSTANTIATE_TEST_CASE_P(Filter, MorphologyEx, Combine(\n  757:                             Values(CV_8UC1, CV_8UC3, CV_8UC4, CV_32FC1, CV_32FC3, CV_32FC4),\n  758                              Values(3, 5, 7), // kernel size\n  759                              Values((MorphOp)MORPH_OPEN, (MorphOp)MORPH_CLOSE, (MorphOp)MORPH_GRADIENT, (MorphOp)MORPH_TOPHAT, (MorphOp)MORPH_BLACKHAT), // used as generator of operations\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\test\\ocl\\test_histogram.cpp:\n  239  \n  240          Border srcBorder = randomBorder(0, useRoi ? MAX_VALUE : 0);\n  241:         randomSubMat(src, src_roi, roiSize, srcBorder, CV_8UC1, 0, 256);\n  242  \n  243          Border histBorder = randomBorder(0, useRoi ? MAX_VALUE : 0);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\test\\ocl\\test_houghlines.cpp:\n   44      {\n   45          src_size = randomSize(500, 1920);\n   46:         src.create(src_size, CV_8UC1);\n   47          src.setTo(Scalar::all(0));\n   48          line(src, Point(0, 100), Point(100, 100), Scalar::all(255), 1);\n   ..\n  139          if (dst.total() > 0 && lines_gpu.total() > 0)\n  140          {\n  141:             Mat result_cpu(src.size(), CV_8UC1, Scalar::all(0));\n  142:             Mat result_gpu(src.size(), CV_8UC1, Scalar::all(0));\n  143  \n  144              MatConstIterator_<Vec4i> it = dst.begin<Vec4i>(), end = dst.end<Vec4i>();\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\test\\ocl\\test_imgproc.cpp:\n  405          Size roiSize = randomSize(std::max(gridSize.height, gridSize.width), MAX_VALUE);\n  406          Border srcBorder = randomBorder(0, useRoi ? MAX_VALUE : 0);\n  407:         randomSubMat(src, src_roi, roiSize, srcBorder, CV_8UC1, 5, 256);\n  408  \n  409          Border dstBorder = randomBorder(0, useRoi ? MAX_VALUE : 0);\n  410:         randomSubMat(dst, dst_roi, roiSize, dstBorder, CV_8UC1, 5, 16);\n  411  \n  412          UMAT_UPLOAD_INPUT_PARAMETER(src);\n  ...\n  438  \n  439  OCL_INSTANTIATE_TEST_CASE_P(Imgproc, EqualizeHist, Combine(\n  440:                             Values((MatType)CV_8UC1),\n  441                              Values(0), // not used\n  442                              Values(0), // not used\n  ...\n  444  \n  445  OCL_INSTANTIATE_TEST_CASE_P(Imgproc, CornerMinEigenVal, Combine(\n  446:                             Values((MatType)CV_8UC1, (MatType)CV_32FC1),\n  447                              Values(3, 5),\n  448                              Values((BorderType)BORDER_CONSTANT, (BorderType)BORDER_REPLICATE,\n  ...\n  451  \n  452  OCL_INSTANTIATE_TEST_CASE_P(Imgproc, CornerHarris, Combine(\n  453:                             Values((MatType)CV_8UC1, CV_32FC1),\n  454                              Values(3, 5),\n  455                              Values( (BorderType)BORDER_CONSTANT, (BorderType)BORDER_REPLICATE,\n  ...\n  458  \n  459  OCL_INSTANTIATE_TEST_CASE_P(Imgproc, PreCornerDetect, Combine(\n  460:                             Values((MatType)CV_8UC1, CV_32FC1),\n  461                              Values(3, 5),\n  462                              Values( (BorderType)BORDER_CONSTANT, (BorderType)BORDER_REPLICATE,\n  ...\n  465  \n  466  OCL_INSTANTIATE_TEST_CASE_P(Imgproc, Integral, Combine(\n  467:                             Values((MatType)CV_8UC1), // TODO does not work with CV_32F, CV_64F\n  468                              Values(CV_32SC1, CV_32FC1), // desired sdepth\n  469                              Values(CV_32FC1, CV_64FC1), // desired sqdepth\n  ...\n  471  \n  472  OCL_INSTANTIATE_TEST_CASE_P(Imgproc, Threshold, Combine(\n  473:                             Values(CV_8UC1, CV_8UC2, CV_8UC3, CV_8UC4,\n  474                                     CV_16SC1, CV_16SC2, CV_16SC3, CV_16SC4,\n  475                                     CV_32FC1, CV_32FC2, CV_32FC3, CV_32FC4),\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\test\\ocl\\test_warp.cpp:\n  431  \n  432  OCL_INSTANTIATE_TEST_CASE_P(ImgprocWarp, WarpAffine, Combine(\n  433:                             Values(CV_8UC1, CV_8UC3, CV_8UC4, CV_32FC1, CV_32FC3, CV_32FC4),\n  434                              Values((Interpolation)INTER_NEAREST, (Interpolation)INTER_LINEAR, (Interpolation)INTER_CUBIC),\n  435                              Bool(),\n  ...\n  437  \n  438  OCL_INSTANTIATE_TEST_CASE_P(ImgprocWarp, WarpAffine_cols4, Combine(\n  439:                             Values((MatType)CV_8UC1),\n  440                              Values((Interpolation)INTER_NEAREST, (Interpolation)INTER_LINEAR, (Interpolation)INTER_CUBIC),\n  441                              Bool(),\n  ...\n  443  \n  444  OCL_INSTANTIATE_TEST_CASE_P(ImgprocWarp, WarpPerspective, Combine(\n  445:                             Values(CV_8UC1, CV_8UC3, CV_8UC4, CV_32FC1, CV_32FC3, CV_32FC4),\n  446                              Values((Interpolation)INTER_NEAREST, (Interpolation)INTER_LINEAR, (Interpolation)INTER_CUBIC),\n  447                              Bool(),\n  ...\n  449  \n  450  OCL_INSTANTIATE_TEST_CASE_P(ImgprocWarp, WarpPerspective_cols4, Combine(\n  451:                             Values((MatType)CV_8UC1),\n  452                              Values((Interpolation)INTER_NEAREST, (Interpolation)INTER_LINEAR, (Interpolation)INTER_CUBIC),\n  453                              Bool(),\n  ...\n  455  \n  456  OCL_INSTANTIATE_TEST_CASE_P(ImgprocWarp, Resize, Combine(\n  457:                             Values(CV_8UC1, CV_8UC4, CV_16UC2, CV_32FC1, CV_32FC4),\n  458                              Values(0.5, 1.5, 2.0, 0.2),\n  459                              Values(0.5, 1.5, 2.0, 0.2),\n  ...\n  463  \n  464  OCL_INSTANTIATE_TEST_CASE_P(ImgprocWarpResizeArea, Resize, Combine(\n  465:                             Values((MatType)CV_8UC1, CV_8UC4, CV_32FC1, CV_32FC4),\n  466                              Values(0.7, 0.4, 0.5),\n  467                              Values(0.3, 0.6, 0.5),\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\test\\test_bilateral_filter.cpp:\n  234      int CV_BilateralFilterTest::prepare_test_case(int /* test_case_index */)\n  235      {\n  236:         const static int types[] = { CV_32FC1, CV_32FC3, CV_8UC1, CV_8UC3 };\n  237          RNG& rng = ts->get_rng();\n  238          Size size(getRandInt(rng, MIN_WIDTH, MAX_WIDTH), getRandInt(rng, MIN_HEIGHT, MAX_HEIGHT));\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\test\\test_color.cpp:\n 1976      {\n 1977          calculateBayerPattern<uchar, CV_8U>(src, bayer, pattern[i]);\n 1978:         CV_Assert(!bayer.empty() && bayer.type() == CV_8UC1);\n 1979  \n 1980          // calculating a dst image\n ....\n 2971                  calculateBayerPattern<unsigned short int, CV_16U>(src, bayer, types[i]);\n 2972  \n 2973:             CV_Assert(!bayer.empty() && (bayer.type() == CV_8UC1 || bayer.type() == CV_16UC1));\n 2974  \n 2975              Mat actual;\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\test\\test_convhull.cpp:\n  565      hull_count = hseq->total;\n  566      hull = cvCreateMat( 1, hull_count, CV_32FC2 );\n  567:     mask = cvCreateMat( 1, hull_count, CV_8UC1 );\n  568      cvZero( mask );\n  569      Mat _mask = cvarrToMat(mask);\n  ...\n 1444      }\n 1445  \n 1446:     Mat image = Mat::zeros(dim*4, dim*4, CV_8UC1);\n 1447      ellipse(image, center, Size(height, width), angle,\n 1448              0, 360, Scalar(255, 0, 0), 1, 8);\n ....\n 1823      int code = CV_BaseShapeDescrTest::validate_test_results( test_case_idx );\n 1824      int i, n = (int)(sizeof(moments)/sizeof(moments.inv_sqrt_m00));\n 1825:     CvMat* img = cvCreateMat( img_size.height, img_size.width, CV_8UC1 );\n 1826      CvPoint* pt = (CvPoint*)points2->data.i;\n 1827      int count = points2->cols + points2->rows - 1;\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\test\\test_cvtyuv.cpp:\n  643  \n  644          Size srcSize = cvt.getSrcSize(sz);\n  645:         Mat src = Mat(srcSize.height, srcSize.width * scn, CV_8UC1).reshape(scn);\n  646  \n  647          Size dstSize = cvt.getDstSize(sz);\n  648:         Mat dst = Mat(dstSize.height, dstSize.width * dcn, CV_8UC1).reshape(dcn);\n  649          Mat gold(dstSize, CV_8UC(dcn));\n  650  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\test\\test_distancetransform.cpp:\n   84      cvtest::ArrayTest::get_test_array_types_and_sizes( test_case_idx, sizes, types );\n   85  \n   86:     types[INPUT][0] = CV_8UC1;\n   87      types[OUTPUT][0] = types[REF_OUTPUT][0] = CV_32FC1;\n   88      types[OUTPUT][1] = types[REF_OUTPUT][1] = CV_32SC1;\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\test\\test_drawing.cpp:\n  674      const int cols = 256;\n  675  \n  676:     Mat img(rows, cols, CV_8UC1, Scalar(255));\n  677  \n  678      line(img, Point(0, 10), Point(255, 10), Scalar(0), 2, 4);\n  ...\n  692  TEST(Drawing, polylines_empty)\n  693  {\n  694:     Mat img(100, 100, CV_8UC1, Scalar(0));\n  695      vector<Point> pts; // empty\n  696      polylines(img, pts, false, Scalar(255));\n  ...\n  701  TEST(Drawing, polylines)\n  702  {\n  703:     Mat img(100, 100, CV_8UC1, Scalar(0));\n  704      vector<Point> pts;\n  705      pts.push_back(Point(0, 0));\n  ...\n  712  TEST(Drawing, longline)\n  713  {\n  714:     Mat mat = Mat::zeros(256, 256, CV_8UC1);\n  715  \n  716      line(mat, cv::Point(34, 204), cv::Point(46400, 47400), cv::Scalar(255), 3);\n  ...\n  739  {\n  740      Size sz(640, 480);\n  741:     Mat mat = Mat::zeros(sz, CV_8UC1);\n  742  \n  743      mat = Scalar::all(0);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\test\\test_filter.cpp:\n  143      anchor.y = cvtest::randInt(rng) % aperture_size.height;\n  144  \n  145:     types[INPUT][1] = fp_kernel ? CV_32FC1 : CV_8UC1;\n  146      sizes[INPUT][1] = aperture_size;\n  147  \n  ...\n  583      sizes[OUTPUT][1] = sizes[REF_OUTPUT][1] = sizes[OUTPUT][0];\n  584  \n  585:     // Inputs are only CV_8UC1 for now\n  586:     types[INPUT][0] = CV_8UC1;\n  587  \n  588      // Outputs are only CV_16SC1 for now\n  ...\n  975  \n  976      assert( src.rows == dst.rows + m - 1 && src.cols == dst.cols + m - 1 &&\n  977:             src.type() == dst.type() && src.type() == CV_8UC1 );\n  978  \n  979      for( i = 0; i < dst.rows; i++ )\n  ...\n 1360      Point anchor( aperture_size/2, aperture_size/2 );\n 1361  \n 1362:     CV_Assert( src.type() == CV_8UC1 || src.type() == CV_32FC1 );\n 1363      CV_Assert( eigenv.type() == CV_32FC1 );\n 1364      CV_Assert( src.rows == eigenv.rows &&\n ....\n 1956  \n 1957      /// ksize > src_roi.size()\n 1958:     Mat src(3, 3, CV_8UC1, cv::Scalar::all(255)), dst;\n 1959      Mat src_roi = src(Rect(1, 1, 1, 1));\n 1960      src_roi.setTo(cv::Scalar::all(0));\n ....\n 1969  \n 1970      /// ksize <= src_roi.size()\n 1971:     src = Mat(5, 5, CV_8UC1, cv::Scalar(255));\n 1972      src_roi = src(Rect(1, 1, 3, 3));\n 1973      src_roi.setTo(0);\n ....\n 1987      Size kernelSize(3, 3);\n 1988  \n 1989:     Mat src_16(16, 16, CV_8UC1, cv::Scalar::all(42)), dst_16;\n 1990      Mat src_roi_16 = src_16(Rect(1, 1, 14, 14));\n 1991      src_roi_16.setTo(cv::Scalar::all(3));\n ....\n 1995      EXPECT_EQ(20, dst_16.at<uchar>(0, 0));\n 1996  \n 1997:     Mat src(3, 12, CV_8UC1, cv::Scalar::all(42)), dst;\n 1998      Mat src_roi = src(Rect(1, 1, 10, 1));\n 1999      src_roi.setTo(cv::Scalar::all(2));\n ....\n 2060  \n 2061      /// ksize <= src_roi.size()\n 2062:     src = Mat(5, 5, CV_8UC1, cv::Scalar(5));\n 2063      src_roi = src(Rect(1, 1, 3, 3));\n 2064      src_roi.setTo(0);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\test\\test_floodfill.cpp:\n  109  \n  110      types[INPUT_OUTPUT][0] = types[REF_INPUT_OUTPUT][0] = CV_MAKETYPE(depth, cn);\n  111:     types[INPUT_OUTPUT][1] = types[REF_INPUT_OUTPUT][1] = CV_8UC1;\n  112      types[OUTPUT][0] = types[REF_OUTPUT][0] = CV_64FC1;\n  113      sizes[OUTPUT][0] = sizes[REF_OUTPUT][0] = cvSize(9,1);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\test\\test_goodfeaturetotrack.cpp:\n   74      Point anchor( aperture_size/2, aperture_size/2 );\n   75  \n   76:     CV_Assert( src.type() == CV_8UC1 || src.type() == CV_32FC1 );\n   77      CV_Assert( eigenv.type() == CV_32FC1 );\n   78      CV_Assert( ( src.rows == eigenv.rows ) &&\n   ..\n  167  \n  168      CV_Assert( qualityLevel > 0 && minDistance >= 0 && maxCorners >= 0 );\n  169:     CV_Assert( _mask.empty() || (_mask.type() == CV_8UC1 && _mask.sameSize(_image)) );\n  170  \n  171  \n  ...\n  355  int CV_GoodFeatureToTTest::prepare_test_case( int test_case_idx )\n  356  {\n  357:     const static int types[] = { CV_32FC1, CV_8UC1 };\n  358  \n  359      cvtest::TS& tst = *cvtest::TS::ptr();\n  ...\n  374  \n  375      CV_Assert( cn == 1 );\n  376:     CV_Assert( ( CV_MAT_DEPTH(SrcType) == CV_32FC1 ) || ( CV_MAT_DEPTH(SrcType) == CV_8UC1 ));\n  377  \n  378      TEST_MESSAGEL (\"             maxCorners = \", maxCorners)\n  ...\n  406      else\n  407      {\n  408:         if (src_gray.depth() != CV_8UC1 ) src_gray.convertTo(src_gray8U, CV_8UC1);\n  409          else   src_gray8U = src_gray.clone();\n  410  \n  ...\n  449      else\n  450      {\n  451:         if (src_gray.depth() != CV_8UC1 ) src_gray.convertTo(src_gray8U, CV_8UC1);\n  452          else   src_gray8U = src_gray.clone();\n  453  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\test\\test_imgwarp.cpp:\n 1558          expected_data[i] = (uchar)(254 + i / (16 * 8));\n 1559  \n 1560:     cv::Mat src(32, 32, CV_8UC1, input_data);\n 1561:     cv::Mat expected(16, 16, CV_8UC1, expected_data);\n 1562      cv::Mat actual(expected.size(), expected.type());\n 1563  \n ....\n 1577          expected_data[i] = 254;\n 1578  \n 1579:     cv::Mat src(32, 32, CV_8UC1, input_data);\n 1580:     cv::Mat expected(8, 8, CV_8UC1, expected_data);\n 1581      cv::Mat actual(expected.size(), expected.type());\n 1582  \n ....\n 1648  {\n 1649      const int size = 1000;\n 1650:     int types[] = { CV_8UC1, CV_8UC4,\n 1651                      CV_16UC1, CV_16UC4,\n 1652                      CV_16SC1, CV_16SC3, CV_16SC4,\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\imgproc\\test\\test_lsd.cpp:\n   54  void LSDBase::GenerateWhiteNoise(Mat& image)\n   55  {\n   56:     image = Mat(img_size, CV_8UC1);\n   57      rng.fill(image, RNG::UNIFORM, 0, 256);\n   58  }\n   ..\n   60  void LSDBase::GenerateConstColor(Mat& image)\n   61  {\n   62:     image = Mat(img_size, CV_8UC1, Scalar::all(rng.uniform(0, 256)));\n   63  }\n   64  \n   65  void LSDBase::GenerateLines(Mat& image, const unsigned int numLines)\n   66  {\n   67:     image = Mat(img_size, CV_8UC1, Scalar::all(rng.uniform(0, 128)));\n   68  \n   69      for(unsigned int i = 0; i < numLines; ++i)\n   ..\n   78  void LSDBase::GenerateRotatedRect(Mat& image)\n   79  {\n   80:     image = Mat::zeros(img_size, CV_8UC1);\n   81  \n   82      Point center(rng.uniform(img_size.width/4, img_size.width*3/4),\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\java\\generator\\src\\cpp\\converters.cpp:\n   54  {\n   55      v_uchar.clear();\n   56:     CHECK_MAT(mat.type()==CV_8UC1 && mat.cols==1);\n   57      v_uchar = (std::vector<uchar>) mat;\n   58  }\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\java\\generator\\src\\cpp\\utils.cpp:\n   96                         info.format == ANDROID_BITMAP_FORMAT_RGB_565 );\n   97              CV_Assert( src.dims == 2 && info.height == (uint32_t)src.rows && info.width == (uint32_t)src.cols );\n   98:             CV_Assert( src.type() == CV_8UC1 || src.type() == CV_8UC3 || src.type() == CV_8UC4 );\n   99              CV_Assert( AndroidBitmap_lockPixels(env, bitmap, &pixels) >= 0 );\n  100              CV_Assert( pixels );\n  ...\n  102              {\n  103                  Mat tmp(info.height, info.width, CV_8UC4, pixels);\n  104:                 if(src.type() == CV_8UC1)\n  105                  {\n  106:                     LOGD(\"nMatToBitmap: CV_8UC1 -> RGBA_8888\");\n  107                      cvtColor(src, tmp, COLOR_GRAY2RGBA);\n  108                  } else if(src.type() == CV_8UC3){\n  ...\n  117                  // info.format == ANDROID_BITMAP_FORMAT_RGB_565\n  118                  Mat tmp(info.height, info.width, CV_8UC2, pixels);\n  119:                 if(src.type() == CV_8UC1)\n  120                  {\n  121:                     LOGD(\"nMatToBitmap: CV_8UC1 -> RGB_565\");\n  122                      cvtColor(src, tmp, COLOR_GRAY2BGR565);\n  123                  } else if(src.type() == CV_8UC3){\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\js\\src\\core_bindings.cpp:\n  540      function(\"getBuildInformation\", &binding_utils::getBuildInformation);\n  541  \n  542:     constant(\"CV_8UC1\", CV_8UC1);\n  543      constant(\"CV_8UC2\", CV_8UC2);\n  544      constant(\"CV_8UC3\", CV_8UC3);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\objdetect\\src\\detection_based_tracker.cpp:\n  556      if (shouldSendNewDataToWorkThread) {\n  557  \n  558:         imageSeparateDetecting.create(imageGray.size(), CV_8UC1);\n  559  \n  560          imageGray.copyTo(imageSeparateDetecting);//may change imageSeparateDetecting ptr. But should not.\n  ...\n  629      CV_INSTRUMENT_REGION()\n  630  \n  631:     CV_Assert(imageGray.type()==CV_8UC1);\n  632  \n  633      if ( separateDetectionWork && !separateDetectionWork->isWorking() ) {\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\objdetect\\src\\haar.cpp:\n 1260      }\n 1261  \n 1262:     temp.reset(cvCreateMat( img->rows, img->cols, CV_8UC1 ));\n 1263      sum.reset(cvCreateMat( img->rows + 1, img->cols + 1, CV_32SC1 ));\n 1264      sqsum.reset(cvCreateMat( img->rows + 1, img->cols + 1, CV_64FC1 ));\n ....\n 1290              normImg.reset(cvCreateMat( img->rows, img->cols, CV_32FC1));\n 1291  #endif\n 1292:         imgSmall.reset(cvCreateMat( img->rows + 1, img->cols + 1, CV_8UC1 ));\n 1293  \n 1294          for( factor = 1; ; factor *= scaleFactor )\n ....\n 1313                  continue;\n 1314  \n 1315:             img1 = cvMat( sz.height, sz.width, CV_8UC1, imgSmall->data.ptr );\n 1316              sum1 = cvMat( sz.height+1, sz.width+1, CV_32SC1, sum->data.ptr );\n 1317              sqsum1 = cvMat( sz.height+1, sz.width+1, CV_64FC1, sqsum->data.ptr );\n ....\n 1322              }\n 1323              norm1 = cvMat( sz1.height, sz1.width, CV_32FC1, normImg ? normImg->data.ptr : 0 );\n 1324:             mask1 = cvMat( sz1.height, sz1.width, CV_8UC1, temp->data.ptr );\n 1325  \n 1326              cvResize( img, &img1, CV_INTER_LINEAR );\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\objdetect\\src\\hog.cpp:\n 1605      Size paddedImgSize(imgSize.width + padding.width*2, imgSize.height + padding.height*2);\n 1606  \n 1607:     CV_OCL_RUN(_img.dims() <= 2 && _img.type() == CV_8UC1 && _img.isUMat(),\n 1608          ocl_compute(_img, winStride, descriptors, DESCR_FORMAT_COL_BY_COL, blockSize,\n 1609          cellSize, nbins, blockStride, winSize, (float)getWinSigma(), gammaCorrection, L2HysThreshold, signedGradient))\n ....\n 2077          winStride = blockStride;\n 2078  \n 2079:     CV_OCL_RUN(_img.dims() <= 2 && _img.type() == CV_8UC1 && scale0 > 1 && winStride.width % blockStride.width == 0 &&\n 2080          winStride.height % blockStride.height == 0 && padding == Size(0,0) && _img.isUMat(),\n 2081          ocl_detectMultiScale(_img, foundLocations, levelScale, hitThreshold, winStride, finalThreshold, oclSvmDetector,\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\objdetect\\test\\opencl\\test_hogdetector.cpp:\n  116  INSTANTIATE_TEST_CASE_P(OCL_ObjDetect, HOG, testing::Combine(\n  117                              testing::Values(Size(64, 128), Size(48, 96)),\n  118:                             testing::Values( MatType(CV_8UC1) ) ) );\n  119  \n  120  }}\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\objdetect\\test\\test_cascadeandhog.cpp:\n 1345          Size ssize(rng.uniform(1, 10) * actual_hog.winSize.width,\n 1346              rng.uniform(1, 10) * actual_hog.winSize.height);\n 1347:         int type = rng.uniform(0, 1) > 0 ? CV_8UC1 : CV_8UC3;\n 1348          Mat image(ssize, type);\n 1349          rng.fill(image, RNG::UNIFORM, 0, 256, true);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\photo\\include\\opencv2\\photo\\cuda.hpp:\n   53  /** @brief Performs pure non local means denoising without any simplification, and thus it is not fast.\n   54  \n   55: @param src Source image. Supports only CV_8UC1, CV_8UC2 and CV_8UC3.\n   56  @param dst Destination image.\n   57  @param h Filter sigma regulating filter strength for color.\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\photo\\perf\\perf_inpaint.cpp:\n   24      int inpaintingMethod = get<1>(GetParam());\n   25  \n   26:     Mat mask(src.size(), CV_8UC1, Scalar(0));\n   27      Mat result(src.size(), src.type());\n   28  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\photo\\src\\align.cpp:\n  230      void downsample(Mat& src, Mat& dst)\n  231      {\n  232:         dst = Mat(src.rows / 2, src.cols / 2, CV_8UC1);\n  233  \n  234          int offset = src.cols * 2;\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\photo\\src\\contrast_preserve.cpp:\n   56  \n   57      Mat I = _src.getMat();\n   58:     _dst.create(I.size(), CV_8UC1);\n   59      Mat dst = _dst.getMat();\n   60  \n   ..\n  183      obj.grayImContruct(wei, img, Gray);\n  184  \n  185:     Gray.convertTo(dst,CV_8UC1,255);\n  186  \n  187      ///////////////////////////////////       Contrast Boosting   /////////////////////////////////\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\photo\\src\\inpaint.cpp:\n  757          \"8-bit, 16-bit unsigned or 32-bit float 1-channel and 8-bit 3-channel input/output images are supported\" );\n  758  \n  759:     if( CV_MAT_TYPE(inpaint_mask->type) != CV_8UC1 )\n  760          CV_Error( CV_StsUnsupportedFormat, \"The mask must be 8-bit 1-channel image\" );\n  761  \n  ...\n  766      erows = input_img->rows + 2;\n  767  \n  768:     f.reset(cvCreateMat(erows, ecols, CV_8UC1));\n  769      t.reset(cvCreateMat(erows, ecols, CV_32FC1));\n  770:     band.reset(cvCreateMat(erows, ecols, CV_8UC1));\n  771:     mask.reset(cvCreateMat(erows, ecols, CV_8UC1));\n  772      el_cross.reset(cvCreateStructuringElementEx(3,3,1,1,CV_SHAPE_CROSS,NULL));\n  773  \n  ...\n  792      if( flags == cv::INPAINT_TELEA )\n  793      {\n  794:         out.reset(cvCreateMat(erows, ecols, CV_8UC1));\n  795          el_range.reset(cvCreateStructuringElementEx(2*range+1,2*range+1,\n  796              range,range,CV_SHAPE_RECT,NULL));\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\photo\\src\\npr.cpp:\n  126  \n  127      Mat I = _src.getMat();\n  128:     _dst1.create(I.size(), CV_8UC1);\n  129      Mat dst1 = _dst1.getMat();\n  130  \n  ...\n  142      obj.pencil_sketch(img, sketch, color_sketch, sigma_s, sigma_r, shade_factor);\n  143  \n  144:     sketch.convertTo(dst1,CV_8UC1,255);\n  145      color_sketch.convertTo(dst2,CV_8UC3,255);\n  146  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\photo\\src\\seamless_cloning.cpp:\n   63      int w = mask.size().width;\n   64  \n   65:     Mat gray = Mat(mask.size(),CV_8UC1);\n   66  \n   67      if(mask.channels() == 3)\n   ..\n  123      float blue = b;\n  124  \n  125:     Mat gray = Mat::zeros(mask.size(),CV_8UC1);\n  126  \n  127      if(mask.channels() == 3)\n  ...\n  150      float beta = b;\n  151  \n  152:     Mat gray = Mat::zeros(mask.size(),CV_8UC1);\n  153  \n  154      if(mask.channels() == 3)\n  ...\n  177      Mat blend = _dst.getMat();\n  178  \n  179:     Mat gray = Mat::zeros(mask.size(),CV_8UC1);\n  180  \n  181      if(mask.channels() == 3)\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\photo\\src\\seamless_cloning_impl.cpp:\n  271      computeGradientY(patch,patchGradientY);\n  272  \n  273:     Mat Kernel(Size(3, 3), CV_8UC1);\n  274      Kernel.setTo(Scalar(1));\n  275      erode(binaryMask, binaryMask, Kernel, Point(-1,-1), 3);\n  ...\n  391  \n  392          case MONOCHROME_TRANSFER:\n  393:             Mat gray = Mat(patch.size(),CV_8UC1);\n  394              cvtColor(patch, gray, COLOR_BGR2GRAY );\n  395  \n  ...\n  456      computeDerivatives(I,mask,wmask);\n  457  \n  458:     Mat out = Mat(mask.size(),CV_8UC1);\n  459      Canny(mask,out,low_threshold,high_threshold,kernel_size);\n  460  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\photo\\test\\test_denoising.cpp:\n  149  TEST(Photo_White, issue_2646)\n  150  {\n  151:     cv::Mat img(50, 50, CV_8UC1, cv::Scalar::all(255));\n  152      cv::Mat filtered;\n  153      cv::fastNlMeansDenoising(img, filtered);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\python\\src2\\cv2.cpp:\n 1807  \n 1808    PUBLISH(CV_8U);\n 1809:   PUBLISH(CV_8UC1);\n 1810    PUBLISH(CV_8UC2);\n 1811    PUBLISH(CV_8UC3);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\stitching\\perf\\opencl\\perf_warpers.cpp:\n  109  static void prepareWarperSrc(InputOutputArray src, Size srcSize)\n  110  {\n  111:     src.create(srcSize, CV_8UC1);\n  112      src.setTo(Scalar::all(64));\n  113      ellipse(src, Point(srcSize.width/2, srcSize.height/2), Size(srcSize.width/2, srcSize.height/2),\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\stitching\\src\\matchers.cpp:\n  455  {\n  456      UMat gray_image;\n  457:     CV_Assert((image.type() == CV_8UC3) || (image.type() == CV_8UC1));\n  458      if(image.type() == CV_8UC3)\n  459      {\n  ...\n  487      UMat gray_image;\n  488  \n  489:     CV_Assert((image.type() == CV_8UC3) || (image.type() == CV_8UC4) || (image.type() == CV_8UC1));\n  490  \n  491      if (image.type() == CV_8UC3) {\n  ...\n  493      } else if (image.type() == CV_8UC4) {\n  494          cvtColor(image, gray_image, COLOR_BGRA2GRAY);\n  495:     } else if (image.type() == CV_8UC1) {\n  496          gray_image = image.getUMat();\n  497      } else {\n  ...\n  562  void AKAZEFeaturesFinder::find(InputArray image, detail::ImageFeatures &features)\n  563  {\n  564:     CV_Assert((image.type() == CV_8UC3) || (image.type() == CV_8UC1));\n  565      akaze->detectAndCompute(image, noArray(), features.keypoints, features.descriptors);\n  566  }\n  ...\n  587      image_.upload(image);\n  588  \n  589:     ensureSizeIsEnough(image.size(), CV_8UC1, gray_image_);\n  590  \n  591  #ifdef HAVE_OPENCV_CUDAIMGPROC\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\superres\\perf\\perf_superres.cpp:\n  120  PERF_TEST_P(Size_MatType, SuperResolution_BTVL1,\n  121              Combine(Values(szSmall64, szSmall128),\n  122:                     Values(MatType(CV_8UC1), MatType(CV_8UC3))))\n  123  {\n  124      declare.time(5 * 60);\n  ...\n  182  OCL_PERF_TEST_P(SuperResolution_BTVL1 ,BTVL1,\n  183              Combine(Values(szSmall64, szSmall128),\n  184:                     Values(MatType(CV_8UC1), MatType(CV_8UC3))))\n  185  {\n  186      Size_MatType_t params = GetParam();\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\superres\\src\\optical_flow.cpp:\n  208      };\n  209  \n  210:     Farneback::Farneback() : CpuOpticalFlow(CV_8UC1)\n  211      {\n  212          pyrScale_ = 0.5;\n  ...\n  360      };\n  361  \n  362:     DualTVL1::DualTVL1() : CpuOpticalFlow(CV_8UC1)\n  363      {\n  364          alg_ = cv::createOptFlow_DualTVL1();\n  ...\n  595      };\n  596  \n  597:     PyrLK_CUDA::PyrLK_CUDA() : GpuOpticalFlow(CV_8UC1)\n  598      {\n  599          alg_ = cuda::DensePyrLKOpticalFlow::create();\n  ...\n  672      };\n  673  \n  674:     Farneback_CUDA::Farneback_CUDA() : GpuOpticalFlow(CV_8UC1)\n  675      {\n  676          alg_ = cuda::FarnebackOpticalFlow::create();\n  ...\n  759      };\n  760  \n  761:     DualTVL1_CUDA::DualTVL1_CUDA() : GpuOpticalFlow(CV_8UC1)\n  762      {\n  763          alg_ = cuda::OpticalFlowDual_TVL1::create();\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\ts\\include\\opencv2\\ts\\ocl_perf.hpp:\n   89  \n   90  #define OCL_TEST_SIZES ::testing::Values(OCL_SIZE_1, OCL_SIZE_2, OCL_SIZE_3, OCL_SIZE_4)\n   91: #define OCL_TEST_TYPES ::testing::Values(CV_8UC1, CV_32FC1, CV_8UC4, CV_32FC4)\n   92  #define OCL_TEST_TYPES_14 OCL_TEST_TYPES\n   93: #define OCL_TEST_TYPES_134 ::testing::Values(CV_8UC1, CV_32FC1, CV_8UC3, CV_32FC3, CV_8UC4, CV_32FC4)\n   94  \n   95  #define OCL_PERF_ENUM ::testing::Values\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\ts\\include\\opencv2\\ts\\ocl_test.hpp:\n  133      Size _wholeSize; \\\n  134      u ## name ## _roi.locateROI(_wholeSize, _offset); \\\n  135:     Mat _mask(name.size(), CV_8UC1, Scalar::all(255)); \\\n  136      _mask(Rect(_offset, name ## _roi.size())).setTo(Scalar::all(0)); \\\n  137      ASSERT_EQ(name.type(), u ## name.type()); \\\n  ...\n  151      Size _wholeSize; \\\n  152      name ## _roi.locateROI(_wholeSize, _offset); \\\n  153:     Mat _mask(name.size(), CV_8UC1, Scalar::all(255)); \\\n  154      _mask(Rect(_offset, name ## _roi.size())).setTo(Scalar::all(0)); \\\n  155      ASSERT_EQ(name.type(), u ## name.type()); \\\n  ...\n  170      Size _wholeSize; \\\n  171      name ## _roi.locateROI(_wholeSize, _offset); \\\n  172:     Mat _mask(name.size(), CV_8UC1, Scalar::all(255)); \\\n  173      _mask(Rect(_offset, name ## _roi.size())).setTo(Scalar::all(0)); \\\n  174      ASSERT_EQ(name.type(), u ## name.type()); \\\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\ts\\include\\opencv2\\ts\\ts_perf.hpp:\n   81  \n   82  #define TYPICAL_MAT_SIZES ::perf::szVGA, ::perf::sz720p, ::perf::sz1080p, ::perf::szODD\n   83: #define TYPICAL_MAT_TYPES CV_8UC1, CV_8UC4, CV_32FC1\n   84  #define TYPICAL_MATS testing::Combine( testing::Values( TYPICAL_MAT_SIZES ), testing::Values( TYPICAL_MAT_TYPES ) )\n   85: #define TYPICAL_MATS_C1 testing::Combine( testing::Values( TYPICAL_MAT_SIZES ), testing::Values( CV_8UC1, CV_32FC1 ) )\n   86  #define TYPICAL_MATS_C4 testing::Combine( testing::Values( TYPICAL_MAT_SIZES ), testing::Values( CV_8UC4 ) )\n   87  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\ts\\src\\ocl_test.cpp:\n  285          if (sz1 == 0 && sz2 == 0)\n  286              return 0;\n  287:         cv::Mat cpu_result(sz, CV_8UC1);\n  288          cpu_result.setTo(0);\n  289  \n  ...\n  296          int cpu_area = cv::countNonZero(cpu_result > 0);\n  297  \n  298:         cv::Mat gpu_result(sz, CV_8UC1);\n  299          gpu_result.setTo(0);\n  300          for(vector<Rect>::const_iterator r2 = ob2.begin(); r2 != ob2.end(); ++r2)\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\ts\\src\\ts_arrtest.cpp:\n  118          {\n  119              sizes[i][j] = size;\n  120:             types[i][j] = CV_8UC1;\n  121          }\n  122      }\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\video\\perf\\opencl\\perf_motempl.cpp:\n   23      checkDeviceMaxMemoryAllocSize(size, CV_32FC1);\n   24  \n   25:     UMat silhouette(size, CV_8UC1), mhi(size, CV_32FC1);\n   26      randu(silhouette, -5, 5);\n   27      declare.in(mhi, WARMUP_RNG);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\video\\src\\bgfg_gaussmix2.cpp:\n  220  \n  221              //make the array for keeping track of the used modes per pixel - all zeros at start\n  222:             u_bgmodelUsedModes.create(frameSize, CV_8UC1);\n  223              u_bgmodelUsedModes.setTo(cv::Scalar::all(0));\n  224          }\n  ...\n  922  void BackgroundSubtractorMOG2Impl::getBackgroundImage(OutputArray backgroundImage) const\n  923  {\n  924:     CV_Assert(frameType == CV_8UC1 || frameType == CV_8UC3 || frameType == CV_32FC1 || frameType == CV_32FC3);\n  925  \n  926  #ifdef HAVE_OPENCL\n  ...\n  935      switch(frameType)\n  936      {\n  937:     case CV_8UC1:\n  938          getBackgroundImage_intern<uchar,1>(backgroundImage);\n  939          break;\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\video\\src\\ecc.cpp:\n  341  \n  342      //accept only 1-channel images\n  343:     if( src.type() != CV_8UC1 && src.type()!= CV_32FC1)\n  344          CV_Error( Error::StsUnsupportedFormat, \"Images must have 8uC1 or 32fC1 type\");\n  345  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\video\\src\\lkpyramid.cpp:\n 1062              umatErr.create((int)npoints, 1, CV_32FC1);\n 1063  \n 1064:         _status.create((int)npoints, 1, CV_8UC1);\n 1065          UMat umatNextPts = _nextPts.getUMat();\n 1066          UMat umatStatus = _status.getUMat();\n ....\n 1082          Mat prevImgMat = _prevImg.getMat(), nextImgMat = _nextImg.getMat();\n 1083  \n 1084:         if(prevImgMat.type() != CV_8UC1 || nextImgMat.type() != CV_8UC1)\n 1085              return false;\n 1086  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\video\\src\\tvl1flow.cpp:\n  400      Mat I1 = _I1.getMat();\n  401  \n  402:     CV_Assert( I0.type() == CV_8UC1 || I0.type() == CV_32FC1 );\n  403      CV_Assert( I0.size() == I1.size() );\n  404      CV_Assert( I0.type() == I1.type() );\n  ...\n  526      UMat I1 = _I1.getUMat();\n  527  \n  528:     CV_Assert(I0.type() == CV_8UC1 || I0.type() == CV_32FC1);\n  529      CV_Assert(I0.size() == I1.size());\n  530      CV_Assert(I0.type() == I1.type());\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\videoio\\include\\opencv2\\videoio.hpp:\n  253  enum { CAP_OPENNI_DEPTH_MAP         = 0, //!< Depth values in mm (CV_16UC1)\n  254         CAP_OPENNI_POINT_CLOUD_MAP   = 1, //!< XYZ in meters (CV_32FC3)\n  255:        CAP_OPENNI_DISPARITY_MAP     = 2, //!< Disparity in pixels (CV_8UC1)\n  256         CAP_OPENNI_DISPARITY_MAP_32F = 3, //!< Disparity in pixels (CV_32FC1)\n  257:        CAP_OPENNI_VALID_DEPTH_MASK  = 4, //!< CV_8UC1\n  258  \n  259         CAP_OPENNI_BGR_IMAGE         = 5, //!< Data given from RGB image generator\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\videoio\\include\\opencv2\\videoio\\videoio_c.h:\n  468      CV_CAP_OPENNI_DEPTH_MAP                 = 0, // Depth values in mm (CV_16UC1)\n  469      CV_CAP_OPENNI_POINT_CLOUD_MAP           = 1, // XYZ in meters (CV_32FC3)\n  470:     CV_CAP_OPENNI_DISPARITY_MAP             = 2, // Disparity in pixels (CV_8UC1)\n  471      CV_CAP_OPENNI_DISPARITY_MAP_32F         = 3, // Disparity in pixels (CV_32FC1)\n  472:     CV_CAP_OPENNI_VALID_DEPTH_MASK          = 4, // CV_8UC1\n  473  \n  474      // Data given from RGB image generator.\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\videoio\\src\\cap_gphoto2.cpp:\n 1006      if (size > 0)\n 1007      {\n 1008:         Mat buf = Mat(1, size, CV_8UC1, (void *) data);\n 1009          if(!buf.empty())\n 1010          {\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\videoio\\src\\cap_openni.cpp:\n 1244      computeDisparity_32F( depthMetaData, disp32, baseline, depthFocalLength_VGA, noSampleValue, shadowValue );\n 1245  \n 1246:     disp32.convertTo( outputMaps[CV_CAP_OPENNI_DISPARITY_MAP].mat, CV_8UC1 );\n 1247  \n 1248      return outputMaps[CV_CAP_OPENNI_DISPARITY_MAP].getIplImagePtr();\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\videoio\\src\\cap_openni2.cpp:\n  938      computeDisparity_32F(streamFrames[CV_DEPTH_STREAM], disp32, baseline, depthFocalLength_VGA, noSampleValue, shadowValue);\n  939  \n  940:     disp32.convertTo( outputMaps[CV_CAP_OPENNI_DISPARITY_MAP].mat, CV_8UC1 );\n  941  \n  942      return outputMaps[CV_CAP_OPENNI_DISPARITY_MAP].getIplImagePtr();\n  ...\n  983      if (imageMetaData.getVideoMode().getPixelFormat() == openni::PIXEL_FORMAT_GRAY8)\n  984      {\n  985:         grayImage.create(imageMetaData.getHeight(), imageMetaData.getWidth(), CV_8UC1);\n  986          grayImage.data = (uchar*)imageMetaData.getData();\n  987      }\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\modules\\videostab\\src\\global_motion.cpp:\n  788      : ImageMotionEstimatorBase(estimator->motionModel()), motionEstimator_(estimator)\n  789  {\n  790:     detector_ = cuda::createGoodFeaturesToTrackDetector(CV_8UC1);\n  791  \n  792      CV_Assert(cuda::getCudaEnabledDeviceCount() > 0);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\cpp\\cloning_gui.cpp:\n  139  \n  140          final = Mat::zeros(img0.size(),CV_8UC3);\n  141:         res1 = Mat::zeros(img0.size(),CV_8UC1);\n  142          const Point* pts4[1] = {&pts[0]};\n  143  \n  ...\n  236  \n  237          final1 = Mat::zeros(img2.size(),CV_8UC3);\n  238:         res = Mat::zeros(img2.size(),CV_8UC1);\n  239          for(int i=miny, k=minyd;i<(miny+leny);i++,k++)\n  240              for(int j=minx,l=minxd ;j<(minx+lenx);j++,l++)\n  ...\n  333          channel = img0.channels();\n  334  \n  335:         res = Mat::zeros(img2.size(),CV_8UC1);\n  336:         res1 = Mat::zeros(img0.size(),CV_8UC1);\n  337          final = Mat::zeros(img0.size(),CV_8UC3);\n  338          final1 = Mat::zeros(img2.size(),CV_8UC3);\n  ...\n  374          }\n  375  \n  376:         res1 = Mat::zeros(img0.size(),CV_8UC1);\n  377          final = Mat::zeros(img0.size(),CV_8UC3);\n  378  \n  ...\n  404          }\n  405  \n  406:         res1 = Mat::zeros(img0.size(),CV_8UC1);\n  407          final = Mat::zeros(img0.size(),CV_8UC3);\n  408  \n  ...\n  437          }\n  438  \n  439:         res1 = Mat::zeros(img0.size(),CV_8UC1);\n  440          final = Mat::zeros(img0.size(),CV_8UC3);\n  441  \n  ...\n  492  \n  493              final = Mat::zeros(img0.size(),CV_8UC3);\n  494:             res1 = Mat::zeros(img0.size(),CV_8UC1);\n  495              const Point* pts4[1] = {&pts[0]};\n  496  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\cpp\\contours2.cpp:\n   42          return 0;\n   43      }\n   44:     Mat img = Mat::zeros(w, w, CV_8UC1);\n   45      //Draw 6 faces\n   46      for( int i = 0; i < 6; i++ )\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\cpp\\create_mask.cpp:\n   94  \n   95          final = Mat::zeros(img0.size(),CV_8UC3);\n   96:         res1 = Mat::zeros(img0.size(),CV_8UC1);\n   97          const Point* pts4[1] = {&pts[0]};\n   98  \n   ..\n  150      img0 = src;\n  151  \n  152:     res1 = Mat::zeros(img0.size(),CV_8UC1);\n  153      final = Mat::zeros(img0.size(),CV_8UC3);\n  154      //////////// source image ///////////////////\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\cpp\\detect_blob.cpp:\n   69  {\n   70      vector<String> fileName;\n   71:     Mat img(600, 800, CV_8UC1);\n   72      cv::CommandLineParser parser(argc, argv, \"{@input |../data/detect_blob.png| }{h help | | }\");\n   73      if (parser.has(\"h\"))\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\cpp\\detect_mser.cpp:\n  219  {\n  220      Mat imgGray;\n  221:     if (img.type() != CV_8UC1)\n  222          cvtColor(img, imgGray, COLOR_BGR2GRAY);\n  223      else\n  ...\n  335  static Mat MakeSyntheticImage()\n  336  {\n  337:     Mat img(800, 800, CV_8UC1);\n  338      map<int, char> val;\n  339      int fond = 0;\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\cpp\\example_cmake\\example.cpp:\n   33      {\n   34          cout << \"No capture\" << endl;\n   35:         image = Mat::zeros(480, 640, CV_8UC1);\n   36          drawText(image);\n   37          imshow(\"Sample\", image);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\cpp\\falsecolor.cpp:\n   39  static Mat DrawMyImage(int thickness,int nbShape)\n   40  {\n   41:     Mat img=Mat::zeros(500,256*thickness+100,CV_8UC1);\n   42      int offsetx = 50, offsety = 25;\n   43      int lineLenght = 50;\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\cpp\\ffilldemo.cpp:\n   94      image0.copyTo(image);\n   95      cvtColor(image0, gray, COLOR_BGR2GRAY);\n   96:     mask.create(image0.rows+2, image0.cols+2, CV_8UC1);\n   97  \n   98      namedWindow( \"image\", 0 );\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\cpp\\grabcut.cpp:\n   40  static void getBinMask( const Mat& comMask, Mat& binMask )\n   41  {\n   42:     if( comMask.empty() || comMask.type()!=CV_8UC1 )\n   43:         CV_Error( Error::StsBadArg, \"comMask is empty or has incorrect type (not CV_8UC1)\" );\n   44      if( binMask.empty() || binMask.rows!=comMask.rows || binMask.cols!=comMask.cols )\n   45:         binMask.create( comMask.size(), CV_8UC1 );\n   46      binMask = comMask & 1;\n   47  }\n   ..\n   97      image = &_image;\n   98      winName = &_winName;\n   99:     mask.create( image->size(), CV_8UC1);\n  100      reset();\n  101  }\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\cpp\\intelperc_capture.cpp:\n  189      else\n  190      {\n  191:         image.create(ir.rows, ir.cols, CV_8UC1);\n  192          for (int row = 0; row < ir.rows; row++)\n  193          {\n  ...\n  246      else\n  247      {\n  248:         image.create(depth.rows, depth.cols, CV_8UC1);\n  249          for (int row = 0; row < depth.rows; row++)\n  250          {\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\cpp\\openni_capture.cpp:\n   16              \"   CAP_OPENNI_DEPTH_MAP            - depth values in mm (CV_16UC1)\\n\"\n   17              \"   CAP_OPENNI_POINT_CLOUD_MAP      - XYZ in meters (CV_32FC3)\\n\"\n   18:             \"   CAP_OPENNI_DISPARITY_MAP        - disparity in pixels (CV_8UC1)\\n\"\n   19              \"   CAP_OPENNI_DISPARITY_MAP_32F    - disparity in pixels (CV_32FC1)\\n\"\n   20:             \"   CAP_OPENNI_VALID_DEPTH_MASK     - mask of valid pixels (not ocluded, not shaded etc.) (CV_8UC1)\\n\"\n   21              \"2.) Data given from RGB image generator\\n\"\n   22              \"   CAP_OPENNI_BGR_IMAGE            - color image (CV_8UC3)\\n\"\n   23:             \"   CAP_OPENNI_GRAY_IMAGE           - gray image (CV_8UC1)\\n\"\n   24              \"2.) Data given from IR image generator\\n\"\n   25              \"   CAP_OPENNI_IR_IMAGE             - gray image (CV_16UC1)\\n\"\n   ..\n   30  {\n   31      CV_Assert( !gray.empty() );\n   32:     CV_Assert( gray.type() == CV_8UC1 );\n   33  \n   34      if( maxDisp <= 0 )\n   ..\n  270              {\n  271                  const float scaleFactor = 0.05f;\n  272:                 Mat show; depthMap.convertTo( show, CV_8UC1, scaleFactor );\n  273                  imshow( \"depth map\", show );\n  274              }\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\cpp\\pca.cpp:\n   84      // create and return normalized image\n   85      Mat dst;\n   86:     cv::normalize(_src, dst, 0, 255, NORM_MINMAX, CV_8UC1);\n   87      return dst;\n   88  }\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\cpp\\stitching_detailed.cpp:\n  865          if (timelapse)\n  866          {\n  867:             timelapser->process(img_warped_s, Mat::ones(img_warped_s.size(), CV_8UC1), corners[img_idx]);\n  868              String fixedFileName;\n  869              size_t pos_s = String(img_names[img_idx]).find_last_of(\"/\\\\\");\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\cpp\\tutorial_code\\calib3d\\stereoBM\\SBM_Sample.cpp:\n   29    //-- And create the image in which we will save our disparities\n   30    Mat imgDisparity16S = Mat( imgLeft.rows, imgLeft.cols, CV_16S );\n   31:   Mat imgDisparity8U = Mat( imgLeft.rows, imgLeft.cols, CV_8UC1 );\n   32  \n   33    if( imgLeft.empty() || imgRight.empty() )\n   ..\n   50    printf(\"Min disp: %f Max value: %f \\n\", minVal, maxVal);\n   51  \n   52:   //-- 4. Display it as a CV_8UC1 image\n   53:   imgDisparity16S.convertTo( imgDisparity8U, CV_8UC1, 255/(maxVal - minVal));\n   54  \n   55    namedWindow( windowDisparity, WINDOW_NORMAL );\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\cpp\\tutorial_code\\core\\mat_the_basic_image_container\\mat_the_basic_image_container.cpp:\n   50      Mat O = Mat::ones(2, 2, CV_32F);\n   51      cout << \"O = \" << endl << \" \" << O << endl << endl;\n   52:     Mat Z = Mat::zeros(3,3, CV_8UC1);\n   53      cout << \"Z = \" << endl << \" \" << Z << endl << endl;\n   54      //! [matlab]\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\cpp\\tutorial_code\\features2D\\AKAZE_tracking\\planar_tracking.cpp:\n   51      }\n   52      first_frame = frame.clone();\n   53:     cv::Mat matMask = cv::Mat::zeros(frame.size(), CV_8UC1);\n   54      cv::fillPoly(matMask, &ptContain, &iSize, 1, cv::Scalar::all(255));\n   55      detector->detectAndCompute(first_frame, matMask, first_kp, first_desc);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\cpp\\tutorial_code\\Histograms_Matching\\calcBackProject_Demo2.cpp:\n   66    int flags = connectivity + (newMaskVal << 8 ) + FLOODFILL_FIXED_RANGE + FLOODFILL_MASK_ONLY;\n   67  \n   68:   Mat mask2 = Mat::zeros( src.rows + 2, src.cols + 2, CV_8UC1 );\n   69    floodFill( src, mask2, seed, newVal, 0, Scalar( lo, lo, lo ), Scalar( up, up, up), flags );\n   70    mask = mask2( Range( 1, mask2.rows - 1 ), Range( 1, mask2.cols - 1 ) );\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\cpp\\tutorial_code\\ImgProc\\morph_lines_detection\\Morphology_3.cpp:\n  109  \n  110      // Step 2\n  111:     Mat kernel = Mat::ones(2, 2, CV_8UC1);\n  112      dilate(edges, edges, kernel);\n  113      show_wait_destroy(\"dilate\", edges);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\cpp\\tutorial_code\\ImgTrans\\imageSegmentation.cpp:\n   96  \n   97      // Dilate a bit the dist image\n   98:     Mat kernel1 = Mat::ones(3, 3, CV_8UC1);\n   99      dilate(dist, dist, kernel1);\n  100      imshow(\"Peaks\", dist);\n  ...\n  127      watershed(src, markers);\n  128  \n  129:     Mat mark = Mat::zeros(markers.size(), CV_8UC1);\n  130:     markers.convertTo(mark, CV_8UC1);\n  131      bitwise_not(mark, mark);\n  132  //    imshow(\"Markers_v2\", mark); // uncomment this if you want to see how the mark\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\cpp\\tutorial_code\\photo\\decolorization\\decolor.cpp:\n   31      src = imread(argv[1], IMREAD_COLOR);\n   32  \n   33:     Mat gray = Mat(src.size(),CV_8UC1);\n   34      Mat color_boost = Mat(src.size(),CV_8UC3);\n   35  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\cpp\\tutorial_code\\photo\\seamless_cloning\\cloning_gui.cpp:\n  138  \n  139          final = Mat::zeros(img0.size(),CV_8UC3);\n  140:         res1 = Mat::zeros(img0.size(),CV_8UC1);\n  141          const Point* pts4[1] = {&pts[0]};\n  142  \n  ...\n  235  \n  236          final1 = Mat::zeros(img2.size(),CV_8UC3);\n  237:         res = Mat::zeros(img2.size(),CV_8UC1);\n  238          for(int i=miny, k=minyd;i<(miny+leny);i++,k++)\n  239              for(int j=minx,l=minxd ;j<(minx+lenx);j++,l++)\n  ...\n  332          channel = img0.channels();\n  333  \n  334:         res = Mat::zeros(img2.size(),CV_8UC1);\n  335:         res1 = Mat::zeros(img0.size(),CV_8UC1);\n  336          final = Mat::zeros(img0.size(),CV_8UC3);\n  337          final1 = Mat::zeros(img2.size(),CV_8UC3);\n  ...\n  373          }\n  374  \n  375:         res1 = Mat::zeros(img0.size(),CV_8UC1);\n  376          final = Mat::zeros(img0.size(),CV_8UC3);\n  377  \n  ...\n  403          }\n  404  \n  405:         res1 = Mat::zeros(img0.size(),CV_8UC1);\n  406          final = Mat::zeros(img0.size(),CV_8UC3);\n  407  \n  ...\n  436          }\n  437  \n  438:         res1 = Mat::zeros(img0.size(),CV_8UC1);\n  439          final = Mat::zeros(img0.size(),CV_8UC3);\n  440  \n  ...\n  491  \n  492              final = Mat::zeros(img0.size(),CV_8UC3);\n  493:             res1 = Mat::zeros(img0.size(),CV_8UC1);\n  494              const Point* pts4[1] = {&pts[0]};\n  495  \n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\cpp\\tutorial_code\\ShapeDescriptors\\pointPolygonTest_demo.cpp:\n   19    /// Create an image\n   20    const int r = 100;\n   21:   Mat src = Mat::zeros( Size( 4*r, 4*r ), CV_8UC1 );\n   22  \n   23    /// Create a sequence of points to make a contour:\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\directx\\d3d11_interop.cpp:\n  336                          }\n  337  \n  338:                         cv::Mat frame_nv12(m_height + (m_height / 2), m_width, CV_8UC1, mappedTex.pData, mappedTex.RowPitch);\n  339                          cv::cvtColor(frame_nv12, m_frame_rgba, CV_YUV2RGBA_NV12);\n  340  \n  ...\n  416      void convert_I420_to_NV12(cv::Mat& i420, cv::Mat& nv12, int width, int height)\n  417      {\n  418:         nv12.create(i420.rows, i420.cols, CV_8UC1);\n  419  \n  420          unsigned char* pSrcY = i420.data;\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\dnn\\fcn_semsegm.cpp:\n   51      const int chns = score.size[1];\n   52  \n   53:     cv::Mat maxCl=cv::Mat::zeros(rows, cols, CV_8UC1);\n   54      cv::Mat maxVal(rows, cols, CV_32FC1, cv::Scalar(-FLT_MAX));\n   55      for (int ch = 0; ch < chns; ch++)\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\dnn\\torch_enet.cpp:\n  130      const int chns = score.size[1];\n  131  \n  132:     cv::Mat maxCl(rows, cols, CV_8UC1);\n  133      cv::Mat maxVal(rows, cols, CV_32FC1);\n  134      for (int ch = 0; ch < chns; ch++)\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\gpu\\performance\\tests.cpp:\n  607      cuda::GpuMat d_src, d_dst;\n  608  \n  609:     gen(src, 4000, 4000, CV_8UC1, 0, 255);\n  610      d_src.upload(src);\n  611  \n  ...\n 1042          Mat src, dst;\n 1043  \n 1044:         gen(src, size, size, CV_8UC1, 0, 256);\n 1045  \n 1046          equalizeHist(src, dst);\n ....\n 1068      if (img.empty()) throw runtime_error(\"can't open ../data/aloeL.jpg\");\n 1069  \n 1070:     Mat edges(img.size(), CV_8UC1);\n 1071  \n 1072      CPU_ON;\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\gpu\\pyrlk_optical_flow.cpp:\n   25  {\n   26      vec.resize(d_mat.cols);\n   27:     Mat mat(1, d_mat.cols, CV_8UC1, (void*)&vec[0]);\n   28      d_mat.download(mat);\n   29  }\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\gpu\\stereo_multi.cpp:\n  218  void StereoMultiGpuThread::compute(const Mat& leftFrame, const Mat& rightFrame, Mat& disparity)\n  219  {\n  220:     disparity.create(leftFrame.size(), CV_8UC1);\n  221  \n  222      // Split input data onto two parts for each GPUs.\n  ...\n  317  void StereoMultiGpuStream::compute(const HostMem& leftFrame, const HostMem& rightFrame, HostMem& disparity)\n  318  {\n  319:     disparity.create(leftFrame.size(), CV_8UC1);\n  320  \n  321      // Split input data onto two parts for each GPUs.\n  ...\n  439          }\n  440  \n  441:         leftGrayFrame.create(leftFrame.size(), CV_8UC1);\n  442:         rightGrayFrame.create(leftFrame.size(), CV_8UC1);\n  443  \n  444          cvtColor(leftFrame, leftGrayFrame.createMatHeader(), COLOR_BGR2GRAY);\n\nc:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master\\samples\\winrt\\ImageManipulations\\MediaExtensions\\OcvTransform\\OcvTransform.cpp:\n 1312      }\n 1313  \n 1314:     cv::Mat InputFrame(m_imageHeightInPixels + m_imageHeightInPixels/2, m_imageWidthInPixels, CV_8UC1, pSrc, lSrcStride);\n 1315      cv::Mat InputGreyScale(InputFrame, cv::Range(0, m_imageHeightInPixels), cv::Range(0, m_imageWidthInPixels));\n 1316:     cv::Mat OutputFrame(m_imageHeightInPixels + m_imageHeightInPixels/2, m_imageWidthInPixels, CV_8UC1, pDest, lDestStride);\n 1317  \n 1318      switch (m_TransformType)\n ....\n 1352              const cv::Scalar mColorsUV[] = { cv::Scalar(84, 255), cv::Scalar(43, 21), cv::Scalar(255, 107) };\n 1353  \n 1354:             cv::Mat OutputY(m_imageHeightInPixels, m_imageWidthInPixels, CV_8UC1, pDest, lDestStride);\n 1355              cv::Mat OutputUV(m_imageHeightInPixels/2, m_imageWidthInPixels/2,\n 1356                               CV_8UC2, pDest+m_imageHeightInPixels*lDestStride, lDestStride);\n\n1059 matches across 303 files\n",
			"settings":
			{
				"buffer_size": 414157,
				"line_ending": "Windows",
				"name": "Find Results",
				"scratch": true
			}
		},
		{
			"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/opencv/modules/core/include/opencv2/core/hal/interface.h",
			"settings":
			{
				"buffer_size": 4430,
				"line_ending": "Unix"
			}
		},
		{
			"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/projects/oled/settings.py",
			"settings":
			{
				"buffer_size": 6128,
				"encoding": "UTF-8",
				"line_ending": "Unix"
			}
		},
		{
			"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/projects/raspicamtest/raspicamtest.cpp",
			"settings":
			{
				"buffer_size": 2179,
				"line_ending": "Unix"
			}
		},
		{
			"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/projects/oled/checkface.cpp",
			"settings":
			{
				"buffer_size": 5621,
				"encoding": "UTF-8",
				"line_ending": "Unix"
			}
		},
		{
			"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/opencv/modules/core/include/opencv2/core/mat.hpp",
			"settings":
			{
				"buffer_size": 153793,
				"line_ending": "Unix"
			}
		},
		{
			"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/raspi.ida",
			"settings":
			{
				"buffer_size": 8778,
				"encoding": "UTF-8",
				"line_ending": "Windows"
			}
		},
		{
			"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/opencv/modules/imgproc/src/histogram.cpp",
			"settings":
			{
				"buffer_size": 132073,
				"line_ending": "Unix"
			}
		},
		{
			"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/raspicam/src/raspicam_cv.h",
			"settings":
			{
				"buffer_size": 4142,
				"line_ending": "Unix"
			}
		},
		{
			"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/projects/seeface/seeface.cpp",
			"settings":
			{
				"buffer_size": 5568,
				"encoding": "UTF-8",
				"line_ending": "Unix"
			}
		},
		{
			"file": "raspicam/src/raspicam_still.h",
			"settings":
			{
				"buffer_size": 4525,
				"line_ending": "Unix"
			}
		},
		{
			"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/raspicam/src/raspicam_cv.cpp",
			"settings":
			{
				"buffer_size": 7836,
				"line_ending": "Unix"
			}
		},
		{
			"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/raspicam/src/private/private_impl.cpp",
			"settings":
			{
				"buffer_size": 33554,
				"line_ending": "Unix"
			}
		},
		{
			"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/raspicam/src/private/private_impl.h",
			"settings":
			{
				"buffer_size": 10775,
				"line_ending": "Unix"
			}
		},
		{
			"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/projects/raspicam/src/raspicamtypes.h",
			"settings":
			{
				"buffer_size": 4622,
				"line_ending": "Unix"
			}
		},
		{
			"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/opencv/modules/objdetect/src/cascadedetect.cpp",
			"settings":
			{
				"buffer_size": 57785,
				"line_ending": "Unix"
			}
		},
		{
			"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/raspicam/src/raspicam_still_cv.h",
			"settings":
			{
				"buffer_size": 4170,
				"line_ending": "Unix"
			}
		},
		{
			"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/raspicam/src/raspicam.h",
			"settings":
			{
				"buffer_size": 7042,
				"line_ending": "Unix"
			}
		}
	],
	"build_system": "",
	"build_system_choices":
	[
	],
	"build_varint": "",
	"command_palette":
	{
		"height": 392.0,
		"last_filter": "pack",
		"selected_items":
		[
			[
				"pack",
				"Package Control: Remove Package"
			],
			[
				"gi",
				"GitHub: Open Gist in Browser"
			],
			[
				"g",
				"GitHub: Open Gist in Browser"
			],
			[
				"Package Control: ",
				"Package Control: Discover Packages"
			],
			[
				"pa",
				"Package Control: Install Package"
			],
			[
				"Snippet: ",
				"Snippet: Lorem ipsum"
			],
			[
				"or",
				"Origami: Create Pane Below"
			],
			[
				"a",
				"View: Toggle Open Files in Side Bar"
			],
			[
				"fil",
				"Origami: Clone File to Pane on the Right"
			],
			[
				"per",
				"Perforce: Checkout"
			],
			[
				"sw",
				"Sweyla's Color Theme Generator: Generate dark!"
			],
			[
				"p",
				"Package Control: Install Package"
			]
		],
		"width": 460.0
	},
	"console":
	{
		"height": 153.0,
		"history":
		[
			"1.0 / 0.5",
			"300 / 60",
			"def dude():",
			"for x in range(7,0):",
			"for x in range(7,0): print x;",
			"for x in range(7,0): print x",
			"b",
			"b[-1] = 1",
			"b",
			"b = bytearray(8)",
			"hex(104)",
			"sublime.log_commands(False)",
			"sublime.log_commands(True)",
			"dir(sublime)",
			"help(sublime)",
			"hex(x & (~y))",
			"hex(x & (~z))",
			"hex",
			"x & (~ z)",
			"x & (not z)",
			"z = 0x1000",
			"y = 0x10",
			"x = 0xFFFFFFFF",
			"Eraser",
			"Pencil",
			"Pen",
			"Pen, Pencil, Eraser = range(3)",
			"range(3)",
			"view.run_command()"
		]
	},
	"distraction_free":
	{
		"menu_visible": false,
		"show_minimap": false,
		"show_open_files": false,
		"show_tabs": false,
		"side_bar_visible": false,
		"status_bar_visible": false
	},
	"expanded_folders":
	[
		"/c/Users/gcarver/OneDrive/Projects/Raspi",
		"/c/Users/gcarver/OneDrive/Projects/Raspi/projects",
		"/c/Users/gcarver/OneDrive/Projects/Raspi/projects/oled",
		"/c/Users/gcarver/OneDrive/Projects/Raspi/projects/seeface"
	],
	"file_history":
	[
		"/C/Projects/Python/extension/checkface.cpp",
		"/c/Users/gcarver/OneDrive/Projects/Raspi/raspicam/src/raspicam_cv.cpp",
		"/c/Users/gcarver/OneDrive/Projects/Raspi/opencv/platforms/linux/runcmake",
		"/c/Users/gcarver/OneDrive/Projects/Raspi/opencv/platforms/linux/runcmake2",
		"/c/Users/gcarver/AppData/Local/lxss/home/gcarver/raspi/backup/opencv/platforms/linux/arm.toolchain.cmake",
		"/c/Users/gcarver/OneDrive/Projects/Raspi/projects/oled/clock.json",
		"/C/Users/gcarver/OneDrive/Projects/raspi/tft/ST7735.py",
		"/C/Users/gcarver/OneDrive/Projects/raspi/clock/clock.py",
		"/c/Users/gcarver/AppData/Local/lxss/home/gcarver/raspi/projects/seeface/seefaceold.cpp",
		"/c/Users/gcarver/AppData/Local/lxss/home/gcarver/raspi/projects/raspicamtest/raspicamtest.cpp",
		"/c/Users/gcarver/AppData/Local/lxss/home/gcarver/raspi/projects/raspicamtest/makeit",
		"/c/Users/gcarver/AppData/Local/lxss/home/gcarver/raspi/projects/oled/checkface.cpp",
		"/c/Users/gcarver/OneDrive/Projects/Raspi/notes.ida",
		"/C/Users/gcarver/OneDrive/Projects/raspi/myglfw/myglfw.c",
		"/c/Users/gcarver/AppData/Local/lxss/home/gcarver/raspi/raspicam/src/raspicam_cv.h",
		"/c/Users/gcarver/AppData/Local/lxss/home/gcarver/raspi/projects/oled/makecheckface",
		"/c/Users/gcarver/AppData/Local/lxss/home/gcarver/raspi/projects/seeface/seeface.cpp",
		"/C/temp/checkface.cpp",
		"/c/Users/gcarver/AppData/Local/lxss/home/gcarver/raspi/projects/oled/makeseeface",
		"/C/Projects/Python/extension/compile",
		"/C/Users/gcarver/AppData/Roaming/Sublime Text 3/Packages/FileHeader/Default (Windows).sublime-keymap",
		"/c/Users/gcarver/AppData/Local/lxss/home/gcarver/raspi/projects/oled/clock.py",
		"/c/Users/gcarver/AppData/Local/lxss/home/gcarver/raspi/projects/pygame/clock/clock.py",
		"/C/Users/gcarver/OneDrive/Projects/MicroPython/lib/OLED.py",
		"/c/Users/gcarver/AppData/Local/lxss/home/gcarver/raspi/projects/oled/settings.py",
		"/C/Users/gcarver/AppData/Local/lxss/home/gcarver/raspi/projects/seeface/seeface.cpp",
		"/c/Users/gcarver/AppData/Local/lxss/home/gcarver/raspi/opencv/modules/objdetect/src/cascadedetect.cpp",
		"/c/Users/gcarver/AppData/Local/lxss/home/gcarver/raspi/projects/DisplayImage/DisplayImage.cpp",
		"/C/Users/gcarver/Dropbox/Apps/Guys app/htmlserversample.py",
		"/C/Users/gcarver/Dropbox/Apps/Guys app/echoserver.py",
		"/c/Users/gcarver/AppData/Local/lxss/home/gcarver/raspi/opencv/platforms/linux/arm.toolchain.cmake",
		"/c/Users/gcarver/OneDrive/Projects/Raspi/pygame/clock/savetest.py",
		"/c/Users/gcarver/OneDrive/Projects/Raspi/pygame/clock/settings.py",
		"/c/Users/gcarver/AppData/Local/lxss/home/gcarver/raspi/projects/seeface/CMakeLists.txt",
		"/c/Users/gcarver/OneDrive/Projects/Raspi/pygame/clock/clock.json",
		"/c/Users/gcarver/OneDrive/Projects/Raspi/pygame/clock/woeid.py",
		"/c/Users/gcarver/OneDrive/Projects/Raspi/pygame/clock/iploc.py",
		"/C/Users/gcarver/OneDrive/Projects/raspi/pygame/clock/seeface.py",
		"/c/Users/gcarver/OneDrive/Projects/Raspi/pygame/clock/clock.py",
		"/C/Users/gcarver/AppData/Local/lxss/home/gcarver/raspi/projects/seeface/seefaceold.cpp",
		"/c/Users/gcarver/AppData/Local/lxss/home/gcarver/raspi/toolchain-rpi.cmake",
		"/C/Users/gcarver/AppData/Local/lxss/home/gcarver/raspi/rootfs/usr/include/python2.7/pyconfig.h",
		"/C/Users/gcarver/AppData/Local/lxss/home/gcarver/raspi/rootfs/usr/include/python3.5m/pyconfig.h",
		"/C/Sublime Text Backups/2017-11-17/c/Users/gcarver/AppData/Local/lxss/home/gcarver/raspi/projects/seeface/seeface.cpp",
		"/C/Sublime Text Backups/2017-11-18/C/Users/gcarver/AppData/Local/lxss/home/gcarver/raspi/projects/seeface/seeface.cpp",
		"/c/Users/gcarver/AppData/Local/lxss/home/gcarver/raspi/rootfs/usr/local/include/raspicam/raspicam.h",
		"/c/Users/gcarver/AppData/Local/lxss/home/gcarver/raspi/rootfs/usr/local/include/raspicam/raspicam_still_cv.h",
		"/c/Users/gcarver/AppData/Local/lxss/home/gcarver/raspi/rootfs/usr/local/include/raspicam/raspicam_cv.h",
		"/C/Users/gcarver/AppData/Local/lxss/home/gcarver/raspi/toolchain-rpi.cmake",
		"/C/Users/gcarver/AppData/Roaming/Sublime Text 3/Packages/User/Package Control.sublime-settings",
		"/C/temp/image.ppm",
		"/C/Users/gcarver/AppData/Local/lxss/home/gcarver/raspi/opencv/platforms/linux/arm.toolchain.cmake",
		"/C/Users/gcarver/Dropbox/Apps/Guys app/Interactive Form.py",
		"/C/Users/gcarver/Dropbox/Apps/Guys app/Examples (previous beta)/HTTP Server/Server.py",
		"/C/Users/gcarver/Dropbox/Apps/Guys app/guy/clock/settings.py",
		"/C/Users/gcarver/OneDrive/Projects/Python/weathertest.py",
		"/C/Users/gcarver/OneDrive/notes.ida",
		"/c/Users/gcarver/OneDrive/Projects/Raspi/tft/ST77352.py",
		"/c/Users/gcarver/OneDrive/Projects/Raspi/tft/shapes.py",
		"/C/Users/gcarver/OneDrive/Projects/Python/clock/clock.py",
		"/C/Users/gcarver/OneDrive/Projects/raspi/pygame/clock/iploc.py",
		"/c/Users/gcarver/OneDrive/Projects/Raspi/oled/clock.py",
		"/C/Users/gcarver/OneDrive/Projects/raspi/pygame/clock.py",
		"/c/Users/gcarver/OneDrive/Projects/Raspi/oled/oled.py",
		"/c/Users/gcarver/OneDrive/Projects/Raspi/clock/clock.py",
		"/C/Users/gcarver/OneDrive/Projects/MicroPython/lib/ST7735.py",
		"/c/Projects/Raspi/peterderivaz-penguinspuzzle-818906c/penguinspuzzle.c",
		"/C/Users/gcarver/OneDrive/Projects/raspi/raspi.sublime-project",
		"/C/Users/gcarver/AppData/Local/Temp/scp31059/home/pi/python_games/memorypuzzle.py",
		"/c/Projects/Raspi/peterderivaz-penguinspuzzle-818906c/penguinspuzzle.bin",
		"/C/Users/gcarver/AppData/Local/Temp/scp11626/usr/include/EGL/egl.h",
		"/C/Users/gcarver/AppData/Local/Temp/scp11842/usr/include/EGL/eglext.h",
		"/C/Users/gcarver/AppData/Local/Temp/scp12876/usr/include/EGL/eglmesaext.h",
		"/C/Users/gcarver/AppData/Local/Temp/scp12447/usr/include/EGL/eglplatform.h",
		"/C/Users/gcarver/AppData/Local/Temp/scp59009/home/gcarver/Projects/penguins/penguins.c",
		"/C/Users/gcarver/AppData/Local/Temp/scp58580/home/gcarver/Projects/penguins/penguinspuzzle.c",
		"/C/Users/gcarver/AppData/Local/Temp/scp38916/opt/vc/src/hello_pi/Makefile.include",
		"/C/Users/gcarver/AppData/Local/Temp/scp05977/usr/include/X11/Xlib.h",
		"/C/Users/gcarver/AppData/Local/Temp/scp07681/usr/include/X11/X.h",
		"/C/Users/gcarver/AppData/Local/Temp/scp07658/home/gcarver/penguinspuzzle/penguinspuzzle.c",
		"/C/Users/gcarver/AppData/Local/Temp/scp34111/usr/include/GL/glfw.h",
		"/c/Projects/Raspi/peterderivaz-penguinspuzzle-818906c/README",
		"/C/Users/gcarver/AppData/Local/Temp/scp47668/home/gcarver/penguinspuzzle/matrix.c",
		"/C/Users/gcarver/AppData/Local/Temp/scp47188/home/gcarver/penguinspuzzle/global.h",
		"/C/Users/gcarver/AppData/Local/Temp/scp13189/usr/include/GLES2/gl2.h",
		"/C/Users/gcarver/AppData/Local/Temp/scp45595/usr/include/GLES2/gl2ext.h",
		"/C/Projects/raspi/wiringPi/examples/Makefile",
		"/C/Users/gcarver/AppData/Local/Temp/scp58827/home/gcarver/myglfw/Makefile",
		"/C/Users/gcarver/AppData/Local/Temp/scp31657/home/gcarver/penguinspuzzle/audio.c",
		"/c/Projects/Raspi/peterderivaz-penguinspuzzle-818906c/matrix.h",
		"/C/Users/gcarver/AppData/Local/Temp/scp41190/home/gcarver/myglfw/myglfw.c",
		"/C/Users/gcarver/AppData/Local/Temp/scp42865/root/.vnc/xstartup",
		"/C/Projects/raspi/myglfw/Makefile",
		"/C/Projects/raspi/pforth/build/wiringPi/examples/Makefile",
		"/C/Projects/raspi/pforth/build/unix/Makefile",
		"/C/Projects/raspi/myglfw/myglfw.c",
		"/C/Users/gcarver/AppData/Local/Temp/scp07658/home/gcarver/myglfw/myglfw.c",
		"/C/Users/gcarver/AppData/Local/Temp/scp06550/usr/include/X11/Xutil.h",
		"/C/Users/gcarver/AppData/Local/Temp/scp00579/usr/include/KHR/khrplatform.h",
		"/c/Projects/Raspi/peterderivaz-penguinspuzzle-818906c/Makefile",
		"/C/Users/gcarver/AppData/Local/Temp/scp18976/home/gcarver/penguinspuzzle/shaders.c",
		"/C/Users/gcarver/AppData/Local/Temp/scp37557/home/gcarver/penguinspuzzle/framebuffer.c",
		"/c/Projects/Raspi/peterderivaz-penguinspuzzle-818906c/matrix.c",
		"/C/Users/gcarver/AppData/Local/Temp/scp45879/home/gcarver/penguinspuzzle/model.c",
		"/C/Users/gcarver/AppData/Local/Temp/scp05866/home/gcarver/penguinspuzzle/audio.h",
		"/C/Users/gcarver/AppData/Local/Temp/scp44996/usr/include/GLES2/gl2platform.h",
		"/c/Projects/Raspi/peterderivaz-penguinspuzzle-818906c/global.h",
		"/C/Users/gcarver/AppData/Local/Temp/scp48909/home/gcarver/penguinspuzzle/keys.c",
		"/C/Users/gcarver/AppData/Local/Temp/scp54218/home/gcarver/penguinspuzzle/embed_file.c",
		"/C/Projects/raspi/peterderivaz-penguinspuzzle-818906c/audio.c",
		"/C/Users/gcarver/AppData/Local/Temp/scp18947/home/gcarver/penguinspuzzle/global.h",
		"/C/Users/gcarver/AppData/Local/Temp/scp19262/home/gcarver/penguinspuzzle/embed_file.c",
		"/C/Users/gcarver/AppData/Local/Temp/scp42202/home/gcarver/penguinspuzzle/global.h",
		"/C/Users/gcarver/AppData/Local/Temp/scp16684/home/gcarver/penguinspuzzle/buffer.c",
		"/C/Users/gcarver/AppData/Local/Temp/scp49363/home/gcarver/penguinspuzzle/embed_file.c",
		"/C/Users/gcarver/AppData/Local/Temp/scp49498/home/gcarver/penguinspuzzle/embed_file.c",
		"/C/Users/gcarver/AppData/Roaming/Sublime Text 2/Packages.sublime-project",
		"/C/Users/gcarver/AppData/Roaming/Sublime Text 2/Packages/XDevkit/Main.sublime-menu",
		"/C/Users/gcarver/AppData/Roaming/Sublime Text 2/Packages/MailFile/MailFile.py",
		"/C/Users/gcarver/AppData/Roaming/Sublime Text 2/Packages/Super Calculator/Main.sublime-menu",
		"/C/Users/gcarver/AppData/Roaming/Sublime Text 2/Packages/Origami/Main.sublime-menu",
		"/C/Users/gcarver/AppData/Roaming/Sublime Text 2/Packages/Origami/origami.py",
		"/C/Users/gcarver/AppData/Roaming/Sublime Text 2/Packages/Function Name Display/Main.sublime-menu",
		"/C/Users/gcarver/AppData/Roaming/Sublime Text 2/Packages/Diff/Context.sublime-menu",
		"/C/Users/gcarver/AppData/Roaming/Sublime Text 2/Packages/Default/Syntax.sublime-menu",
		"/C/Users/gcarver/AppData/Roaming/Sublime Text 2/Packages/Default/Main.sublime-menu",
		"/C/Users/gcarver/AppData/Roaming/Sublime Text 2/Packages/Default/Find in Files.sublime-menu",
		"/C/Users/gcarver/AppData/Roaming/Sublime Text 2/Packages/Color Highlighter/Main.sublime-menu"
	],
	"find":
	{
		"height": 34.0
	},
	"find_in_files":
	{
		"height": 105.0,
		"where_history":
		[
			"c:\\Users\\gcarver\\AppData\\Local\\lxss\\home\\gcarver\\raspi\\opencv-master, *.cpp, *.hpp, *.h, *.c",
			"C:\\Users\\gcarver\\AppData\\Roaming\\Sublime Text 2\\Packages,*.py",
			"C:\\Users\\gcarver\\AppData\\Roaming\\Sublime Text 2\\Packages,*.sublime-keymap",
			"C:\\Users\\gcarver\\AppData\\Roaming\\Sublime Text 2\\Packages,*.py",
			"C:\\Users\\gcarver\\AppData\\Roaming\\Sublime Text 2\\Packages,*.sublime-keymap",
			"C:\\Users\\gcarver\\AppData\\Roaming\\Sublime Text 2\\Packages,*.py",
			"C:\\Users\\gcarver\\AppData\\Roaming\\Sublime Text 2\\Packages",
			"C:\\Users\\gcarver\\AppData\\Roaming\\Sublime Text 2\\Packages\\EnvDTE",
			"C:\\Users\\gcarver\\AppData\\Roaming\\Sublime Text 2\\Packages\\EnvDTE,*.py",
			"C:\\Users\\gcarver\\AppData\\Roaming\\Sublime Text 2\\Packages,*.py",
			"C:\\Users\\gcarver\\AppData\\Roaming\\Sublime Text 2\\Packages"
		]
	},
	"find_state":
	{
		"case_sensitive": false,
		"find_history":
		[
			"print",
			"type",
			"wh",
			"w",
			"scale",
			"smallImg",
			"RASPICAM_FORMAT",
			"imgFormat",
			"CV_8UC1",
			"digitpos",
			"tempsize",
			"self.pos",
			"self\\.x",
			"setVerticalFlip",
			"urlopen",
			"startsettings",
			"running",
			"sleep",
			"update",
			"draw",
			"tempdisplaytime",
			"    ",
			"determinedur",
			"_color",
			"fname",
			"image",
			"nestedCascadeName",
			"cascadeName",
			"nestedObjects",
			"nestedCascade",
			"faces",
			"faces2",
			"    ",
			"time.sl",
			"tempupdateinterval",
			"defaulttempupdate",
			"tempupdateinterval",
			"tempdisplay",
			"ourTarget",
			"RequestHandler",
			"cgi",
			"ourTarget",
			"center",
			"sleep",
			"print",
			"location",
			"adj",
			"  def UpdateWeather( self ):\n    try:\n",
			"UpdateW",
			"_rotate",
			"draw",
			"img2data",
			"windowLocData",
			"_windowLocData",
			"colorData",
			"CASET",
			"print",
			"_size",
			"color565",
			"fill",
			"reset",
			"bytearray",
			"pyb",
			"_draw",
			"_write",
			"_draw",
			"_write",
			"\\.rot",
			"\\._spi",
			"\\.spi",
			"_write",
			"draw",
			"spi",
			"reset",
			"TFT",
			"TFT\\.",
			"TFT",
			"_writedata\\((.*)\\)",
			"_writecommand\\((.*)\\)",
			"_writecommand\\((.*\\))",
			"rect",
			"Dispaly",
			"rect",
			"Display",
			"start",
			"add",
			"dst_rect",
			"Window",
			"wl_egl_window",
			"NativeWindowType",
			"dispman_element",
			"Update",
			"width",
			"update",
			"width",
			"element",
			"nativewindow",
			"EGL_DISP",
			"EGL_DISPMAN",
			"path",
			"dreamhost",
			"gert",
			"89",
			"x89",
			"89",
			"print",
			"else",
			"**\n",
			"DicName",
			"ifdef",
			"endif",
			"ctrl+shift",
			"^#(if|else|elif|endif)",
			"conditionkeys",
			"endif",
			"ifdef",
			"defined",
			"#ifdef",
			"ifdef",
			"print",
			"insert_snippet",
			"join",
			"ClassName",
			"write_file",
			"active",
			"faa912",
			"bool",
			"defined"
		],
		"highlight": true,
		"in_selection": false,
		"preserve_case": false,
		"regex": true,
		"replace_history":
		[
			"\\t",
			"RH",
			"ST7735.",
			"ST7735",
			"data = \\1",
			"command = \\1",
			"command = %1",
			"sets_file",
			"Bubba",
			"nction(  )\n{",
			"Function",
			"Bubba",
			"Bubba\nBubba"
		],
		"reverse": false,
		"show_context": true,
		"use_buffer2": true,
		"whole_word": false,
		"wrap": true
	},
	"groups":
	[
		{
			"selected": 0,
			"sheets":
			[
				{
					"buffer": 0,
					"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/projects/oled/clock.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 10325,
						"regions":
						{
						},
						"selection":
						[
							[
								6512,
								6512
							]
						],
						"settings":
						{
							"PrevActive": true,
							"PrevIndex":
							[
								0,
								0
							],
							"syntax": "Packages/Python/Python.sublime-syntax"
						},
						"translation.x": 0.0,
						"translation.y": 2675.0,
						"zoom_level": 1.0
					},
					"stack_index": 0,
					"type": "text"
				},
				{
					"buffer": 1,
					"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/projects/oled/oled.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 8631,
						"regions":
						{
						},
						"selection":
						[
							[
								5864,
								5864
							]
						],
						"settings":
						{
							"syntax": "Packages/Python/Python.sublime-syntax"
						},
						"translation.x": 0.0,
						"translation.y": 2930.0,
						"zoom_level": 1.0
					},
					"stack_index": 1,
					"type": "text"
				},
				{
					"buffer": 2,
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 414157,
						"regions":
						{
							"match":
							{
								"flags": 112,
								"regions":
								[
									[
										261,
										268
									],
									[
										284,
										291
									],
									[
										505,
										512
									],
									[
										831,
										838
									],
									[
										1052,
										1059
									],
									[
										1346,
										1353
									],
									[
										1854,
										1861
									],
									[
										2387,
										2394
									],
									[
										2848,
										2855
									],
									[
										3391,
										3398
									],
									[
										4003,
										4010
									],
									[
										4327,
										4334
									],
									[
										4559,
										4566
									],
									[
										4793,
										4800
									],
									[
										4817,
										4824
									],
									[
										5101,
										5108
									],
									[
										5306,
										5313
									],
									[
										5330,
										5337
									],
									[
										5578,
										5585
									],
									[
										5848,
										5855
									],
									[
										5871,
										5878
									],
									[
										6241,
										6248
									],
									[
										6390,
										6397
									],
									[
										6655,
										6662
									],
									[
										6918,
										6925
									],
									[
										7118,
										7125
									],
									[
										7333,
										7340
									],
									[
										7692,
										7699
									],
									[
										7854,
										7861
									],
									[
										7993,
										8000
									],
									[
										8160,
										8167
									],
									[
										8374,
										8381
									],
									[
										8429,
										8436
									],
									[
										8672,
										8679
									],
									[
										8994,
										9001
									],
									[
										9227,
										9234
									],
									[
										9443,
										9450
									],
									[
										9867,
										9874
									],
									[
										10130,
										10137
									],
									[
										10445,
										10452
									],
									[
										10748,
										10755
									],
									[
										11000,
										11007
									],
									[
										11259,
										11266
									],
									[
										11557,
										11564
									],
									[
										11833,
										11840
									],
									[
										11873,
										11880
									],
									[
										12200,
										12207
									],
									[
										12386,
										12393
									],
									[
										12600,
										12607
									],
									[
										12937,
										12944
									],
									[
										13301,
										13308
									],
									[
										13529,
										13536
									],
									[
										13732,
										13739
									],
									[
										13907,
										13914
									],
									[
										14174,
										14181
									],
									[
										14486,
										14493
									],
									[
										14946,
										14953
									],
									[
										15361,
										15368
									],
									[
										15744,
										15751
									],
									[
										16099,
										16106
									],
									[
										16356,
										16363
									],
									[
										16697,
										16704
									],
									[
										17022,
										17029
									],
									[
										17045,
										17052
									],
									[
										17266,
										17273
									],
									[
										17592,
										17599
									],
									[
										17813,
										17820
									],
									[
										18107,
										18114
									],
									[
										18615,
										18622
									],
									[
										19148,
										19155
									],
									[
										19609,
										19616
									],
									[
										20152,
										20159
									],
									[
										20718,
										20725
									],
									[
										23808,
										23815
									],
									[
										24164,
										24171
									],
									[
										24332,
										24339
									],
									[
										33947,
										33954
									],
									[
										41668,
										41675
									],
									[
										44179,
										44186
									],
									[
										44223,
										44230
									],
									[
										44267,
										44274
									],
									[
										51089,
										51096
									],
									[
										51704,
										51711
									],
									[
										55591,
										55598
									],
									[
										55635,
										55642
									],
									[
										55679,
										55686
									],
									[
										58268,
										58275
									],
									[
										58702,
										58709
									],
									[
										59269,
										59276
									],
									[
										59687,
										59694
									],
									[
										60216,
										60223
									],
									[
										60662,
										60669
									],
									[
										62505,
										62512
									],
									[
										69151,
										69158
									],
									[
										69289,
										69296
									],
									[
										72440,
										72447
									],
									[
										74632,
										74639
									],
									[
										77296,
										77303
									],
									[
										81141,
										81148
									],
									[
										82653,
										82660
									],
									[
										85650,
										85657
									],
									[
										88444,
										88451
									],
									[
										88534,
										88541
									],
									[
										91336,
										91343
									],
									[
										93342,
										93349
									],
									[
										93516,
										93523
									],
									[
										93585,
										93592
									],
									[
										93769,
										93776
									],
									[
										96164,
										96171
									],
									[
										97253,
										97260
									],
									[
										98266,
										98273
									],
									[
										99008,
										99015
									],
									[
										100197,
										100204
									],
									[
										102875,
										102882
									],
									[
										105965,
										105972
									],
									[
										106321,
										106328
									],
									[
										106489,
										106496
									],
									[
										116104,
										116111
									],
									[
										123825,
										123832
									],
									[
										126336,
										126343
									],
									[
										126380,
										126387
									],
									[
										126424,
										126431
									],
									[
										133246,
										133253
									],
									[
										133861,
										133868
									],
									[
										137748,
										137755
									],
									[
										137792,
										137799
									],
									[
										137836,
										137843
									],
									[
										140425,
										140432
									],
									[
										140859,
										140866
									],
									[
										141426,
										141433
									],
									[
										141844,
										141851
									],
									[
										142373,
										142380
									],
									[
										142819,
										142826
									],
									[
										144662,
										144669
									],
									[
										151308,
										151315
									],
									[
										151446,
										151453
									],
									[
										154597,
										154604
									],
									[
										156789,
										156796
									],
									[
										159453,
										159460
									],
									[
										163298,
										163305
									],
									[
										164810,
										164817
									],
									[
										167807,
										167814
									],
									[
										170601,
										170608
									],
									[
										170691,
										170698
									],
									[
										173493,
										173500
									],
									[
										175499,
										175506
									],
									[
										175673,
										175680
									],
									[
										175742,
										175749
									],
									[
										175926,
										175933
									],
									[
										178321,
										178328
									],
									[
										179410,
										179417
									],
									[
										180423,
										180430
									],
									[
										181165,
										181172
									],
									[
										182354,
										182361
									],
									[
										184996,
										185003
									],
									[
										185255,
										185262
									],
									[
										185475,
										185482
									],
									[
										185770,
										185777
									],
									[
										185928,
										185935
									],
									[
										186140,
										186147
									],
									[
										186325,
										186332
									],
									[
										186747,
										186754
									],
									[
										186938,
										186945
									],
									[
										187206,
										187213
									],
									[
										187498,
										187505
									],
									[
										187528,
										187535
									],
									[
										187624,
										187631
									],
									[
										187945,
										187952
									],
									[
										188184,
										188191
									],
									[
										188527,
										188534
									],
									[
										188681,
										188688
									],
									[
										189073,
										189080
									],
									[
										189345,
										189352
									],
									[
										189539,
										189546
									],
									[
										189747,
										189754
									],
									[
										190019,
										190026
									],
									[
										190276,
										190283
									],
									[
										190540,
										190547
									],
									[
										190839,
										190846
									],
									[
										191103,
										191110
									],
									[
										191172,
										191179
									],
									[
										191428,
										191435
									],
									[
										191606,
										191613
									],
									[
										191886,
										191893
									],
									[
										192103,
										192110
									],
									[
										192403,
										192410
									],
									[
										192525,
										192532
									],
									[
										192857,
										192864
									],
									[
										193131,
										193138
									],
									[
										193369,
										193376
									],
									[
										193698,
										193705
									],
									[
										194053,
										194060
									],
									[
										194309,
										194316
									],
									[
										194583,
										194590
									],
									[
										194656,
										194663
									],
									[
										194729,
										194736
									],
									[
										194894,
										194901
									],
									[
										194978,
										194985
									],
									[
										195062,
										195069
									],
									[
										195299,
										195306
									],
									[
										195372,
										195379
									],
									[
										195445,
										195452
									],
									[
										195610,
										195617
									],
									[
										195694,
										195701
									],
									[
										195778,
										195785
									],
									[
										196099,
										196106
									],
									[
										196421,
										196428
									],
									[
										196907,
										196914
									],
									[
										197195,
										197202
									],
									[
										197576,
										197583
									],
									[
										197903,
										197910
									],
									[
										198382,
										198389
									],
									[
										198825,
										198832
									],
									[
										199149,
										199156
									],
									[
										199494,
										199501
									],
									[
										199916,
										199923
									],
									[
										200339,
										200346
									],
									[
										200817,
										200824
									],
									[
										201259,
										201266
									],
									[
										201680,
										201687
									],
									[
										202105,
										202112
									],
									[
										202577,
										202584
									],
									[
										202882,
										202889
									],
									[
										203234,
										203241
									],
									[
										203563,
										203570
									],
									[
										203939,
										203946
									],
									[
										204268,
										204275
									],
									[
										204901,
										204908
									],
									[
										205362,
										205369
									],
									[
										205685,
										205692
									],
									[
										205829,
										205836
									],
									[
										206173,
										206180
									],
									[
										206377,
										206384
									],
									[
										206623,
										206630
									],
									[
										206844,
										206851
									],
									[
										207060,
										207067
									],
									[
										207281,
										207288
									],
									[
										207568,
										207575
									],
									[
										207577,
										207584
									],
									[
										207969,
										207976
									],
									[
										208107,
										208114
									],
									[
										208269,
										208276
									],
									[
										208612,
										208619
									],
									[
										208826,
										208833
									],
									[
										209025,
										209032
									],
									[
										209289,
										209296
									],
									[
										209544,
										209551
									],
									[
										209994,
										210001
									],
									[
										210478,
										210485
									],
									[
										210948,
										210955
									],
									[
										211303,
										211310
									],
									[
										211616,
										211623
									],
									[
										212057,
										212064
									],
									[
										212325,
										212332
									],
									[
										212398,
										212405
									],
									[
										212467,
										212474
									],
									[
										212799,
										212806
									],
									[
										213136,
										213143
									],
									[
										213486,
										213493
									],
									[
										214028,
										214035
									],
									[
										214329,
										214336
									],
									[
										214611,
										214618
									],
									[
										214831,
										214838
									],
									[
										215076,
										215083
									],
									[
										215329,
										215336
									],
									[
										215580,
										215587
									],
									[
										215932,
										215939
									],
									[
										216077,
										216084
									],
									[
										216284,
										216291
									],
									[
										216456,
										216463
									],
									[
										216507,
										216514
									],
									[
										216841,
										216848
									],
									[
										217132,
										217139
									],
									[
										217394,
										217401
									],
									[
										217551,
										217558
									],
									[
										217832,
										217839
									],
									[
										218102,
										218109
									],
									[
										218405,
										218412
									],
									[
										218709,
										218716
									],
									[
										219072,
										219079
									],
									[
										219221,
										219228
									],
									[
										219629,
										219636
									],
									[
										219946,
										219953
									],
									[
										220329,
										220336
									],
									[
										220609,
										220616
									],
									[
										220897,
										220904
									],
									[
										221299,
										221306
									],
									[
										221760,
										221767
									],
									[
										222066,
										222073
									],
									[
										222375,
										222382
									],
									[
										222607,
										222614
									],
									[
										222935,
										222942
									],
									[
										223052,
										223059
									],
									[
										223187,
										223194
									],
									[
										223304,
										223311
									],
									[
										223534,
										223541
									],
									[
										223706,
										223713
									],
									[
										223961,
										223968
									],
									[
										224287,
										224294
									],
									[
										224636,
										224643
									],
									[
										224991,
										224998
									],
									[
										225324,
										225331
									],
									[
										225674,
										225681
									],
									[
										226050,
										226057
									],
									[
										226421,
										226428
									],
									[
										226815,
										226822
									],
									[
										227212,
										227219
									],
									[
										227566,
										227573
									],
									[
										227943,
										227950
									],
									[
										228275,
										228282
									],
									[
										228590,
										228597
									],
									[
										229020,
										229027
									],
									[
										229088,
										229095
									],
									[
										229277,
										229284
									],
									[
										229348,
										229355
									],
									[
										229574,
										229581
									],
									[
										229912,
										229919
									],
									[
										230096,
										230103
									],
									[
										230235,
										230242
									],
									[
										230691,
										230698
									],
									[
										230927,
										230934
									],
									[
										231184,
										231191
									],
									[
										231354,
										231361
									],
									[
										231524,
										231531
									],
									[
										231819,
										231826
									],
									[
										232030,
										232037
									],
									[
										232084,
										232091
									],
									[
										232347,
										232354
									],
									[
										232401,
										232408
									],
									[
										232792,
										232799
									],
									[
										233091,
										233098
									],
									[
										233102,
										233109
									],
									[
										233286,
										233293
									],
									[
										233479,
										233486
									],
									[
										233520,
										233527
									],
									[
										233529,
										233536
									],
									[
										233654,
										233661
									],
									[
										233789,
										233796
									],
									[
										233924,
										233931
									],
									[
										234166,
										234173
									],
									[
										234545,
										234552
									],
									[
										235008,
										235015
									],
									[
										235241,
										235248
									],
									[
										235399,
										235406
									],
									[
										235741,
										235748
									],
									[
										235822,
										235829
									],
									[
										235963,
										235970
									],
									[
										236109,
										236116
									],
									[
										236208,
										236215
									],
									[
										236327,
										236334
									],
									[
										236498,
										236505
									],
									[
										236678,
										236685
									],
									[
										236918,
										236925
									],
									[
										237096,
										237103
									],
									[
										237252,
										237259
									],
									[
										237382,
										237389
									],
									[
										237549,
										237556
									],
									[
										237733,
										237740
									],
									[
										237901,
										237908
									],
									[
										238090,
										238097
									],
									[
										238260,
										238267
									],
									[
										238438,
										238445
									],
									[
										238578,
										238585
									],
									[
										238758,
										238765
									],
									[
										239038,
										239045
									],
									[
										239290,
										239297
									],
									[
										239738,
										239745
									],
									[
										239937,
										239944
									],
									[
										240135,
										240142
									],
									[
										240399,
										240406
									],
									[
										240634,
										240641
									],
									[
										240849,
										240856
									],
									[
										241147,
										241154
									],
									[
										241533,
										241540
									],
									[
										241793,
										241800
									],
									[
										241954,
										241961
									],
									[
										242211,
										242218
									],
									[
										242300,
										242307
									],
									[
										242447,
										242454
									],
									[
										242593,
										242600
									],
									[
										242739,
										242746
									],
									[
										243179,
										243186
									],
									[
										243466,
										243473
									],
									[
										243654,
										243661
									],
									[
										243943,
										243950
									],
									[
										244137,
										244144
									],
									[
										244338,
										244345
									],
									[
										244679,
										244686
									],
									[
										244873,
										244880
									],
									[
										245089,
										245096
									],
									[
										245285,
										245292
									],
									[
										245442,
										245449
									],
									[
										245807,
										245814
									],
									[
										246103,
										246110
									],
									[
										246403,
										246410
									],
									[
										246698,
										246705
									],
									[
										246998,
										247005
									],
									[
										247298,
										247305
									],
									[
										247534,
										247541
									],
									[
										247915,
										247922
									],
									[
										248146,
										248153
									],
									[
										248377,
										248384
									],
									[
										248616,
										248623
									],
									[
										248849,
										248856
									],
									[
										248968,
										248975
									],
									[
										249160,
										249167
									],
									[
										249279,
										249286
									],
									[
										249469,
										249476
									],
									[
										249586,
										249593
									],
									[
										249778,
										249785
									],
									[
										249897,
										249904
									],
									[
										250261,
										250268
									],
									[
										250558,
										250565
									],
									[
										250783,
										250790
									],
									[
										250939,
										250946
									],
									[
										250991,
										250998
									],
									[
										251198,
										251205
									],
									[
										251250,
										251257
									],
									[
										251410,
										251417
									],
									[
										251629,
										251636
									],
									[
										251847,
										251854
									],
									[
										252033,
										252040
									],
									[
										252220,
										252227
									],
									[
										252369,
										252376
									],
									[
										252586,
										252593
									],
									[
										252953,
										252960
									],
									[
										253217,
										253224
									],
									[
										253412,
										253419
									],
									[
										253730,
										253737
									],
									[
										253908,
										253915
									],
									[
										254179,
										254186
									],
									[
										254578,
										254585
									],
									[
										254995,
										255002
									],
									[
										255233,
										255240
									],
									[
										255623,
										255630
									],
									[
										255756,
										255763
									],
									[
										255978,
										255985
									],
									[
										256330,
										256337
									],
									[
										256660,
										256667
									],
									[
										257075,
										257082
									],
									[
										257497,
										257504
									],
									[
										257913,
										257920
									],
									[
										257982,
										257989
									],
									[
										258284,
										258291
									],
									[
										258467,
										258474
									],
									[
										258536,
										258543
									],
									[
										258761,
										258768
									],
									[
										258967,
										258974
									],
									[
										259262,
										259269
									],
									[
										259561,
										259568
									],
									[
										259796,
										259803
									],
									[
										259997,
										260004
									],
									[
										260260,
										260267
									],
									[
										260424,
										260431
									],
									[
										260628,
										260635
									],
									[
										260933,
										260940
									],
									[
										261210,
										261217
									],
									[
										261421,
										261428
									],
									[
										261822,
										261829
									],
									[
										262135,
										262142
									],
									[
										262491,
										262498
									],
									[
										262776,
										262783
									],
									[
										263062,
										263069
									],
									[
										263323,
										263330
									],
									[
										263619,
										263626
									],
									[
										264155,
										264162
									],
									[
										264357,
										264364
									],
									[
										264590,
										264597
									],
									[
										264797,
										264804
									],
									[
										265005,
										265012
									],
									[
										265202,
										265209
									],
									[
										265408,
										265415
									],
									[
										265574,
										265581
									],
									[
										265795,
										265802
									],
									[
										266022,
										266029
									],
									[
										266030,
										266037
									],
									[
										266313,
										266320
									],
									[
										266643,
										266650
									],
									[
										266829,
										266836
									],
									[
										267053,
										267060
									],
									[
										267313,
										267320
									],
									[
										267401,
										267408
									],
									[
										267591,
										267598
									],
									[
										267938,
										267945
									],
									[
										268217,
										268224
									],
									[
										268475,
										268482
									],
									[
										268663,
										268670
									],
									[
										268957,
										268964
									],
									[
										269300,
										269307
									],
									[
										269775,
										269782
									],
									[
										270017,
										270024
									],
									[
										270317,
										270324
									],
									[
										270617,
										270624
									],
									[
										271013,
										271020
									],
									[
										271317,
										271324
									],
									[
										271483,
										271490
									],
									[
										271675,
										271682
									],
									[
										271961,
										271968
									],
									[
										272211,
										272218
									],
									[
										272450,
										272457
									],
									[
										272745,
										272752
									],
									[
										273048,
										273055
									],
									[
										273428,
										273435
									],
									[
										273774,
										273781
									],
									[
										274160,
										274167
									],
									[
										274557,
										274564
									],
									[
										274703,
										274710
									],
									[
										274854,
										274861
									],
									[
										275098,
										275105
									],
									[
										275405,
										275412
									],
									[
										275683,
										275690
									],
									[
										275885,
										275892
									],
									[
										276202,
										276209
									],
									[
										276378,
										276385
									],
									[
										276537,
										276544
									],
									[
										276766,
										276773
									],
									[
										276890,
										276897
									],
									[
										277235,
										277242
									],
									[
										277401,
										277408
									],
									[
										277565,
										277572
									],
									[
										277810,
										277817
									],
									[
										278209,
										278216
									],
									[
										278284,
										278291
									],
									[
										278435,
										278442
									],
									[
										278643,
										278650
									],
									[
										278835,
										278842
									],
									[
										279159,
										279166
									],
									[
										279447,
										279454
									],
									[
										279812,
										279819
									],
									[
										280125,
										280132
									],
									[
										280189,
										280196
									],
									[
										280367,
										280374
									],
									[
										280554,
										280561
									],
									[
										280735,
										280742
									],
									[
										280934,
										280941
									],
									[
										281125,
										281132
									],
									[
										281334,
										281341
									],
									[
										281517,
										281524
									],
									[
										281700,
										281707
									],
									[
										281883,
										281890
									],
									[
										282011,
										282018
									],
									[
										282271,
										282278
									],
									[
										282711,
										282718
									],
									[
										282786,
										282793
									],
									[
										282931,
										282938
									],
									[
										283313,
										283320
									],
									[
										283698,
										283705
									],
									[
										284144,
										284151
									],
									[
										284431,
										284438
									],
									[
										284819,
										284826
									],
									[
										285192,
										285199
									],
									[
										285620,
										285627
									],
									[
										285924,
										285931
									],
									[
										286064,
										286071
									],
									[
										286219,
										286226
									],
									[
										286271,
										286278
									],
									[
										286472,
										286479
									],
									[
										286615,
										286622
									],
									[
										286897,
										286904
									],
									[
										287040,
										287047
									],
									[
										287194,
										287201
									],
									[
										287416,
										287423
									],
									[
										287855,
										287862
									],
									[
										288278,
										288285
									],
									[
										288571,
										288578
									],
									[
										288716,
										288723
									],
									[
										288937,
										288944
									],
									[
										289148,
										289155
									],
									[
										289223,
										289230
									],
									[
										289481,
										289488
									],
									[
										289583,
										289590
									],
									[
										289809,
										289816
									],
									[
										290059,
										290066
									],
									[
										290339,
										290346
									],
									[
										290389,
										290396
									],
									[
										290686,
										290693
									],
									[
										291007,
										291014
									],
									[
										291159,
										291166
									],
									[
										291466,
										291473
									],
									[
										291928,
										291935
									],
									[
										292273,
										292280
									],
									[
										292573,
										292580
									],
									[
										292818,
										292825
									],
									[
										293123,
										293130
									],
									[
										293321,
										293328
									],
									[
										293545,
										293552
									],
									[
										293812,
										293819
									],
									[
										294062,
										294069
									],
									[
										294493,
										294500
									],
									[
										294813,
										294820
									],
									[
										295083,
										295090
									],
									[
										295530,
										295537
									],
									[
										295900,
										295907
									],
									[
										296236,
										296243
									],
									[
										296315,
										296322
									],
									[
										296760,
										296767
									],
									[
										297065,
										297072
									],
									[
										297218,
										297225
									],
									[
										297500,
										297507
									],
									[
										297867,
										297874
									],
									[
										298227,
										298234
									],
									[
										298516,
										298523
									],
									[
										298910,
										298917
									],
									[
										299531,
										299538
									],
									[
										299960,
										299967
									],
									[
										300497,
										300504
									],
									[
										300648,
										300655
									],
									[
										301106,
										301113
									],
									[
										301630,
										301637
									],
									[
										301832,
										301839
									],
									[
										302295,
										302302
									],
									[
										302762,
										302769
									],
									[
										303088,
										303095
									],
									[
										303264,
										303271
									],
									[
										303541,
										303548
									],
									[
										303891,
										303898
									],
									[
										304178,
										304185
									],
									[
										304513,
										304520
									],
									[
										304791,
										304798
									],
									[
										305281,
										305288
									],
									[
										305558,
										305565
									],
									[
										305762,
										305769
									],
									[
										306067,
										306074
									],
									[
										306446,
										306453
									],
									[
										306845,
										306852
									],
									[
										307143,
										307150
									],
									[
										307441,
										307448
									],
									[
										307798,
										307805
									],
									[
										308189,
										308196
									],
									[
										308431,
										308438
									],
									[
										308541,
										308548
									],
									[
										308686,
										308693
									],
									[
										308876,
										308883
									],
									[
										309018,
										309025
									],
									[
										309171,
										309178
									],
									[
										309532,
										309539
									],
									[
										309875,
										309882
									],
									[
										310295,
										310302
									],
									[
										310766,
										310773
									],
									[
										311071,
										311078
									],
									[
										311366,
										311373
									],
									[
										311596,
										311603
									],
									[
										311947,
										311954
									],
									[
										312124,
										312131
									],
									[
										312414,
										312421
									],
									[
										312734,
										312741
									],
									[
										313264,
										313271
									],
									[
										313445,
										313452
									],
									[
										313934,
										313941
									],
									[
										314355,
										314362
									],
									[
										314680,
										314687
									],
									[
										314852,
										314859
									],
									[
										315243,
										315250
									],
									[
										315527,
										315534
									],
									[
										315574,
										315581
									],
									[
										315597,
										315604
									],
									[
										315773,
										315780
									],
									[
										315820,
										315827
									],
									[
										315843,
										315850
									],
									[
										316099,
										316106
									],
									[
										316160,
										316167
									],
									[
										316495,
										316502
									],
									[
										316542,
										316549
									],
									[
										316565,
										316572
									],
									[
										316724,
										316731
									],
									[
										316771,
										316778
									],
									[
										316955,
										316962
									],
									[
										317002,
										317009
									],
									[
										317049,
										317056
									],
									[
										317267,
										317274
									],
									[
										317490,
										317497
									],
									[
										317719,
										317726
									],
									[
										317904,
										317911
									],
									[
										318108,
										318115
									],
									[
										318362,
										318369
									],
									[
										318409,
										318416
									],
									[
										318432,
										318439
									],
									[
										318637,
										318644
									],
									[
										318979,
										318986
									],
									[
										319159,
										319166
									],
									[
										319186,
										319193
									],
									[
										319310,
										319317
									],
									[
										319563,
										319570
									],
									[
										319809,
										319816
									],
									[
										319942,
										319949
									],
									[
										320154,
										320161
									],
									[
										320277,
										320284
									],
									[
										320500,
										320507
									],
									[
										320887,
										320894
									],
									[
										321158,
										321165
									],
									[
										321428,
										321435
									],
									[
										321683,
										321690
									],
									[
										321950,
										321957
									],
									[
										322221,
										322228
									],
									[
										322492,
										322499
									],
									[
										322744,
										322751
									],
									[
										323053,
										323060
									],
									[
										323292,
										323299
									],
									[
										323555,
										323562
									],
									[
										323807,
										323814
									],
									[
										324110,
										324117
									],
									[
										324371,
										324378
									],
									[
										324646,
										324653
									],
									[
										324943,
										324950
									],
									[
										324981,
										324988
									],
									[
										325142,
										325149
									],
									[
										325180,
										325187
									],
									[
										325440,
										325447
									],
									[
										325863,
										325870
									],
									[
										326160,
										326167
									],
									[
										326438,
										326445
									],
									[
										326760,
										326767
									],
									[
										327104,
										327111
									],
									[
										327171,
										327178
									],
									[
										327429,
										327436
									],
									[
										327564,
										327571
									],
									[
										327938,
										327945
									],
									[
										328247,
										328254
									],
									[
										328500,
										328507
									],
									[
										328854,
										328861
									],
									[
										329180,
										329187
									],
									[
										329356,
										329363
									],
									[
										329389,
										329396
									],
									[
										329524,
										329531
									],
									[
										329783,
										329790
									],
									[
										329801,
										329808
									],
									[
										330028,
										330035
									],
									[
										330046,
										330053
									],
									[
										330306,
										330313
									],
									[
										330606,
										330613
									],
									[
										330736,
										330743
									],
									[
										330954,
										330961
									],
									[
										331208,
										331215
									],
									[
										331312,
										331319
									],
									[
										331583,
										331590
									],
									[
										331687,
										331694
									],
									[
										331920,
										331927
									],
									[
										332143,
										332150
									],
									[
										332447,
										332454
									],
									[
										332604,
										332611
									],
									[
										332782,
										332789
									],
									[
										332858,
										332865
									],
									[
										333029,
										333036
									],
									[
										333338,
										333345
									],
									[
										333790,
										333797
									],
									[
										334171,
										334178
									],
									[
										334520,
										334527
									],
									[
										334858,
										334865
									],
									[
										334990,
										334997
									],
									[
										335318,
										335325
									],
									[
										335434,
										335441
									],
									[
										335827,
										335834
									],
									[
										336129,
										336136
									],
									[
										336300,
										336307
									],
									[
										336461,
										336468
									],
									[
										336746,
										336753
									],
									[
										337132,
										337139
									],
									[
										337358,
										337365
									],
									[
										337737,
										337744
									],
									[
										338062,
										338069
									],
									[
										338364,
										338371
									],
									[
										338676,
										338683
									],
									[
										339024,
										339031
									],
									[
										339205,
										339212
									],
									[
										339230,
										339237
									],
									[
										339385,
										339392
									],
									[
										339439,
										339446
									],
									[
										339591,
										339598
									],
									[
										339833,
										339840
									],
									[
										340085,
										340092
									],
									[
										340388,
										340395
									],
									[
										340679,
										340686
									],
									[
										340937,
										340944
									],
									[
										341153,
										341160
									],
									[
										341498,
										341505
									],
									[
										341711,
										341718
									],
									[
										342032,
										342039
									],
									[
										342346,
										342353
									],
									[
										342745,
										342752
									],
									[
										343130,
										343137
									],
									[
										343195,
										343202
									],
									[
										343486,
										343493
									],
									[
										343718,
										343725
									],
									[
										344043,
										344050
									],
									[
										344298,
										344305
									],
									[
										344562,
										344569
									],
									[
										344869,
										344876
									],
									[
										345107,
										345114
									],
									[
										345333,
										345340
									],
									[
										345486,
										345493
									],
									[
										345627,
										345634
									],
									[
										345796,
										345803
									],
									[
										345987,
										345994
									],
									[
										346181,
										346188
									],
									[
										346346,
										346353
									],
									[
										346629,
										346636
									],
									[
										346654,
										346661
									],
									[
										346894,
										346901
									],
									[
										347179,
										347186
									],
									[
										347218,
										347225
									],
									[
										347532,
										347539
									],
									[
										347871,
										347878
									],
									[
										348231,
										348238
									],
									[
										348589,
										348596
									],
									[
										349034,
										349041
									],
									[
										349296,
										349303
									],
									[
										349476,
										349483
									],
									[
										349784,
										349791
									],
									[
										349820,
										349827
									],
									[
										349950,
										349957
									],
									[
										350208,
										350215
									],
									[
										350453,
										350460
									],
									[
										350701,
										350708
									],
									[
										350985,
										350992
									],
									[
										351218,
										351225
									],
									[
										351613,
										351620
									],
									[
										351969,
										351976
									],
									[
										352395,
										352402
									],
									[
										352755,
										352762
									],
									[
										352870,
										352877
									],
									[
										353263,
										353270
									],
									[
										353491,
										353498
									],
									[
										353842,
										353849
									],
									[
										354164,
										354171
									],
									[
										354389,
										354396
									],
									[
										354432,
										354439
									],
									[
										354663,
										354670
									],
									[
										354865,
										354872
									],
									[
										355109,
										355116
									],
									[
										355369,
										355376
									],
									[
										355594,
										355601
									],
									[
										355838,
										355845
									],
									[
										356162,
										356169
									],
									[
										356494,
										356501
									],
									[
										356755,
										356762
									],
									[
										357105,
										357112
									],
									[
										357551,
										357558
									],
									[
										357742,
										357749
									],
									[
										357909,
										357916
									],
									[
										358281,
										358288
									],
									[
										358608,
										358615
									],
									[
										358838,
										358845
									],
									[
										359069,
										359076
									],
									[
										359281,
										359288
									],
									[
										359571,
										359578
									],
									[
										359771,
										359778
									],
									[
										360063,
										360070
									],
									[
										360341,
										360348
									],
									[
										360654,
										360661
									],
									[
										360910,
										360917
									],
									[
										361264,
										361271
									],
									[
										361649,
										361656
									],
									[
										361936,
										361943
									],
									[
										362515,
										362522
									],
									[
										362831,
										362838
									],
									[
										363092,
										363099
									],
									[
										363164,
										363171
									],
									[
										363637,
										363644
									],
									[
										363800,
										363807
									],
									[
										364006,
										364013
									],
									[
										364269,
										364276
									],
									[
										364580,
										364587
									],
									[
										364886,
										364893
									],
									[
										365185,
										365192
									],
									[
										365520,
										365527
									],
									[
										365950,
										365957
									],
									[
										366321,
										366328
									],
									[
										366634,
										366641
									],
									[
										367010,
										367017
									],
									[
										367314,
										367321
									],
									[
										367629,
										367636
									],
									[
										368063,
										368070
									],
									[
										368485,
										368492
									],
									[
										368719,
										368726
									],
									[
										369048,
										369055
									],
									[
										369202,
										369209
									],
									[
										369563,
										369570
									],
									[
										369916,
										369923
									],
									[
										370063,
										370070
									],
									[
										370390,
										370397
									],
									[
										370706,
										370713
									],
									[
										370888,
										370895
									],
									[
										371076,
										371083
									],
									[
										371254,
										371261
									],
									[
										371440,
										371447
									],
									[
										371726,
										371733
									],
									[
										371902,
										371909
									],
									[
										371947,
										371954
									],
									[
										372170,
										372177
									],
									[
										372343,
										372350
									],
									[
										372557,
										372564
									],
									[
										372768,
										372775
									],
									[
										372946,
										372953
									],
									[
										373180,
										373187
									],
									[
										373391,
										373398
									],
									[
										373762,
										373769
									],
									[
										374125,
										374132
									],
									[
										374417,
										374424
									],
									[
										374609,
										374616
									],
									[
										374814,
										374821
									],
									[
										374976,
										374983
									],
									[
										375017,
										375024
									],
									[
										375162,
										375169
									],
									[
										375203,
										375210
									],
									[
										375485,
										375492
									],
									[
										375543,
										375550
									],
									[
										375721,
										375728
									],
									[
										375777,
										375784
									],
									[
										375947,
										375954
									],
									[
										376268,
										376275
									],
									[
										376437,
										376444
									],
									[
										376616,
										376623
									],
									[
										376830,
										376837
									],
									[
										377110,
										377117
									],
									[
										377545,
										377552
									],
									[
										377872,
										377879
									],
									[
										377953,
										377960
									],
									[
										378289,
										378296
									],
									[
										378370,
										378377
									],
									[
										378729,
										378736
									],
									[
										378739,
										378746
									],
									[
										379071,
										379078
									],
									[
										379289,
										379296
									],
									[
										379568,
										379575
									],
									[
										379909,
										379916
									],
									[
										380088,
										380095
									],
									[
										380479,
										380486
									],
									[
										380839,
										380846
									],
									[
										381195,
										381202
									],
									[
										381823,
										381830
									],
									[
										382165,
										382172
									],
									[
										382564,
										382571
									],
									[
										382899,
										382906
									],
									[
										383187,
										383194
									],
									[
										383433,
										383440
									],
									[
										383578,
										383585
									],
									[
										383989,
										383996
									],
									[
										384200,
										384207
									],
									[
										384316,
										384323
									],
									[
										384375,
										384382
									],
									[
										384594,
										384601
									],
									[
										384911,
										384918
									],
									[
										385103,
										385110
									],
									[
										385372,
										385379
									],
									[
										385512,
										385519
									],
									[
										385652,
										385659
									],
									[
										385803,
										385810
									],
									[
										386065,
										386072
									],
									[
										386280,
										386287
									],
									[
										386453,
										386460
									],
									[
										386726,
										386733
									],
									[
										386988,
										386995
									],
									[
										387282,
										387289
									],
									[
										387648,
										387655
									],
									[
										387849,
										387856
									],
									[
										388064,
										388071
									],
									[
										388311,
										388318
									],
									[
										388518,
										388525
									],
									[
										388854,
										388861
									],
									[
										389085,
										389092
									],
									[
										389353,
										389360
									],
									[
										389484,
										389491
									],
									[
										389639,
										389646
									],
									[
										389811,
										389818
									],
									[
										389980,
										389987
									],
									[
										390328,
										390335
									],
									[
										390466,
										390473
									],
									[
										390819,
										390826
									],
									[
										391110,
										391117
									],
									[
										391401,
										391408
									],
									[
										391813,
										391820
									],
									[
										392067,
										392074
									],
									[
										392420,
										392427
									],
									[
										392590,
										392597
									],
									[
										392915,
										392922
									],
									[
										393167,
										393174
									],
									[
										393550,
										393557
									],
									[
										393787,
										393794
									],
									[
										393969,
										393976
									],
									[
										394244,
										394251
									],
									[
										394600,
										394607
									],
									[
										394852,
										394859
									],
									[
										394884,
										394891
									],
									[
										395113,
										395120
									],
									[
										395329,
										395336
									],
									[
										395806,
										395813
									],
									[
										395952,
										395959
									],
									[
										396433,
										396440
									],
									[
										396591,
										396598
									],
									[
										396841,
										396848
									],
									[
										397221,
										397228
									],
									[
										397637,
										397644
									],
									[
										397928,
										397935
									],
									[
										398292,
										398299
									],
									[
										398579,
										398586
									],
									[
										398761,
										398768
									],
									[
										398999,
										399006
									],
									[
										399054,
										399061
									],
									[
										399253,
										399260
									],
									[
										399403,
										399410
									],
									[
										399553,
										399560
									],
									[
										399750,
										399757
									],
									[
										399994,
										400001
									],
									[
										400278,
										400285
									],
									[
										400423,
										400430
									],
									[
										400715,
										400722
									],
									[
										401023,
										401030
									],
									[
										401186,
										401193
									],
									[
										401463,
										401470
									],
									[
										401761,
										401768
									],
									[
										402080,
										402087
									],
									[
										402356,
										402363
									],
									[
										402454,
										402461
									],
									[
										402607,
										402614
									],
									[
										402766,
										402773
									],
									[
										402985,
										402992
									],
									[
										403154,
										403161
									],
									[
										403594,
										403601
									],
									[
										403807,
										403814
									],
									[
										404033,
										404040
									],
									[
										404280,
										404287
									],
									[
										404471,
										404478
									],
									[
										404785,
										404792
									],
									[
										405064,
										405071
									],
									[
										405555,
										405562
									],
									[
										405738,
										405745
									],
									[
										405804,
										405811
									],
									[
										406209,
										406216
									],
									[
										406560,
										406567
									],
									[
										407046,
										407053
									],
									[
										407452,
										407459
									],
									[
										407769,
										407776
									],
									[
										407952,
										407959
									],
									[
										407997,
										408004
									],
									[
										408357,
										408364
									],
									[
										408674,
										408681
									],
									[
										408856,
										408863
									],
									[
										409094,
										409101
									],
									[
										409149,
										409156
									],
									[
										409348,
										409355
									],
									[
										409498,
										409505
									],
									[
										409648,
										409655
									],
									[
										409845,
										409852
									],
									[
										410162,
										410169
									],
									[
										410473,
										410480
									],
									[
										410775,
										410782
									],
									[
										411044,
										411051
									],
									[
										411356,
										411363
									],
									[
										411643,
										411650
									],
									[
										411778,
										411785
									],
									[
										411971,
										411978
									],
									[
										412192,
										412199
									],
									[
										412517,
										412524
									],
									[
										412772,
										412779
									],
									[
										412936,
										412943
									],
									[
										413001,
										413008
									],
									[
										413376,
										413383
									],
									[
										413626,
										413633
									],
									[
										413911,
										413918
									]
								],
								"scope": ""
							}
						},
						"selection":
						[
							[
								0,
								0
							]
						],
						"settings":
						{
							"detect_indentation": false,
							"line_numbers": false,
							"output_tag": 1,
							"result_base_dir": "",
							"result_file_regex": "^([^ \t].*):$",
							"result_line_regex": "^ +([0-9]+):",
							"scroll_past_end": true,
							"syntax": "Packages/Default/Find Results.hidden-tmLanguage"
						},
						"translation.x": 0.0,
						"translation.y": 2880.0,
						"zoom_level": 1.0
					},
					"stack_index": 16,
					"type": "text"
				},
				{
					"buffer": 3,
					"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/opencv/modules/core/include/opencv2/core/hal/interface.h",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 4430,
						"regions":
						{
						},
						"selection":
						[
							[
								2104,
								2104
							]
						],
						"settings":
						{
							"syntax": "Packages/C++/C++.sublime-syntax"
						},
						"translation.x": 0.0,
						"translation.y": 747.0,
						"zoom_level": 1.0
					},
					"stack_index": 3,
					"type": "text"
				},
				{
					"buffer": 4,
					"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/projects/oled/settings.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 6128,
						"regions":
						{
						},
						"selection":
						[
							[
								538,
								538
							]
						],
						"settings":
						{
							"PrevIndex":
							[
								1,
								2
							],
							"syntax": "Packages/Python/Python.sublime-syntax"
						},
						"translation.x": 0.0,
						"translation.y": 0.0,
						"zoom_level": 1.0
					},
					"stack_index": 19,
					"type": "text"
				},
				{
					"buffer": 5,
					"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/projects/raspicamtest/raspicamtest.cpp",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 2179,
						"regions":
						{
						},
						"selection":
						[
							[
								193,
								193
							]
						],
						"settings":
						{
							"history_list_is_closing": true,
							"syntax": "Packages/C++/C++.sublime-syntax"
						},
						"translation.x": 0.0,
						"translation.y": 0.0,
						"zoom_level": 1.0
					},
					"stack_index": 5,
					"type": "text"
				},
				{
					"buffer": 6,
					"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/projects/oled/checkface.cpp",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 5621,
						"regions":
						{
						},
						"selection":
						[
							[
								1938,
								1938
							]
						],
						"settings":
						{
							"syntax": "Packages/C++/C++.sublime-syntax"
						},
						"translation.x": 0.0,
						"translation.y": 0.0,
						"zoom_level": 1.0
					},
					"stack_index": 2,
					"type": "text"
				},
				{
					"buffer": 7,
					"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/opencv/modules/core/include/opencv2/core/mat.hpp",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 153793,
						"regions":
						{
						},
						"selection":
						[
							[
								32882,
								32882
							]
						],
						"settings":
						{
							"syntax": "Packages/C++/C++.sublime-syntax"
						},
						"translation.x": 0.0,
						"translation.y": 25700.0,
						"zoom_level": 1.0
					},
					"stack_index": 10,
					"type": "text"
				}
			]
		},
		{
			"selected": 0,
			"sheets":
			[
				{
					"buffer": 8,
					"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/raspi.ida",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 8778,
						"regions":
						{
						},
						"selection":
						[
							[
								1792,
								1792
							]
						],
						"settings":
						{
							"PrevIndex":
							[
								1,
								1
							],
							"syntax": "Packages/ida/ida.tmLanguage"
						},
						"translation.x": 0.0,
						"translation.y": 0.0,
						"zoom_level": 1.0
					},
					"stack_index": 17,
					"type": "text"
				},
				{
					"buffer": 9,
					"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/opencv/modules/imgproc/src/histogram.cpp",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 132073,
						"regions":
						{
						},
						"selection":
						[
							[
								126246,
								126246
							]
						],
						"settings":
						{
							"syntax": "Packages/C++/C++.sublime-syntax"
						},
						"translation.x": 0.0,
						"translation.y": 58220.0,
						"zoom_level": 1.0
					},
					"stack_index": 15,
					"type": "text"
				},
				{
					"buffer": 10,
					"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/raspicam/src/raspicam_cv.h",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 4142,
						"regions":
						{
						},
						"selection":
						[
							[
								4142,
								4142
							]
						],
						"settings":
						{
							"syntax": "Packages/C++/C++.sublime-syntax"
						},
						"translation.x": 0.0,
						"translation.y": 806.0,
						"zoom_level": 1.0
					},
					"stack_index": 7,
					"type": "text"
				},
				{
					"buffer": 11,
					"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/projects/seeface/seeface.cpp",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 5568,
						"regions":
						{
						},
						"selection":
						[
							[
								2844,
								2844
							]
						],
						"settings":
						{
							"syntax": "Packages/C++/C++.sublime-syntax"
						},
						"translation.x": 0.0,
						"translation.y": 1260.0,
						"zoom_level": 1.0
					},
					"stack_index": 4,
					"type": "text"
				},
				{
					"buffer": 12,
					"file": "raspicam/src/raspicam_still.h",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 4525,
						"regions":
						{
						},
						"selection":
						[
							[
								0,
								0
							]
						],
						"settings":
						{
							"syntax": "Packages/C++/C++.sublime-syntax"
						},
						"translation.x": 0.0,
						"translation.y": 315.0,
						"zoom_level": 1.0
					},
					"stack_index": 6,
					"type": "text"
				},
				{
					"buffer": 13,
					"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/raspicam/src/raspicam_cv.cpp",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 7836,
						"regions":
						{
						},
						"selection":
						[
							[
								5464,
								5464
							]
						],
						"settings":
						{
							"syntax": "Packages/C++/C++.sublime-syntax"
						},
						"translation.x": 0.0,
						"translation.y": 1812.0,
						"zoom_level": 1.0
					},
					"stack_index": 14,
					"type": "text"
				},
				{
					"buffer": 14,
					"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/raspicam/src/private/private_impl.cpp",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 33554,
						"regions":
						{
						},
						"selection":
						[
							[
								6853,
								6853
							]
						],
						"settings":
						{
							"syntax": "Packages/C++/C++.sublime-syntax"
						},
						"translation.x": 0.0,
						"translation.y": 2165.0,
						"zoom_level": 1.0
					},
					"stack_index": 13,
					"type": "text"
				},
				{
					"buffer": 15,
					"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/raspicam/src/private/private_impl.h",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 10775,
						"regions":
						{
						},
						"selection":
						[
							[
								5222,
								5237
							]
						],
						"settings":
						{
							"syntax": "Packages/C++/C++.sublime-syntax"
						},
						"translation.x": 0.0,
						"translation.y": 1220.0,
						"zoom_level": 1.0
					},
					"stack_index": 12,
					"type": "text"
				},
				{
					"buffer": 16,
					"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/projects/raspicam/src/raspicamtypes.h",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 4622,
						"regions":
						{
						},
						"selection":
						[
							[
								2383,
								2383
							]
						],
						"settings":
						{
							"syntax": "Packages/C++/C++.sublime-syntax"
						},
						"translation.x": 0.0,
						"translation.y": 192.0,
						"zoom_level": 1.0
					},
					"stack_index": 11,
					"type": "text"
				},
				{
					"buffer": 17,
					"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/opencv/modules/objdetect/src/cascadedetect.cpp",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 57785,
						"regions":
						{
						},
						"selection":
						[
							[
								55495,
								55495
							]
						],
						"settings":
						{
							"syntax": "Packages/C++/C++.sublime-syntax"
						},
						"translation.x": 0.0,
						"translation.y": 24995.0,
						"zoom_level": 1.0
					},
					"stack_index": 9,
					"type": "text"
				},
				{
					"buffer": 18,
					"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/raspicam/src/raspicam_still_cv.h",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 4170,
						"regions":
						{
						},
						"selection":
						[
							[
								3361,
								3361
							]
						],
						"settings":
						{
							"syntax": "Packages/C++/C++.sublime-syntax"
						},
						"translation.x": 0.0,
						"translation.y": 850.0,
						"zoom_level": 1.0
					},
					"stack_index": 8,
					"type": "text"
				},
				{
					"buffer": 19,
					"file": "/c/Users/gcarver/OneDrive/Projects/Raspi/raspicam/src/raspicam.h",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 7042,
						"regions":
						{
						},
						"selection":
						[
							[
								0,
								0
							]
						],
						"settings":
						{
							"syntax": "Packages/C++/C++.sublime-syntax"
						},
						"translation.x": 0.0,
						"translation.y": 1395.0,
						"zoom_level": 1.0
					},
					"stack_index": 18,
					"type": "text"
				}
			]
		}
	],
	"incremental_find":
	{
		"height": 39.0
	},
	"input":
	{
		"height": 36.0
	},
	"layout":
	{
		"cells":
		[
			[
				0,
				0,
				1,
				1
			],
			[
				1,
				0,
				2,
				1
			]
		],
		"cols":
		[
			0.0,
			0.5,
			1.0
		],
		"rows":
		[
			0.0,
			1.0
		]
	},
	"menu_visible": true,
	"output.exec":
	{
		"height": 100.0
	},
	"output.find_results":
	{
		"height": 0.0
	},
	"output.unsaved_changes":
	{
		"height": 100.0
	},
	"pinned_build_system": "",
	"project": "raspi.sublime-project",
	"replace":
	{
		"height": 73.0
	},
	"save_all_on_build": true,
	"select_file":
	{
		"height": 0.0,
		"last_filter": "",
		"selected_items":
		[
			[
				"raspicam_still_cv",
				"Raspi\\raspicam\\src\\raspicam_still_cv.h"
			],
			[
				"cascadede",
				"Raspi\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp"
			],
			[
				"private",
				"Raspi\\raspicam\\src\\private\\private_impl.cpp"
			],
			[
				"raspicam.h",
				"Raspi\\raspicam\\src\\raspicam.h"
			],
			[
				"raspicam_cv",
				"Raspi\\raspicam\\src\\raspicam_cv.h"
			],
			[
				"raspicam",
				"raspi\\raspicam\\src\\raspicam_cv.h"
			],
			[
				"st",
				"tft\\ST77352.py"
			],
			[
				"mailfile",
				"MailFile/MailFile.py"
			],
			[
				"mail",
				"MailFile/MailFile.py"
			],
			[
				"env",
				"EnvDTE/EnvDTE.py"
			],
			[
				"clipk",
				"ClipBoards/Default (Windows).sublime-keymap"
			],
			[
				"clipke",
				"ClipBoards/Default (Linux).sublime-keymap"
			],
			[
				"clipkeymap",
				"ClipBoards/Default (Linux).sublime-keymap"
			],
			[
				"clip",
				"ClipBoards/Clipboards.py"
			],
			[
				"colo",
				"Color Highlighter/ColorHighlighter.py"
			],
			[
				"ba",
				"Automatic Backups/backup_paths.py"
			],
			[
				"au",
				"Automatic Backups/AutomaticBackups.py"
			],
			[
				"my",
				"User/MyUtils.py"
			]
		],
		"width": 0.0
	},
	"select_project":
	{
		"height": 500.0,
		"last_filter": "",
		"selected_items":
		[
			[
				"",
				"C:\\Projects\\Python\\python.sublime-project"
			]
		],
		"width": 380.0
	},
	"select_symbol":
	{
		"height": 392.0,
		"last_filter": "MP_DEFINE",
		"selected_items":
		[
			[
				"MP_DEFINE",
				"MP_DEFINE_CONST_DICT"
			],
			[
				"mp_obj_new_int",
				"mp_obj_new_int"
			],
			[
				"mp_call",
				"mp_call_function_n_kw"
			],
			[
				"mp_map_loo",
				"mp_map_lookup"
			],
			[
				"mp_map_ele",
				"_mp_map_elem_t"
			],
			[
				"Test",
				"Test3"
			]
		],
		"width": 664.0
	},
	"selected_group": 0,
	"settings":
	{
	},
	"show_minimap": true,
	"show_open_files": true,
	"show_tabs": true,
	"side_bar_visible": true,
	"side_bar_width": 191.0,
	"status_bar_visible": true,
	"template_settings":
	{
	}
}
